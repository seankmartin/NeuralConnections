<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>neuroconnect.compound API documentation</title>
<meta name="description" content="Compound operations to perform more complex tasks than control." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>neuroconnect.compound</code></h1>
</header>
<section id="section-intro">
<p>Compound operations to perform more complex tasks than control.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Compound operations to perform more complex tasks than control.&#34;&#34;&#34;

import os
from configparser import ConfigParser
import json
import time

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from skm_pyutils.py_config import print_cfg
from skm_pyutils.py_table import list_to_df, df_to_file, df_from_file
from dictances.bhattacharyya import bhattacharyya

from .experiment import do_full_experiment
from .connectivity_patterns import get_by_name
from .matrix import main as mouse_main
from .matrix import convert_mouse_data, load_matrix_data, matrix_vis
from .mpf_connection import CombProb
from .connect_math import create_uniform
from .stored_results import store_mouse_result
from .atlas import (
    place_probes_at_com,
    get_n_random_points_in_region,
    get_brain_region_meshes,
    get_idx_of_points_in_meshes,
)
from .atlas_graph import prob_connect_probe


here = os.path.dirname(os.path.realpath(__file__))


def proportion(config, depths=[1, 2, 3]):
    &#34;&#34;&#34;Load a config, change a var, and plot the result over the change.&#34;&#34;&#34;
    np.random.seed(42)
    sns.set_style(&#34;ticks&#34;)
    sns.set_palette(&#34;colorblind&#34;)

    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    num_iters = int(config.get(&#34;default&#34;, &#34;num_iters&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_graph = False
    do_nx = False
    do_vis_graph = False
    full_num = num_samples[0]
    samples = [i for i in range(1, num_samples[0] + 10)]

    for depth in depths:
        saved = []
        saved_least = []
        for val in samples:
            new_samples = [val] * 2
            result = do_full_experiment(
                region_sizes,
                connectivity_pattern,
                connectivity_params,
                new_samples,
                do_mpf,
                do_graph,
                do_nx,
                do_vis_graph,
                num_iters=num_iters,
                max_depth=depth,
            )
            at_least_one = 1 - result[&#34;mpf&#34;][&#34;total&#34;][0]
            expected = result[&#34;mpf&#34;][&#34;expected&#34;]
            proportion = expected / val
            saved.append(proportion)
            saved_least.append(at_least_one)

            if val == full_num:
                full = result[&#34;mpf&#34;]

        here = os.path.dirname(os.path.realpath(__file__))
        os.makedirs(os.path.join(here, &#34;..&#34;, &#34;figures&#34;), exist_ok=True)

        fig, ax = plt.subplots()
        ax.plot(np.array(samples, dtype=float), np.array(saved, dtype=float), c=&#34;k&#34;)
        print(&#34;Setting x ticks&#34;)
        # plt.xticks([i for i in range(num_samples[0])])
        sns.despine()
        plt.xlabel(&#34;Number of recorded neurons&#34;)
        plt.ylabel(&#34;Proportion of connection receiving neurons&#34;)
        fig.savefig(
            os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;proportion_{}.pdf&#34;.format(depth)),
            dpi=400,
        )

        fig, ax = plt.subplots()
        ax.plot(
            np.array(samples, dtype=float), np.array(saved_least, dtype=float), c=&#34;k&#34;
        )
        sns.despine()
        plt.xlabel(&#34;Number of recorded neurons&#34;)
        plt.ylabel(&#34;Probability of at least one neuron receiving a connection&#34;)
        fig.savefig(
            os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;prob_one_{}.pdf&#34;).format(depth),
            dpi=400,
        )

        fig, ax = plt.subplots()
        x = np.array(list(full[&#34;total&#34;].keys()), dtype=float)
        y = np.array(list(full[&#34;total&#34;].values()), dtype=float)

        ax.plot(x, y, &#34;ko&#34;, ms=2.5)
        y_vals_min = [0 for _ in x]
        y_vals_max = y
        colors = [&#34;k&#34; for _ in x]
        ax.set_xticks([i for i in range(num_samples[0] + 1)])
        ax.set_xticklabels([i for i in range(num_samples[0] + 1)])
        # ax.set_ylim([0, 1])
        ax.vlines(x, y_vals_min, y_vals_max, colors=colors)
        sns.despine(offset=0, trim=True)
        plt.xlabel(&#34;Number of recorded connections&#34;)
        plt.ylabel(&#34;Probability&#34;)
        fig.savefig(
            os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;pdf_samples_{}.pdf&#34;).format(depth),
            dpi=400,
        )


def pmf_accuracy(
    config,
    out_name,
    clt_start=10,
    sr=0.01,
    num_iters=50000,
    depth_full=3,
    num_graphs=1,
    do_the_stats=True,
):
    &#34;&#34;&#34;Return pmf on samples.&#34;&#34;&#34;
    np.random.seed(42)
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_graph = True
    do_nx = False
    do_vis_graph = False

    vals = []
    mean_vals = []
    for max_depth in range(1, depth_full + 1):
        result = do_full_experiment(
            region_sizes,
            connectivity_pattern,
            connectivity_params,
            num_samples,
            do_mpf,
            False,
            do_nx,
            do_vis_graph,
            num_iters=num_iters,
            max_depth=max_depth,
            clt_start=clt_start,
            subsample_rate=sr,
            use_mean=do_the_stats,
        )

        cols = [&#34;Number of connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
        mpf_res = result[&#34;mpf&#34;][&#34;total&#34;]

        for k, v in mpf_res.items():
            vals.append([k, v, &#34;Statistical estimation {}&#34;.format(max_depth)])

        mean_vals.append(
            [max_depth, &#34;Statistical estimation&#34;, float(result[&#34;mpf&#34;][&#34;expected&#34;])]
        )

        mean = 0
        for i in range(num_graphs):
            result = do_full_experiment(
                region_sizes,
                connectivity_pattern,
                connectivity_params,
                num_samples,
                False,
                do_graph,
                do_nx,
                do_vis_graph,
                num_iters=num_iters,
                max_depth=max_depth,
                quiet=True,
            )
            graph_res = result[&#34;graph&#34;][&#34;dist&#34;]

            for k, v in graph_res.items():
                vals.append([k, v, &#34;Monte Carlo simulation {}&#34;.format(max_depth)])
            mean += np.mean(result[&#34;graph&#34;][&#34;full_results&#34;][&#34;Connections&#34;].values)

        mean = mean / num_graphs
        mean_vals.append([max_depth, &#34;Monte Carlo simulation&#34;, mean])

        result = do_full_experiment(
            region_sizes,
            get_by_name(&#34;mean_connectivity&#34;),
            connectivity_params,
            num_samples,
            do_mpf,
            False,
            False,
            False,
            num_iters=num_iters,
            max_depth=max_depth,
            subsample_rate=None,
        )
        mpf_res = result[&#34;mpf&#34;][&#34;total&#34;]

        for k, v in mpf_res.items():
            vals.append([k, v, &#34;Mean estimation {}&#34;.format(max_depth)])

        mean_vals.append(
            [max_depth, &#34;Mean estimation&#34;, float(result[&#34;mpf&#34;][&#34;expected&#34;])]
        )

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;pmf_comp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    mean_cols = [&#34;Depth&#34;, &#34;Calculation&#34;, &#34;Mean&#34;]
    df = pd.DataFrame(mean_vals, columns=mean_cols)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;pmf_mean_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df


def connections_dependent_on_samples(
    config,
    out_name,
    do_graph=True,
    num_iters=15000,
    use_mean=True,
    num_graphs=1,
    sr=0.01,
    clt_start=30,
    fin_depth=3,
):
    &#34;&#34;&#34;Return expected connections on samples.&#34;&#34;&#34;
    np.random.seed(42)
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))

    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_nx = False
    do_vis_graph = False

    vals = []
    cols = [
        &#34;Number of samples&#34;,
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Max distance&#34;,
        &#34;Calculation&#34;,
    ]
    depth_name = [None, &#34;Direct synapse&#34;, &#34;Two synapses&#34;, &#34;Three synapses&#34;]
    for max_depth in range(1, fin_depth + 1):
        samples = [i for i in range(num_samples[0] + 1)]
        for val in samples:
            if val == 0:
                vals.append(
                    [val, 0, 0, depth_name[max_depth], &#34;Statistical estimation&#34;]
                )
            else:
                new_samples = [val] * 2
                result = do_full_experiment(
                    region_sizes,
                    connectivity_pattern,
                    connectivity_params,
                    new_samples,
                    do_mpf,
                    False,
                    do_nx,
                    do_vis_graph,
                    num_iters=num_iters,
                    max_depth=max_depth,
                    save_every=1,
                    subsample_rate=sr,
                    use_mean=use_mean,
                    clt_start=clt_start,
                )
                vals.append(
                    [
                        val,
                        result[&#34;mpf&#34;][&#34;expected&#34;],
                        result[&#34;mpf&#34;][&#34;expected&#34;] / val,
                        depth_name[max_depth],
                        &#34;Statistical estimation&#34;,
                    ]
                )
            if do_graph:
                if val == 0:
                    vals.append(
                        [val, 0, 0, depth_name[max_depth], &#34;Monte carlo simulation&#34;]
                    )
                else:
                    for _ in range(num_graphs):
                        result = do_full_experiment(
                            region_sizes,
                            connectivity_pattern,
                            connectivity_params,
                            new_samples,
                            False,
                            do_graph,
                            do_nx,
                            do_vis_graph,
                            num_iters=num_iters,
                            max_depth=max_depth,
                            save_every=1,
                            use_mean=use_mean,
                            quiet=True,
                        )
                        connects = result[&#34;graph&#34;][&#34;full_results&#34;][&#34;Connections&#34;].values
                        for df_val in connects:
                            vals.append(
                                [
                                    val,
                                    df_val,
                                    df_val / val,
                                    depth_name[max_depth],
                                    &#34;Monte carlo simulation&#34;,
                                ]
                            )
    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(
            here, &#34;..&#34;, &#34;results&#34;, &#34;connection_samples_{}.csv&#34;.format(out_name)
        ),
        index=False,
    )

    return df


def connections_dependent_on_regions(
    cfg_names,
    r_names,
    depths,
    out_name,
    num_iters=20000,
    do_graph=True,
):
    &#34;&#34;&#34;Return connection expectation for different regions or connectivity.&#34;&#34;&#34;
    vals = []
    cols = [
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Connectivity&#34;,
        &#34;Calculation&#34;,
    ]

    for cfg_name, r_name, max_depth in zip(cfg_names, r_names, depths):
        here = os.path.dirname(os.path.realpath(__file__))
        config_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, cfg_name)
        config = ConfigParser()
        config.read(config_path)

        region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
        num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
        connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
        connectivity_pattern = get_by_name(connectivity_pattern)
        connectivity_param_names = json.loads(
            config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
        )

        connectivity_param_vals = []
        for name in connectivity_param_names:
            cfg_val = config.get(&#34;default&#34;, name, fallback=None)
            if cfg_val is not None:
                val = json.loads(cfg_val)
            else:
                val = [0 for _ in range(len(region_sizes))]
            connectivity_param_vals.append(val)

        connectivity_params = []
        for i in range(len(region_sizes)):
            d = {}
            for k, v in zip(connectivity_param_names, connectivity_param_vals):
                d[k] = v[i]
            connectivity_params.append(d)

        do_mpf = True
        do_nx = False
        do_vis_graph = False

        result = do_full_experiment(
            region_sizes,
            connectivity_pattern,
            connectivity_params,
            num_samples,
            do_mpf,
            do_graph,
            do_nx,
            do_vis_graph,
            num_iters=num_iters,
            max_depth=max_depth,
            gen_graph_each_iter=False,
        )

        vals.append(
            [
                result[&#34;mpf&#34;][&#34;expected&#34;],
                result[&#34;mpf&#34;][&#34;expected&#34;] / num_samples[1],
                r_name,
                &#34;Statistical estimation&#34;,
            ]
        )

        if do_graph:
            to_add = np.mean(result[&#34;graph&#34;][&#34;full_results&#34;][&#34;Connections&#34;].values)
            vals.append(
                [
                    to_add,
                    to_add / num_samples[1],
                    r_name,
                    &#34;Monte Carlo simulation&#34;,
                ]
            )

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;region_exp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df


def distance_dependent_on_regions(
    cfg_names,
    r_names,
    depths,
    out_name,
    num_iters=20000,
):
    &#34;&#34;&#34;Return connection expectation for different regions or connectivity.&#34;&#34;&#34;
    np.random.seed(42)
    vals = []
    cols = [
        &#34;Bhattacharyya distance&#34;,
        &#34;Connectivity&#34;,
    ]

    for cfg_name, r_name, max_depth in zip(cfg_names, r_names, depths):
        if cfg_name == &#34;USE STORED MOUSE&#34;:
            dist = store_mouse_result()
            vals.append([dist, r_name])
            continue
        here = os.path.dirname(os.path.realpath(__file__))
        config_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, cfg_name)
        config = ConfigParser()
        config.read(config_path)

        region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
        num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
        connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
        connectivity_pattern = get_by_name(connectivity_pattern)
        connectivity_param_names = json.loads(
            config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
        )

        connectivity_param_vals = []
        for name in connectivity_param_names:
            cfg_val = config.get(&#34;default&#34;, name, fallback=None)
            if cfg_val is not None:
                val = json.loads(cfg_val)
            else:
                val = [0 for _ in range(len(region_sizes))]
            connectivity_param_vals.append(val)

        connectivity_params = []
        for i in range(len(region_sizes)):
            d = {}
            for k, v in zip(connectivity_param_names, connectivity_param_vals):
                d[k] = v[i]
            connectivity_params.append(d)

        do_mpf = True
        do_graph = True
        do_nx = False
        do_vis_graph = False

        result = do_full_experiment(
            region_sizes,
            connectivity_pattern,
            connectivity_params,
            num_samples,
            do_mpf,
            do_graph,
            do_nx,
            do_vis_graph,
            num_iters=num_iters,
            max_depth=max_depth,
            gen_graph_each_iter=False,
        )

        dist_estimate = result[&#34;mpf&#34;][&#34;total&#34;]
        dist_actual = result[&#34;graph&#34;][&#34;dist&#34;]
        distance = bhattacharyya(dist_estimate, dist_actual)
        vals.append([distance, r_name])

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;region_bhatt_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df


def mouse_region_exp(
    regions, depths, out_name, num_samples, num_iters=1000, do_graph=False
):
    &#34;&#34;&#34;The expected value from different mouse brain regions.&#34;&#34;&#34;
    np.random.seed(42)
    vals = []
    cols = [
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Regions&#34;,
        &#34;Calculation&#34;,
    ]

    for r, d in zip(regions, depths):
        result = mouse_main(
            num_sampled=num_samples,
            max_depth=d,
            num_iters=num_iters,
            do_graph=do_graph,
            only_exp=True,
            A_name=r[0],
            B_name=r[1],
        )
        vals.append(result[0])
        if result[1] is not None:
            vals.append(result[1])

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;mouse_region_exp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df


def mouse_region_exp_probes(
    regions,
    num_sampled,
    colors=None,
    style=&#34;cartoon&#34;,
    interactive=False,
    hemisphere=&#34;right&#34;,
    vis_only=False,
    block_size_sub=10,
    probe_kwargs=None,
    **simulation_kwargs,
):
    &#34;&#34;&#34;The expected value from different mouse brain regions with probes.&#34;&#34;&#34;
    np.random.seed(42)

    cols = [&#34;Number of connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;, &#34;Regions&#34;]

    if probe_kwargs is None:
        probe_kwargs = [None] * len(regions)

    for r, pk in zip(regions, probe_kwargs):
        final_res_list = []

        name = f&#34;{r[0]}_to_{r[1]}_render&#34;
        cylinder = place_probes_at_com(
            r,
            hemisphere=hemisphere,
            colors=colors,
            style=style,
            interactive=interactive,
            screenshot_name=name,
            probe_kwargs=pk,
        )
        if vis_only:
            continue

        # Load mouse data
        A_name, B_name = r
        convert_mouse_data(A_name, B_name)
        to_use = [True, True, True, True]
        mc, full_stats = load_matrix_data(to_use, A_name, B_name, hemisphere=hemisphere)
        print(&#34;{} - {}, {} - {}&#34;.format(A_name, B_name, mc.num_a, mc.num_b))
        region_sizes = [mc.num_a, mc.num_b]

        t = time.perf_counter()
        print(&#34;Creating graph&#34;)
        mc.create_connections()
        t2 = time.perf_counter() - t
        print(f&#34;Finished graph creation in {t2:.2f}s&#34;)

        # Find intersections of probes and cells
        brain_region_meshes = get_brain_region_meshes(r, None, hemisphere=hemisphere)

        t = time.perf_counter()
        print(&#34;Placing cells in device&#34;)
        region_pts = []
        for region_mesh, region_size in zip(brain_region_meshes, region_sizes):
            pts = get_n_random_points_in_region(region_mesh, region_size, sort_=True)
            meshes = [cylinder]
            pts_idxs = np.sort(get_idx_of_points_in_meshes(pts, meshes))
            pts = pts[pts_idxs]
            region_pts.append((pts, pts_idxs))
        t2 = time.perf_counter() - t
        print(f&#34;Finished cells creation in {t2:.2f}s&#34;)

        a_indices = region_pts[0][1]
        b_indices = region_pts[1][1]

        t = time.perf_counter()
        print(&#34;Visualsing matrix&#34;)
        mc_sub = mc.subsample(a_indices, b_indices)
        o_name = f&#34;{r[0]}_to_{r[1]}_connection_matrix_subbed.pdf&#34;
        matrix_vis(mc_sub.ab, mc_sub.ba, mc_sub.aa, mc_sub.bb, block_size_sub, o_name)
        t2 = time.perf_counter() - t
        print(f&#34;Finished matrix vis in {t2:.2f}s&#34;)

        # Probability calculation
        t = time.perf_counter()
        print(&#34;Running simulation&#34;)
        res = prob_connect_probe(
            mc, num_sampled, a_indices, b_indices, full_stats, **simulation_kwargs
        )
        t2 = time.perf_counter() - t
        print(f&#34;Finished simulation in {t2:.2f}s&#34;)

        r_str = f&#34;{r[0]}_{r[1]}&#34;
        for k, v in res[0][&#34;dist&#34;].items():
            final_res_list.append([k, v, &#34;Monte Carlo simulation&#34;, r_str])

        for k, v in res[1][&#34;total&#34;].items():
            final_res_list.append([k, v, &#34;Statistical estimation&#34;, r_str])

        max_depth = simulation_kwargs[&#34;max_depth&#34;]
        df = list_to_df(final_res_list, headers=cols)
        fname = f&#34;sub_regions_{r[0]}_{r[1]}_depth_{max_depth}.csv&#34;
        fname = os.path.join(here, &#34;..&#34;, &#34;results&#34;, fname)
        print(&#34;Saved dataframe results to {}&#34;.format(fname))
        df_to_file(df, fname, index=False)

    l = []
    for r in regions:
        max_depth = simulation_kwargs[&#34;max_depth&#34;]
        fname = f&#34;sub_regions_{r[0]}_{r[1]}_depth_{max_depth}.csv&#34;
        fname = os.path.join(here, &#34;..&#34;, &#34;results&#34;, fname)
        df = df_from_file(fname)

        for calculation in [&#34;Monte Carlo simulation&#34;, &#34;Statistical estimation&#34;]:
            df_stats = df[df[cols[2]] == calculation]
            expected = (df_stats[cols[0]] * df_stats[cols[1]]).sum()
            if num_sampled[1] == 0:
                expected_proportion = 0
            else:
                expected_proportion = expected / num_sampled[1]
            regions = df[cols[-1]][0]
            l.append([expected, expected_proportion, regions, calculation])

    cols = [
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Regions&#34;,
        &#34;Calculation&#34;,
    ]
    new_df = list_to_df(l, headers=cols)
    new_df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;mouse_region_exp_probes.csv&#34;),
        index=False,
    )

    return new_df


def out_exp(config, out_name, depth, num_iters=1000):
    &#34;&#34;&#34;The expected number of receiving neurons in region 2.&#34;&#34;&#34;
    np.random.seed(42)
    vals = []
    cols = [
        &#34;Number of samples&#34;,
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Calculation&#34;,
    ]

    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_nx = False
    do_graph = True
    do_vis_graph = False

    result = do_full_experiment(
        region_sizes,
        connectivity_pattern,
        connectivity_params,
        num_samples,
        do_mpf,
        do_graph,
        do_nx,
        do_vis_graph,
        num_iters=num_iters,
        max_depth=depth,
        gen_graph_each_iter=False,
        do_fixed=1,
    )

    for k, v in result[&#34;mpf&#34;][&#34;each_expected&#34;].items():
        vals.append([k, float(v), float(v) / region_sizes[1], &#34;Statistical estimation&#34;])

    for i in range(num_samples[0] + 1):
        to_add = result[&#34;g_{}&#34;.format(i)][&#34;full_results&#34;][&#34;Connections&#34;].values
        for v in to_add:
            vals.append([i, v, v / region_sizes[1], &#34;Monte Carlo simulation&#34;])

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;total_b_exp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df


def df_from_dict(dict, cols):
    &#34;&#34;&#34;Form a dataframe from a dictionary with cols, keys are considered an entry.&#34;&#34;&#34;
    vals = []
    for k, v in dict.items():
        vals.append([k, v])

    df = pd.DataFrame(vals, columns=cols)

    return df


def explain_calc(config, out_name=&#34;explain&#34;, sr=0.01):
    &#34;&#34;&#34;Figures to explain how the calculation is performed.&#34;&#34;&#34;
    np.random.seed(42)
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    unif_out = create_uniform(
        connectivity_params[0][&#34;min_forward&#34;], connectivity_params[0][&#34;max_forward&#34;]
    )
    unif_re = create_uniform(
        connectivity_params[1][&#34;min_forward&#34;], connectivity_params[1][&#34;max_forward&#34;]
    )
    a, b = (
        int(round(region_sizes[0] * connectivity_params[0][&#34;min_inter&#34;])),
        int(round(region_sizes[0] * connectivity_params[0][&#34;max_inter&#34;])),
    )
    inter_a = create_uniform(a, b)
    a, b = (
        int(round(region_sizes[1] * connectivity_params[1][&#34;min_inter&#34;])),
        int(round(region_sizes[1] * connectivity_params[1][&#34;max_inter&#34;])),
    )
    inter_b = create_uniform(a, b)
    delta_params = {
        &#34;out_connections_dist&#34;: unif_out,
        &#34;recurrent_connections_dist&#34;: unif_re,
        &#34;num_senders&#34;: connectivity_params[0][&#34;num_senders&#34;],
        &#34;num_recurrent&#34;: connectivity_params[1][&#34;num_senders&#34;],
        &#34;num_start&#34;: region_sizes[0],
        &#34;total_samples&#34;: num_samples[0],
        &#34;start_inter_dist&#34;: inter_a,
        &#34;end_inter_dist&#34;: inter_b,
        &#34;static_verbose&#34;: False,
        &#34;max_depth&#34;: 1,
        &#34;init_delta&#34;: True,
        &#34;clt_start&#34;: 30,
    }

    # Firstly, the results for a senders figure
    cp = CombProb(
        region_sizes[0],
        num_samples[0],
        connectivity_params[0][&#34;num_senders&#34;],
        region_sizes[1],
        num_samples[1],
        connectivity_pattern.static_expected_connections,
        cache=True,
        subsample_rate=sr,
        N=region_sizes[1],
        verbose=False,
        **delta_params,
    )

    data = cp.calculate_distribution_n_senders()
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df = df_from_dict(data, cols=[&#34;Number of sampled senders&#34;, &#34;Probability&#34;])
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;a_prob_{}.csv&#34;.format(out_name)),
        index=False,
    )

    # Secondly, the results for a receivers figure
    data = cp.a_to_b_dist
    df = df_from_dict(data, cols=[&#34;Number of receivers&#34;, &#34;Probability&#34;])
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;b_prob_{}.csv&#34;.format(out_name)),
        index=False,
    )

    # Thirdly, the probability of X=x for just one
    data = cp.final_distribution(keep_all=True)
    df = df_from_dict(data, cols=[&#34;Number of sampled senders&#34;, &#34;Probability&#34;])
    vals = []
    cols = [&#34;Number of sampled A&#34;, &#34;Number of receivers&#34;, &#34;Probability&#34;]
    for k, v in data.items():
        for k2, v2 in v.items():
            vals.append([k, k2, v2])
    df = pd.DataFrame(vals, columns=cols)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;b_each_{}.csv&#34;.format(out_name)),
        index=False,
    )

    # Lastly, the full marginal distribution
    data = cp.stored
    df = df_from_dict(data, cols=[&#34;Number of sampled receivers&#34;, &#34;Probability&#34;])
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;b_fin_{}.csv&#34;.format(out_name)),
        index=False,
    )


def main(cfg_name):
    &#34;&#34;&#34;Calculate the proportion for the given config.&#34;&#34;&#34;
    here = os.path.dirname(os.path.realpath(__file__))
    config_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, cfg_name)
    cfg = ConfigParser()
    cfg.read(config_path)
    print_cfg(cfg, &#34;Program started with configuration&#34;)
    sns.set_palette(&#34;colorblind&#34;)
    proportion(cfg)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="neuroconnect.compound.connections_dependent_on_regions"><code class="name flex">
<span>def <span class="ident">connections_dependent_on_regions</span></span>(<span>cfg_names, r_names, depths, out_name, num_iters=20000, do_graph=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return connection expectation for different regions or connectivity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def connections_dependent_on_regions(
    cfg_names,
    r_names,
    depths,
    out_name,
    num_iters=20000,
    do_graph=True,
):
    &#34;&#34;&#34;Return connection expectation for different regions or connectivity.&#34;&#34;&#34;
    vals = []
    cols = [
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Connectivity&#34;,
        &#34;Calculation&#34;,
    ]

    for cfg_name, r_name, max_depth in zip(cfg_names, r_names, depths):
        here = os.path.dirname(os.path.realpath(__file__))
        config_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, cfg_name)
        config = ConfigParser()
        config.read(config_path)

        region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
        num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
        connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
        connectivity_pattern = get_by_name(connectivity_pattern)
        connectivity_param_names = json.loads(
            config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
        )

        connectivity_param_vals = []
        for name in connectivity_param_names:
            cfg_val = config.get(&#34;default&#34;, name, fallback=None)
            if cfg_val is not None:
                val = json.loads(cfg_val)
            else:
                val = [0 for _ in range(len(region_sizes))]
            connectivity_param_vals.append(val)

        connectivity_params = []
        for i in range(len(region_sizes)):
            d = {}
            for k, v in zip(connectivity_param_names, connectivity_param_vals):
                d[k] = v[i]
            connectivity_params.append(d)

        do_mpf = True
        do_nx = False
        do_vis_graph = False

        result = do_full_experiment(
            region_sizes,
            connectivity_pattern,
            connectivity_params,
            num_samples,
            do_mpf,
            do_graph,
            do_nx,
            do_vis_graph,
            num_iters=num_iters,
            max_depth=max_depth,
            gen_graph_each_iter=False,
        )

        vals.append(
            [
                result[&#34;mpf&#34;][&#34;expected&#34;],
                result[&#34;mpf&#34;][&#34;expected&#34;] / num_samples[1],
                r_name,
                &#34;Statistical estimation&#34;,
            ]
        )

        if do_graph:
            to_add = np.mean(result[&#34;graph&#34;][&#34;full_results&#34;][&#34;Connections&#34;].values)
            vals.append(
                [
                    to_add,
                    to_add / num_samples[1],
                    r_name,
                    &#34;Monte Carlo simulation&#34;,
                ]
            )

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;region_exp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.connections_dependent_on_samples"><code class="name flex">
<span>def <span class="ident">connections_dependent_on_samples</span></span>(<span>config, out_name, do_graph=True, num_iters=15000, use_mean=True, num_graphs=1, sr=0.01, clt_start=30, fin_depth=3)</span>
</code></dt>
<dd>
<div class="desc"><p>Return expected connections on samples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def connections_dependent_on_samples(
    config,
    out_name,
    do_graph=True,
    num_iters=15000,
    use_mean=True,
    num_graphs=1,
    sr=0.01,
    clt_start=30,
    fin_depth=3,
):
    &#34;&#34;&#34;Return expected connections on samples.&#34;&#34;&#34;
    np.random.seed(42)
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))

    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_nx = False
    do_vis_graph = False

    vals = []
    cols = [
        &#34;Number of samples&#34;,
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Max distance&#34;,
        &#34;Calculation&#34;,
    ]
    depth_name = [None, &#34;Direct synapse&#34;, &#34;Two synapses&#34;, &#34;Three synapses&#34;]
    for max_depth in range(1, fin_depth + 1):
        samples = [i for i in range(num_samples[0] + 1)]
        for val in samples:
            if val == 0:
                vals.append(
                    [val, 0, 0, depth_name[max_depth], &#34;Statistical estimation&#34;]
                )
            else:
                new_samples = [val] * 2
                result = do_full_experiment(
                    region_sizes,
                    connectivity_pattern,
                    connectivity_params,
                    new_samples,
                    do_mpf,
                    False,
                    do_nx,
                    do_vis_graph,
                    num_iters=num_iters,
                    max_depth=max_depth,
                    save_every=1,
                    subsample_rate=sr,
                    use_mean=use_mean,
                    clt_start=clt_start,
                )
                vals.append(
                    [
                        val,
                        result[&#34;mpf&#34;][&#34;expected&#34;],
                        result[&#34;mpf&#34;][&#34;expected&#34;] / val,
                        depth_name[max_depth],
                        &#34;Statistical estimation&#34;,
                    ]
                )
            if do_graph:
                if val == 0:
                    vals.append(
                        [val, 0, 0, depth_name[max_depth], &#34;Monte carlo simulation&#34;]
                    )
                else:
                    for _ in range(num_graphs):
                        result = do_full_experiment(
                            region_sizes,
                            connectivity_pattern,
                            connectivity_params,
                            new_samples,
                            False,
                            do_graph,
                            do_nx,
                            do_vis_graph,
                            num_iters=num_iters,
                            max_depth=max_depth,
                            save_every=1,
                            use_mean=use_mean,
                            quiet=True,
                        )
                        connects = result[&#34;graph&#34;][&#34;full_results&#34;][&#34;Connections&#34;].values
                        for df_val in connects:
                            vals.append(
                                [
                                    val,
                                    df_val,
                                    df_val / val,
                                    depth_name[max_depth],
                                    &#34;Monte carlo simulation&#34;,
                                ]
                            )
    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(
            here, &#34;..&#34;, &#34;results&#34;, &#34;connection_samples_{}.csv&#34;.format(out_name)
        ),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.df_from_dict"><code class="name flex">
<span>def <span class="ident">df_from_dict</span></span>(<span>dict, cols)</span>
</code></dt>
<dd>
<div class="desc"><p>Form a dataframe from a dictionary with cols, keys are considered an entry.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def df_from_dict(dict, cols):
    &#34;&#34;&#34;Form a dataframe from a dictionary with cols, keys are considered an entry.&#34;&#34;&#34;
    vals = []
    for k, v in dict.items():
        vals.append([k, v])

    df = pd.DataFrame(vals, columns=cols)

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.distance_dependent_on_regions"><code class="name flex">
<span>def <span class="ident">distance_dependent_on_regions</span></span>(<span>cfg_names, r_names, depths, out_name, num_iters=20000)</span>
</code></dt>
<dd>
<div class="desc"><p>Return connection expectation for different regions or connectivity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distance_dependent_on_regions(
    cfg_names,
    r_names,
    depths,
    out_name,
    num_iters=20000,
):
    &#34;&#34;&#34;Return connection expectation for different regions or connectivity.&#34;&#34;&#34;
    np.random.seed(42)
    vals = []
    cols = [
        &#34;Bhattacharyya distance&#34;,
        &#34;Connectivity&#34;,
    ]

    for cfg_name, r_name, max_depth in zip(cfg_names, r_names, depths):
        if cfg_name == &#34;USE STORED MOUSE&#34;:
            dist = store_mouse_result()
            vals.append([dist, r_name])
            continue
        here = os.path.dirname(os.path.realpath(__file__))
        config_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, cfg_name)
        config = ConfigParser()
        config.read(config_path)

        region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
        num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
        connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
        connectivity_pattern = get_by_name(connectivity_pattern)
        connectivity_param_names = json.loads(
            config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
        )

        connectivity_param_vals = []
        for name in connectivity_param_names:
            cfg_val = config.get(&#34;default&#34;, name, fallback=None)
            if cfg_val is not None:
                val = json.loads(cfg_val)
            else:
                val = [0 for _ in range(len(region_sizes))]
            connectivity_param_vals.append(val)

        connectivity_params = []
        for i in range(len(region_sizes)):
            d = {}
            for k, v in zip(connectivity_param_names, connectivity_param_vals):
                d[k] = v[i]
            connectivity_params.append(d)

        do_mpf = True
        do_graph = True
        do_nx = False
        do_vis_graph = False

        result = do_full_experiment(
            region_sizes,
            connectivity_pattern,
            connectivity_params,
            num_samples,
            do_mpf,
            do_graph,
            do_nx,
            do_vis_graph,
            num_iters=num_iters,
            max_depth=max_depth,
            gen_graph_each_iter=False,
        )

        dist_estimate = result[&#34;mpf&#34;][&#34;total&#34;]
        dist_actual = result[&#34;graph&#34;][&#34;dist&#34;]
        distance = bhattacharyya(dist_estimate, dist_actual)
        vals.append([distance, r_name])

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;region_bhatt_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.explain_calc"><code class="name flex">
<span>def <span class="ident">explain_calc</span></span>(<span>config, out_name='explain', sr=0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>Figures to explain how the calculation is performed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def explain_calc(config, out_name=&#34;explain&#34;, sr=0.01):
    &#34;&#34;&#34;Figures to explain how the calculation is performed.&#34;&#34;&#34;
    np.random.seed(42)
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    unif_out = create_uniform(
        connectivity_params[0][&#34;min_forward&#34;], connectivity_params[0][&#34;max_forward&#34;]
    )
    unif_re = create_uniform(
        connectivity_params[1][&#34;min_forward&#34;], connectivity_params[1][&#34;max_forward&#34;]
    )
    a, b = (
        int(round(region_sizes[0] * connectivity_params[0][&#34;min_inter&#34;])),
        int(round(region_sizes[0] * connectivity_params[0][&#34;max_inter&#34;])),
    )
    inter_a = create_uniform(a, b)
    a, b = (
        int(round(region_sizes[1] * connectivity_params[1][&#34;min_inter&#34;])),
        int(round(region_sizes[1] * connectivity_params[1][&#34;max_inter&#34;])),
    )
    inter_b = create_uniform(a, b)
    delta_params = {
        &#34;out_connections_dist&#34;: unif_out,
        &#34;recurrent_connections_dist&#34;: unif_re,
        &#34;num_senders&#34;: connectivity_params[0][&#34;num_senders&#34;],
        &#34;num_recurrent&#34;: connectivity_params[1][&#34;num_senders&#34;],
        &#34;num_start&#34;: region_sizes[0],
        &#34;total_samples&#34;: num_samples[0],
        &#34;start_inter_dist&#34;: inter_a,
        &#34;end_inter_dist&#34;: inter_b,
        &#34;static_verbose&#34;: False,
        &#34;max_depth&#34;: 1,
        &#34;init_delta&#34;: True,
        &#34;clt_start&#34;: 30,
    }

    # Firstly, the results for a senders figure
    cp = CombProb(
        region_sizes[0],
        num_samples[0],
        connectivity_params[0][&#34;num_senders&#34;],
        region_sizes[1],
        num_samples[1],
        connectivity_pattern.static_expected_connections,
        cache=True,
        subsample_rate=sr,
        N=region_sizes[1],
        verbose=False,
        **delta_params,
    )

    data = cp.calculate_distribution_n_senders()
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df = df_from_dict(data, cols=[&#34;Number of sampled senders&#34;, &#34;Probability&#34;])
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;a_prob_{}.csv&#34;.format(out_name)),
        index=False,
    )

    # Secondly, the results for a receivers figure
    data = cp.a_to_b_dist
    df = df_from_dict(data, cols=[&#34;Number of receivers&#34;, &#34;Probability&#34;])
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;b_prob_{}.csv&#34;.format(out_name)),
        index=False,
    )

    # Thirdly, the probability of X=x for just one
    data = cp.final_distribution(keep_all=True)
    df = df_from_dict(data, cols=[&#34;Number of sampled senders&#34;, &#34;Probability&#34;])
    vals = []
    cols = [&#34;Number of sampled A&#34;, &#34;Number of receivers&#34;, &#34;Probability&#34;]
    for k, v in data.items():
        for k2, v2 in v.items():
            vals.append([k, k2, v2])
    df = pd.DataFrame(vals, columns=cols)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;b_each_{}.csv&#34;.format(out_name)),
        index=False,
    )

    # Lastly, the full marginal distribution
    data = cp.stored
    df = df_from_dict(data, cols=[&#34;Number of sampled receivers&#34;, &#34;Probability&#34;])
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;b_fin_{}.csv&#34;.format(out_name)),
        index=False,
    )</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>cfg_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the proportion for the given config.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(cfg_name):
    &#34;&#34;&#34;Calculate the proportion for the given config.&#34;&#34;&#34;
    here = os.path.dirname(os.path.realpath(__file__))
    config_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, cfg_name)
    cfg = ConfigParser()
    cfg.read(config_path)
    print_cfg(cfg, &#34;Program started with configuration&#34;)
    sns.set_palette(&#34;colorblind&#34;)
    proportion(cfg)</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.mouse_region_exp"><code class="name flex">
<span>def <span class="ident">mouse_region_exp</span></span>(<span>regions, depths, out_name, num_samples, num_iters=1000, do_graph=False)</span>
</code></dt>
<dd>
<div class="desc"><p>The expected value from different mouse brain regions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mouse_region_exp(
    regions, depths, out_name, num_samples, num_iters=1000, do_graph=False
):
    &#34;&#34;&#34;The expected value from different mouse brain regions.&#34;&#34;&#34;
    np.random.seed(42)
    vals = []
    cols = [
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Regions&#34;,
        &#34;Calculation&#34;,
    ]

    for r, d in zip(regions, depths):
        result = mouse_main(
            num_sampled=num_samples,
            max_depth=d,
            num_iters=num_iters,
            do_graph=do_graph,
            only_exp=True,
            A_name=r[0],
            B_name=r[1],
        )
        vals.append(result[0])
        if result[1] is not None:
            vals.append(result[1])

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;mouse_region_exp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.mouse_region_exp_probes"><code class="name flex">
<span>def <span class="ident">mouse_region_exp_probes</span></span>(<span>regions, num_sampled, colors=None, style='cartoon', interactive=False, hemisphere='right', vis_only=False, block_size_sub=10, probe_kwargs=None, **simulation_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>The expected value from different mouse brain regions with probes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mouse_region_exp_probes(
    regions,
    num_sampled,
    colors=None,
    style=&#34;cartoon&#34;,
    interactive=False,
    hemisphere=&#34;right&#34;,
    vis_only=False,
    block_size_sub=10,
    probe_kwargs=None,
    **simulation_kwargs,
):
    &#34;&#34;&#34;The expected value from different mouse brain regions with probes.&#34;&#34;&#34;
    np.random.seed(42)

    cols = [&#34;Number of connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;, &#34;Regions&#34;]

    if probe_kwargs is None:
        probe_kwargs = [None] * len(regions)

    for r, pk in zip(regions, probe_kwargs):
        final_res_list = []

        name = f&#34;{r[0]}_to_{r[1]}_render&#34;
        cylinder = place_probes_at_com(
            r,
            hemisphere=hemisphere,
            colors=colors,
            style=style,
            interactive=interactive,
            screenshot_name=name,
            probe_kwargs=pk,
        )
        if vis_only:
            continue

        # Load mouse data
        A_name, B_name = r
        convert_mouse_data(A_name, B_name)
        to_use = [True, True, True, True]
        mc, full_stats = load_matrix_data(to_use, A_name, B_name, hemisphere=hemisphere)
        print(&#34;{} - {}, {} - {}&#34;.format(A_name, B_name, mc.num_a, mc.num_b))
        region_sizes = [mc.num_a, mc.num_b]

        t = time.perf_counter()
        print(&#34;Creating graph&#34;)
        mc.create_connections()
        t2 = time.perf_counter() - t
        print(f&#34;Finished graph creation in {t2:.2f}s&#34;)

        # Find intersections of probes and cells
        brain_region_meshes = get_brain_region_meshes(r, None, hemisphere=hemisphere)

        t = time.perf_counter()
        print(&#34;Placing cells in device&#34;)
        region_pts = []
        for region_mesh, region_size in zip(brain_region_meshes, region_sizes):
            pts = get_n_random_points_in_region(region_mesh, region_size, sort_=True)
            meshes = [cylinder]
            pts_idxs = np.sort(get_idx_of_points_in_meshes(pts, meshes))
            pts = pts[pts_idxs]
            region_pts.append((pts, pts_idxs))
        t2 = time.perf_counter() - t
        print(f&#34;Finished cells creation in {t2:.2f}s&#34;)

        a_indices = region_pts[0][1]
        b_indices = region_pts[1][1]

        t = time.perf_counter()
        print(&#34;Visualsing matrix&#34;)
        mc_sub = mc.subsample(a_indices, b_indices)
        o_name = f&#34;{r[0]}_to_{r[1]}_connection_matrix_subbed.pdf&#34;
        matrix_vis(mc_sub.ab, mc_sub.ba, mc_sub.aa, mc_sub.bb, block_size_sub, o_name)
        t2 = time.perf_counter() - t
        print(f&#34;Finished matrix vis in {t2:.2f}s&#34;)

        # Probability calculation
        t = time.perf_counter()
        print(&#34;Running simulation&#34;)
        res = prob_connect_probe(
            mc, num_sampled, a_indices, b_indices, full_stats, **simulation_kwargs
        )
        t2 = time.perf_counter() - t
        print(f&#34;Finished simulation in {t2:.2f}s&#34;)

        r_str = f&#34;{r[0]}_{r[1]}&#34;
        for k, v in res[0][&#34;dist&#34;].items():
            final_res_list.append([k, v, &#34;Monte Carlo simulation&#34;, r_str])

        for k, v in res[1][&#34;total&#34;].items():
            final_res_list.append([k, v, &#34;Statistical estimation&#34;, r_str])

        max_depth = simulation_kwargs[&#34;max_depth&#34;]
        df = list_to_df(final_res_list, headers=cols)
        fname = f&#34;sub_regions_{r[0]}_{r[1]}_depth_{max_depth}.csv&#34;
        fname = os.path.join(here, &#34;..&#34;, &#34;results&#34;, fname)
        print(&#34;Saved dataframe results to {}&#34;.format(fname))
        df_to_file(df, fname, index=False)

    l = []
    for r in regions:
        max_depth = simulation_kwargs[&#34;max_depth&#34;]
        fname = f&#34;sub_regions_{r[0]}_{r[1]}_depth_{max_depth}.csv&#34;
        fname = os.path.join(here, &#34;..&#34;, &#34;results&#34;, fname)
        df = df_from_file(fname)

        for calculation in [&#34;Monte Carlo simulation&#34;, &#34;Statistical estimation&#34;]:
            df_stats = df[df[cols[2]] == calculation]
            expected = (df_stats[cols[0]] * df_stats[cols[1]]).sum()
            if num_sampled[1] == 0:
                expected_proportion = 0
            else:
                expected_proportion = expected / num_sampled[1]
            regions = df[cols[-1]][0]
            l.append([expected, expected_proportion, regions, calculation])

    cols = [
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Regions&#34;,
        &#34;Calculation&#34;,
    ]
    new_df = list_to_df(l, headers=cols)
    new_df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;mouse_region_exp_probes.csv&#34;),
        index=False,
    )

    return new_df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.out_exp"><code class="name flex">
<span>def <span class="ident">out_exp</span></span>(<span>config, out_name, depth, num_iters=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>The expected number of receiving neurons in region 2.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def out_exp(config, out_name, depth, num_iters=1000):
    &#34;&#34;&#34;The expected number of receiving neurons in region 2.&#34;&#34;&#34;
    np.random.seed(42)
    vals = []
    cols = [
        &#34;Number of samples&#34;,
        &#34;Expected connected&#34;,
        &#34;Expected proportion connected&#34;,
        &#34;Calculation&#34;,
    ]

    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_nx = False
    do_graph = True
    do_vis_graph = False

    result = do_full_experiment(
        region_sizes,
        connectivity_pattern,
        connectivity_params,
        num_samples,
        do_mpf,
        do_graph,
        do_nx,
        do_vis_graph,
        num_iters=num_iters,
        max_depth=depth,
        gen_graph_each_iter=False,
        do_fixed=1,
    )

    for k, v in result[&#34;mpf&#34;][&#34;each_expected&#34;].items():
        vals.append([k, float(v), float(v) / region_sizes[1], &#34;Statistical estimation&#34;])

    for i in range(num_samples[0] + 1):
        to_add = result[&#34;g_{}&#34;.format(i)][&#34;full_results&#34;][&#34;Connections&#34;].values
        for v in to_add:
            vals.append([i, v, v / region_sizes[1], &#34;Monte Carlo simulation&#34;])

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;total_b_exp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.pmf_accuracy"><code class="name flex">
<span>def <span class="ident">pmf_accuracy</span></span>(<span>config, out_name, clt_start=10, sr=0.01, num_iters=50000, depth_full=3, num_graphs=1, do_the_stats=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return pmf on samples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pmf_accuracy(
    config,
    out_name,
    clt_start=10,
    sr=0.01,
    num_iters=50000,
    depth_full=3,
    num_graphs=1,
    do_the_stats=True,
):
    &#34;&#34;&#34;Return pmf on samples.&#34;&#34;&#34;
    np.random.seed(42)
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_graph = True
    do_nx = False
    do_vis_graph = False

    vals = []
    mean_vals = []
    for max_depth in range(1, depth_full + 1):
        result = do_full_experiment(
            region_sizes,
            connectivity_pattern,
            connectivity_params,
            num_samples,
            do_mpf,
            False,
            do_nx,
            do_vis_graph,
            num_iters=num_iters,
            max_depth=max_depth,
            clt_start=clt_start,
            subsample_rate=sr,
            use_mean=do_the_stats,
        )

        cols = [&#34;Number of connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
        mpf_res = result[&#34;mpf&#34;][&#34;total&#34;]

        for k, v in mpf_res.items():
            vals.append([k, v, &#34;Statistical estimation {}&#34;.format(max_depth)])

        mean_vals.append(
            [max_depth, &#34;Statistical estimation&#34;, float(result[&#34;mpf&#34;][&#34;expected&#34;])]
        )

        mean = 0
        for i in range(num_graphs):
            result = do_full_experiment(
                region_sizes,
                connectivity_pattern,
                connectivity_params,
                num_samples,
                False,
                do_graph,
                do_nx,
                do_vis_graph,
                num_iters=num_iters,
                max_depth=max_depth,
                quiet=True,
            )
            graph_res = result[&#34;graph&#34;][&#34;dist&#34;]

            for k, v in graph_res.items():
                vals.append([k, v, &#34;Monte Carlo simulation {}&#34;.format(max_depth)])
            mean += np.mean(result[&#34;graph&#34;][&#34;full_results&#34;][&#34;Connections&#34;].values)

        mean = mean / num_graphs
        mean_vals.append([max_depth, &#34;Monte Carlo simulation&#34;, mean])

        result = do_full_experiment(
            region_sizes,
            get_by_name(&#34;mean_connectivity&#34;),
            connectivity_params,
            num_samples,
            do_mpf,
            False,
            False,
            False,
            num_iters=num_iters,
            max_depth=max_depth,
            subsample_rate=None,
        )
        mpf_res = result[&#34;mpf&#34;][&#34;total&#34;]

        for k, v in mpf_res.items():
            vals.append([k, v, &#34;Mean estimation {}&#34;.format(max_depth)])

        mean_vals.append(
            [max_depth, &#34;Mean estimation&#34;, float(result[&#34;mpf&#34;][&#34;expected&#34;])]
        )

    df = pd.DataFrame(vals, columns=cols)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;pmf_comp_{}.csv&#34;.format(out_name)),
        index=False,
    )

    mean_cols = [&#34;Depth&#34;, &#34;Calculation&#34;, &#34;Mean&#34;]
    df = pd.DataFrame(mean_vals, columns=mean_cols)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;pmf_mean_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.compound.proportion"><code class="name flex">
<span>def <span class="ident">proportion</span></span>(<span>config, depths=[1, 2, 3])</span>
</code></dt>
<dd>
<div class="desc"><p>Load a config, change a var, and plot the result over the change.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def proportion(config, depths=[1, 2, 3]):
    &#34;&#34;&#34;Load a config, change a var, and plot the result over the change.&#34;&#34;&#34;
    np.random.seed(42)
    sns.set_style(&#34;ticks&#34;)
    sns.set_palette(&#34;colorblind&#34;)

    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    num_iters = int(config.get(&#34;default&#34;, &#34;num_iters&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_graph = False
    do_nx = False
    do_vis_graph = False
    full_num = num_samples[0]
    samples = [i for i in range(1, num_samples[0] + 10)]

    for depth in depths:
        saved = []
        saved_least = []
        for val in samples:
            new_samples = [val] * 2
            result = do_full_experiment(
                region_sizes,
                connectivity_pattern,
                connectivity_params,
                new_samples,
                do_mpf,
                do_graph,
                do_nx,
                do_vis_graph,
                num_iters=num_iters,
                max_depth=depth,
            )
            at_least_one = 1 - result[&#34;mpf&#34;][&#34;total&#34;][0]
            expected = result[&#34;mpf&#34;][&#34;expected&#34;]
            proportion = expected / val
            saved.append(proportion)
            saved_least.append(at_least_one)

            if val == full_num:
                full = result[&#34;mpf&#34;]

        here = os.path.dirname(os.path.realpath(__file__))
        os.makedirs(os.path.join(here, &#34;..&#34;, &#34;figures&#34;), exist_ok=True)

        fig, ax = plt.subplots()
        ax.plot(np.array(samples, dtype=float), np.array(saved, dtype=float), c=&#34;k&#34;)
        print(&#34;Setting x ticks&#34;)
        # plt.xticks([i for i in range(num_samples[0])])
        sns.despine()
        plt.xlabel(&#34;Number of recorded neurons&#34;)
        plt.ylabel(&#34;Proportion of connection receiving neurons&#34;)
        fig.savefig(
            os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;proportion_{}.pdf&#34;.format(depth)),
            dpi=400,
        )

        fig, ax = plt.subplots()
        ax.plot(
            np.array(samples, dtype=float), np.array(saved_least, dtype=float), c=&#34;k&#34;
        )
        sns.despine()
        plt.xlabel(&#34;Number of recorded neurons&#34;)
        plt.ylabel(&#34;Probability of at least one neuron receiving a connection&#34;)
        fig.savefig(
            os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;prob_one_{}.pdf&#34;).format(depth),
            dpi=400,
        )

        fig, ax = plt.subplots()
        x = np.array(list(full[&#34;total&#34;].keys()), dtype=float)
        y = np.array(list(full[&#34;total&#34;].values()), dtype=float)

        ax.plot(x, y, &#34;ko&#34;, ms=2.5)
        y_vals_min = [0 for _ in x]
        y_vals_max = y
        colors = [&#34;k&#34; for _ in x]
        ax.set_xticks([i for i in range(num_samples[0] + 1)])
        ax.set_xticklabels([i for i in range(num_samples[0] + 1)])
        # ax.set_ylim([0, 1])
        ax.vlines(x, y_vals_min, y_vals_max, colors=colors)
        sns.despine(offset=0, trim=True)
        plt.xlabel(&#34;Number of recorded connections&#34;)
        plt.ylabel(&#34;Probability&#34;)
        fig.savefig(
            os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;pdf_samples_{}.pdf&#34;).format(depth),
            dpi=400,
        )</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="neuroconnect" href="index.html">neuroconnect</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="neuroconnect.compound.connections_dependent_on_regions" href="#neuroconnect.compound.connections_dependent_on_regions">connections_dependent_on_regions</a></code></li>
<li><code><a title="neuroconnect.compound.connections_dependent_on_samples" href="#neuroconnect.compound.connections_dependent_on_samples">connections_dependent_on_samples</a></code></li>
<li><code><a title="neuroconnect.compound.df_from_dict" href="#neuroconnect.compound.df_from_dict">df_from_dict</a></code></li>
<li><code><a title="neuroconnect.compound.distance_dependent_on_regions" href="#neuroconnect.compound.distance_dependent_on_regions">distance_dependent_on_regions</a></code></li>
<li><code><a title="neuroconnect.compound.explain_calc" href="#neuroconnect.compound.explain_calc">explain_calc</a></code></li>
<li><code><a title="neuroconnect.compound.main" href="#neuroconnect.compound.main">main</a></code></li>
<li><code><a title="neuroconnect.compound.mouse_region_exp" href="#neuroconnect.compound.mouse_region_exp">mouse_region_exp</a></code></li>
<li><code><a title="neuroconnect.compound.mouse_region_exp_probes" href="#neuroconnect.compound.mouse_region_exp_probes">mouse_region_exp_probes</a></code></li>
<li><code><a title="neuroconnect.compound.out_exp" href="#neuroconnect.compound.out_exp">out_exp</a></code></li>
<li><code><a title="neuroconnect.compound.pmf_accuracy" href="#neuroconnect.compound.pmf_accuracy">pmf_accuracy</a></code></li>
<li><code><a title="neuroconnect.compound.proportion" href="#neuroconnect.compound.proportion">proportion</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>