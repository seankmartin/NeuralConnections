{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconnect.connect_math import discretised_rv, get_dist_mean\n",
    "from neuroconnect.mpf_connection import CombProb\n",
    "from neuroconnect.connectivity_patterns import OutgoingDistributionConnections\n",
    "from scipy.stats import truncexpon\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Config - define the power law\n",
    "# sizes = [100, 1000, 5000, 10000, 50000, 100000]\n",
    "sizes = [100, 1000, 2500, 5000, 10000, 50000, 100000, 1000000]\n",
    "scales = [10, 100, 250, 500, 1000, 5000, 10000, 100000]\n",
    "\n",
    "desired_cfg = 0.4\n",
    "percent_out = 0.2\n",
    "sub_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check means\n",
    "for s, scale in zip(sizes, scales):\n",
    "    max_out = s // 2\n",
    "    dist = discretised_rv(truncexpon(s // 2, scale=scale, loc=0), 0, s // 2)\n",
    "    mean = get_dist_mean(dist)\n",
    "    plt.plot(list(dist.keys()), list(dist.values()), label=s)\n",
    "    print(100 * mean / s)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. How to run the stats\n",
    "def do_mpf(num_samples, size, dist, percent_out, clt_start=30, subsample_rate=0.01):\n",
    "    region1_nodes = list(range(size))\n",
    "    region2_nodes = list(range(size, 2 * size))\n",
    "    num_region1_senders = size * percent_out\n",
    "    delta_params = dict(\n",
    "        num_start=len(region1_nodes),\n",
    "        num_end=len(region2_nodes),\n",
    "        num_senders=num_region1_senders,\n",
    "        out_connections_dist=dist,\n",
    "        total_samples=num_samples[0],\n",
    "        clt_start=clt_start,\n",
    "        sub=subsample_rate,\n",
    "    )\n",
    "    connection_prob = CombProb(\n",
    "        len(region1_nodes),\n",
    "        num_samples[0],\n",
    "        num_region1_senders,\n",
    "        len(region2_nodes),\n",
    "        num_samples[1],\n",
    "        OutgoingDistributionConnections.static_expected_connections,\n",
    "        subsample_rate=subsample_rate,\n",
    "        approx_hypergeo=False,\n",
    "        **delta_params,\n",
    "    )\n",
    "    return {\n",
    "        \"expected\": connection_prob.expected_connections(),\n",
    "        \"total\": connection_prob.get_all_prob(),\n",
    "        \"each_expected\": {\n",
    "            k: connection_prob.expected_total(k) for k in range(num_samples[0] + 1)\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run the stats over different sizes and num samples\n",
    "# Start with say 20% of the population\n",
    "def function_to_minimize(\n",
    "    samples_to_use, full_size, desired, dist, percent_out, subsample_rate\n",
    "):\n",
    "    result = do_mpf(samples_to_use, full_size, dist, percent_out, 30, subsample_rate)\n",
    "    expected = result[\"expected\"]\n",
    "    return (expected / samples_to_use[1]) - desired\n",
    "\n",
    "\n",
    "def find_correct_sample_size(\n",
    "    full_size, scale, percent_out, desired, lb, ub, subsample_rate=0.01\n",
    "):\n",
    "    min_ = 0\n",
    "    max_ = min(full_size, 2000)\n",
    "    start = min(full_size // 100, 80)\n",
    "    samples_to_use = [start, start]\n",
    "    max_out = full_size // 4\n",
    "    dist = discretised_rv(truncexpon(max_out, scale=scale, loc=0), 0, max_out)\n",
    "    mean = get_dist_mean(dist)\n",
    "    print(100 * mean / full_size)\n",
    "\n",
    "    max_iters = 200\n",
    "    n = 0\n",
    "\n",
    "    while min_ != max_ and n < max_iters:\n",
    "        result = function_to_minimize(\n",
    "            samples_to_use, full_size, desired, dist, percent_out, subsample_rate\n",
    "        )\n",
    "        n += 1\n",
    "        if n == max_iters:\n",
    "            raise RuntimeError(\n",
    "                f\"Only found expected of {result['expected']} with {samples_to_use[0]}, not {desired}\"\n",
    "            )\n",
    "        if result > -lb and result < ub:\n",
    "            return samples_to_use[0], n\n",
    "        if result < 0:\n",
    "            min_ = samples_to_use[0]\n",
    "            samples_to_use = [(max_ + min_) // 2, (max_ + min_) // 2]\n",
    "        elif result > 0:\n",
    "            max_ = samples_to_use[0]\n",
    "            samples_to_use = [(max_ + min_) // 2, (max_ + min_) // 2]\n",
    "\n",
    "    return samples_to_use[0], n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run over the sizes\n",
    "sub_rates = [None]\n",
    "saved = []\n",
    "for sr in sub_rates:\n",
    "    found_sizes = [\n",
    "        find_correct_sample_size(s, scale, percent_out, desired_cfg, 0.02, 0.02, sr)\n",
    "        for s, scale in zip(sizes, scales)\n",
    "    ]\n",
    "    saved.append(found_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for found_sizes in saved:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(sizes, [fs[0] for fs in found_sizes])\n",
    "    print(sizes, found_sizes)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('notebooks')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dee386f75b2b2024fa24ea07d919084e8ac591973033df4e97cdf4d0511caeb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
