<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>neuroconnect.connectivity_patterns API documentation</title>
<meta name="description" content="Abstract class setting the functions needed to define connections." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>neuroconnect.connectivity_patterns</code></h1>
</header>
<section id="section-intro">
<p>Abstract class setting the functions needed to define connections.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Abstract class setting the functions needed to define connections.&#34;&#34;&#34;

from abc import ABC, abstractmethod
import math
from collections import OrderedDict

from mpmath import nstr
from scipy import sparse
import numpy as np

from .connect_math import (
    expected_unique,
    expected_non_overlapping,
    expected_overlapping,
    random_draw_dist,
    hypergeometric_pmf,
    get_dist_mean,
    apply_fn_to_dist,
    create_uniform,
    nfold_conv,
    convolution,
    combine_dists,
    create_normal,
    get_uniform_moments,
    get_dist_var,
)
from .simple_graph import from_matrix


def get_by_name(name):
    &#34;&#34;&#34;Retrieve a connection strategy by name.&#34;&#34;&#34;
    classes = {
        &#34;recurrent_connectivity&#34;: RecurrentConnectivity,
        &#34;matrix_connectivity&#34;: MatrixConnectivity,
        &#34;mean_connectivity&#34;: MeanRecurrentConnectivity,
        &#34;unique_connectivity&#34;: UniqueConnectivity,
    }
    return classes[name]


class ConnectionStrategy(ABC):
    &#34;&#34;&#34;
    Abstract class to describe the connection strategy between two regions.

    Must define:
    1. create_connections:
        How to form connections between neurons in the regions.
        Expected to return graph, connections
    2. expected_connections:
        How many connections would be expected between neurons in the regions.
    3. static_expected_connections:
        An interface into expected_connections that can be statically called.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        super().__init__()
        pass

    @abstractmethod
    def create_connections(self, *args, **kwargs):
        &#34;&#34;&#34;How to form connections between neurons in the regions.&#34;&#34;&#34;
        pass

    @abstractmethod
    def expected_connections(self, *args, **kwargs):
        &#34;&#34;&#34;The distribution of connections.&#34;&#34;&#34;
        pass

    @staticmethod
    @abstractmethod
    def static_expected_connections(*args, **kwargs):
        &#34;&#34;&#34;The distribution of connections called statically.&#34;&#34;&#34;
        pass


class UniqueConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connections where connections don&#39;t overlap.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        graph = []

        # Choose the forward connectors
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connections = np.random.choice(
                    choices, size=(self.max_forward), replace=False
                )
                forward_connection = forward_connections[: num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return UniqueConnectivity.static_expected_connections(
            total_samples=num_samples, **kwargs
        )

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 1)

        if max_depth &gt; 1:
            raise ValueError(&#34;max_depth must be 1 for unique connections.&#34;)

        num_end = kwargs.get(&#34;N&#34;)
        out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)

        total_samples = kwargs.get(&#34;total_samples&#34;)
        clt_start = kwargs.get(&#34;clt_start&#34;, 30)
        sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

        # Setup required regardless of the depth of the connection

        # Gives dist of num outgoing connections from A
        # This tends towards normal distribution by CLT in most cases

        def fn_to_apply(k):
            return int(round(expected_unique(num_end, k)))

        ab_dist = random_draw_dist(
            total_samples,
            out_connections_dist,
            num_end,
            apply_fn=False,
            keep_all=True,
            clt_start=clt_start,
            sub=sub,
        )

        final_dist = ab_dist

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end + 1), final_dist, prob_a_senders, sub=None
        )

        return ab_dist, weighted_dist


class RecurrentConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connection with recursive connections and interconnections allowed.

    In this, a certain number of neurons output a random number of connections
    to completely random neurons with repetition possible.
    This handles both forward and backward connections.
    interconnections are handled by randomly sampling a set of
    neurons for each neuron.
    The rate at which interconnected synapses are formed is kept fixed
    but the number of connections varies as multiple synapses can be formed.

    Should pass the following keyword arguments on initialisation:
    num_senders : int
        The number of neurons which send a connection
    min_inter : float
        The minimum interconnection rate
    max_inter : float
        The maximum interconnection rate
    min_forward : int
        The minimum number of forward connections from one neuron
    max_forward : int
        The maximum number of forward connections from one neuron

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_inter = kwargs.get(&#34;min_inter&#34;)
        self.max_inter = kwargs.get(&#34;max_inter&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)
        self.recursive = kwargs.get(&#34;recursive&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        box = kwargs.get(&#34;box&#34;, False)  # for performance reasons

        if kwargs.get(&#34;use_full_region&#34;, True):
            graph, connected = self.gen_full_graph(choices, region_verts, box)
        else:
            if self.recursive:
                graph, connected = self.gen_graph_recursive(choices, **kwargs)
            else:
                graph, connected = self.gen_graph(choices, **kwargs)

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return RecurrentConnectivity.static_expected_connections(
            total_samples=num_samples, **kwargs
        )

    def gen_full_graph(self, choices, region_verts, box):
        graph = []
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create connections between neurons in the same region
        if self.max_inter &gt; 0:
            if box:
                num_boxes = 5
                box_like = 4
                box_size = int(math.ceil(len(region_verts) / num_boxes))
                out_box_size = len(region_verts) - box_size

                # Represents in box being box_like times more likely than outside
                # e.g. for 5
                # x = 5y
                # 1 = (1 / num_boxes) * (5 * y) + (1 - 1 / num_boxes) * y
                y_mult = (1 / num_boxes) * (box_like) + (1 - (1 / num_boxes))
                out_box_mult = 1 / y_mult
                in_box_mult = box_like * out_box_mult
                mult = np.array(
                    [
                        (1 / num_boxes) * in_box_mult,
                        (1 - (1 / num_boxes)) * out_box_mult,
                    ]
                )
                rand_amt = self.min_inter + (
                    np.random.rand() * (self.max_inter - self.min_inter)
                )
                sample_sizes = np.ceil(rand_amt * mult * len(region_verts)).astype(int)

                in_box_idx = np.array([i for i in range(box_size)], dtype=np.int32)
                self_connects_box = np.random.choice(
                    in_box_idx,
                    size=(len(region_verts), sample_sizes[0]),
                    replace=True,
                )

                out_box_idx = np.array(
                    [i + box_size for i in range(out_box_size)], dtype=np.int32
                )
                self_connects_outside = np.random.choice(
                    out_box_idx,
                    size=(len(region_verts), sample_sizes[1]),
                    replace=True,
                )

            else:
                self_connects = np.random.choice(
                    region_verts,
                    size=(
                        len(region_verts),
                        int(round(self.max_inter * len(region_verts))),
                    ),
                    replace=True,
                )
                num_choices_inter = np.random.randint(
                    int(round(self.min_inter * len(region_verts))),
                    int(round(self.max_inter * len(region_verts))) + 1,
                    dtype=np.int32,
                    size=len(region_verts),
                )

        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            if self.max_inter &gt; 0:
                if box:
                    which_box = int(math.floor(i / box_size))
                    a = int(which_box * box_size)

                    self_connects_box_i = a + self_connects_box[i]

                    self_connects_out_i = self_connects_outside[i]
                    self_connects_out_i[
                        self_connects_out_i &lt; (a + box_size)
                    ] -= box_size

                    self_connections = np.array(
                        list(
                            set(
                                np.concatenate(
                                    (self_connects_box_i, self_connects_out_i)
                                    + np.min(region_verts)
                                )
                            )
                        ),
                        dtype=np.int32,
                    )

                else:
                    self_connections = np.array(
                        list(set(self_connects[i, : num_choices_inter[i]])),
                        dtype=np.int32,
                    )

                # Remove autaptic synapses
                self_connections = np.delete(
                    self_connections, np.where(self_connections == vert)
                )
                for val in self_connections:
                    if isinstance(val, float):
                        print(val, self_connections)
                        exit(-1)

            else:
                self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def gen_graph(self, choices, **kwargs):
        def d_minmax(dist):
            vals = list(dist.items())
            return vals[0][0], vals[-1][0]

        graph = []

        region_verts = kwargs.get(&#34;region_verts&#34;)
        idx_inA = kwargs.get(&#34;idx_in_deviceA&#34;)
        idx_outA = list(set(region_verts) - set(idx_inA))
        idx_inB = kwargs.get(&#34;idx_in_deviceB&#34;) + len(region_verts)
        idx_outB = list(set(choices) - set(idx_inB))
        num_senders_device = kwargs.get(&#34;num_senders_probe&#34;)
        num_senders_A = kwargs.get(&#34;num_senders_A&#34;)
        num_senders_B = kwargs.get(&#34;num_senders_B&#34;)
        forward_dist_device = kwargs.get(&#34;out_connections_dist_probe&#34;)
        forwardA_to_Bprobe = kwargs.get(&#34;out_connections_dist_B&#34;)
        forwardAprobe_to_B = kwargs.get(&#34;out_connections_dist_A&#34;)
        start_probe_to_outside = kwargs.get(&#34;start_probe_to_outside&#34;)

        forward_dist_device_min, forward_dist_device_max = d_minmax(forward_dist_device)
        forwardA_to_Bprobe_min, forwardA_to_Bprobe_max = d_minmax(forwardA_to_Bprobe)
        forwardAprobe_to_B_min, forwardAprobe_to_B_max = d_minmax(forwardAprobe_to_B)
        start_probe_to_outside_min, start_probe_to_outside_max = d_minmax(
            start_probe_to_outside
        )

        # A device to B device
        connected_device = np.random.choice(
            idx_inA, size=num_senders_device, replace=False
        )
        forward_connections_device = np.random.choice(
            idx_inB, size=(num_senders_device, forward_dist_device_max), replace=True
        )
        num_choices_device = np.random.randint(
            forward_dist_device_min,
            forward_dist_device_max + 1,
            dtype=np.int32,
            size=num_senders_device,
        )

        # A device to B
        if len(idx_outB) == 0:
            connected_Adevice = []
        else:
            connected_Adevice = np.random.choice(
                idx_inA, size=num_senders_A, replace=False
            )
            forward_connections_Adevice_B = np.random.choice(
                idx_outB, size=(num_senders_A, forwardAprobe_to_B_max), replace=True
            )
            num_choices_Adevice_B = np.random.randint(
                forwardAprobe_to_B_min,
                forwardAprobe_to_B_min + 1,
                dtype=np.int32,
                size=num_senders_A,
            )

        # A to B device
        if len(idx_outA) == 0:
            connected_Bdevice = []
        else:
            connected_Bdevice = np.random.choice(
                idx_outA, size=num_senders_B - num_senders_device, replace=False
            )
            forward_connections_A_Bdevice = np.random.choice(
                idx_inB,
                size=(num_senders_B - num_senders_device, forwardA_to_Bprobe_max),
                replace=True,
            )
            num_choices_A_Bdevice = np.random.randint(
                forwardA_to_Bprobe_min,
                forwardA_to_Bprobe_max + 1,
                dtype=np.int32,
                size=num_senders_B,
            )

        # A interconnections
        self_connects_Adevice = np.random.choice(
            region_verts,
            size=(
                len(idx_inA),
                int(round(start_probe_to_outside_max)),
            ),
            replace=True,
        )
        num_choices_inter_device = np.random.randint(
            int(round(start_probe_to_outside_min)),
            int(round(start_probe_to_outside_max)) + 1,
            dtype=np.int32,
            size=len(idx_inA),
        )
        self_connects_Arest = np.random.choice(
            region_verts,
            size=(
                len(region_verts) - len(idx_inA),
                int(round(self.max_inter * len(region_verts))),
            ),
            replace=True,
        )
        num_choices_inter = np.random.randint(
            int(round(self.min_inter * len(region_verts))),
            int(round(self.max_inter * len(region_verts))) + 1,
            dtype=np.int32,
            size=len(region_verts) - len(idx_inA),
        )

        # Create the connections
        a_idx = 0
        b_idx = 0
        c_idx = 0
        d_idx = 0
        e_idx = 0
        for i, vert in enumerate(region_verts):
            if vert in idx_inA:
                self_connections = np.array(
                    list(
                        set(
                            self_connects_Adevice[
                                d_idx, : num_choices_inter_device[d_idx]
                            ]
                        )
                    ),
                    dtype=np.int32,
                )
                d_idx = d_idx + 1
            else:
                self_connections = np.array(
                    list(set(self_connects_Arest[e_idx, : num_choices_inter[e_idx]])),
                    dtype=np.int32,
                )
                e_idx = e_idx + 1

            # Remove autaptic synapses
            self_connections = np.delete(
                self_connections, np.where(self_connections == vert)
            )
            for val in self_connections:
                if isinstance(val, float):
                    print(val, self_connections)
                    exit(-1)

            if vert in connected_device:
                forward_connection = forward_connections_device[
                    a_idx, : num_choices_device[a_idx]
                ]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                a_idx = a_idx + 1

            if vert in connected_Adevice:
                forward_connection = forward_connections_Adevice_B[
                    b_idx, : num_choices_Adevice_B[b_idx]
                ]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                b_idx = b_idx + 1

            if vert in connected_Bdevice:
                forward_connection = forward_connections_A_Bdevice[
                    c_idx, : num_choices_A_Bdevice[c_idx]
                ]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                c_idx = c_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return (
            graph,
            list(
                set(connected_device) | set(connected_Adevice) | set(connected_Bdevice)
            ),
        )

    def gen_graph_recursive(self, choices, **kwargs):
        region_verts = kwargs.get(&#34;region_verts&#34;)
        idx_inB = kwargs.get(&#34;idx_in_deviceB&#34;) + len(choices)
        idx_outB = list(set(choices) - set(idx_inB))
        outside_dist_inter = kwargs.get(&#34;end_outside_to_probe&#34;)
        vals = list(outside_dist_inter.items())
        min_inter = vals[0][0]
        max_inter = vals[-1][0]

        graph = []
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create connections between neurons in the same region
        if self.max_inter &gt; 0:

            self_connects_outside = np.random.choice(
                idx_outB,
                size=(
                    len(region_verts),
                    int(round(self.max_inter * len(region_verts))),
                ),
                replace=True,
            )
            num_choices_inter_outside = np.random.randint(
                int(round(self.min_inter * len(region_verts))),
                int(round(self.max_inter * len(region_verts))) + 1,
                dtype=np.int32,
                size=len(region_verts),
            )

            self_connects_inside = np.random.choice(
                idx_inB,
                size=(
                    len(region_verts),
                    int(round(max_inter * len(region_verts))),
                ),
                replace=True,
            )
            num_choices_inter_inside = np.random.randint(
                int(round(min_inter * len(region_verts))),
                int(round(max_inter * len(region_verts))) + 1,
                dtype=np.int32,
                size=len(region_verts),
            )

        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            if self.max_inter &gt; 0:
                self_connections = np.array(
                    list(set(self_connects_outside[i, : num_choices_inter_outside[i]])),
                    dtype=np.int32,
                )
                self_connections = np.append(
                    self_connections,
                    np.array(
                        list(
                            set(self_connects_inside[i, : num_choices_inter_inside[i]])
                        ),
                        dtype=np.int32,
                    ),
                )

                # Remove autaptic synapses
                self_connections = np.delete(
                    self_connections, np.where(self_connections == vert)
                )
                for val in self_connections:
                    if isinstance(val, float):
                        print(val, self_connections)
                        exit(-1)

            else:
                self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 1)

        use_mean = kwargs.get(&#34;use_mean&#34;, True)
        if max_depth &gt; 3:
            raise ValueError(
                &#34;max_depth must be less than 4 currently for recurrent no mean.&#34;
            )
        if (max_depth == 3) or (use_mean and (max_depth &gt; 1)):
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        if max_depth &gt;= 1:
            num_end = kwargs.get(&#34;N&#34;)
            out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
            num_start = kwargs.get(&#34;num_start&#34;)
            num_senders = kwargs.get(&#34;num_senders&#34;)

            total_samples = kwargs.get(&#34;total_samples&#34;)
            clt_start = kwargs.get(&#34;clt_start&#34;, 30)
            sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

            # Used to specify stats in relation to the recording device(s).
            num_start_probe = kwargs.get(&#34;num_start_probe&#34;, num_start)
            num_senders_probe = kwargs.get(&#34;num_senders_probe&#34;, num_senders)
            out_connections_dist_probe = kwargs.get(
                &#34;out_connections_dist_probe&#34;, out_connections_dist
            )
            num_end_probe = kwargs.get(&#34;num_end_probe&#34;, num_end)

            # Setup required regardless of the depth of the connection
            def fn_to_apply(k):
                # Ideally, here would use float if large var dist, and int otherwise.
                # Not a huge difference though
                # return expected_unique(num_end, k, do_round=False)
                return expected_unique(num_end_probe, k, do_round=True)

            # Gives dist of num outgoing connections from A
            # This tends towards normal distribution by CLT in most cases
            ab_dist = random_draw_dist(
                total_samples,
                out_connections_dist_probe,
                num_end_probe,
                apply_fn=False,
                keep_all=True,
                clt_start=clt_start,
                sub=sub,
            )

            ab_un_dist = OrderedDict()
            for k, v in ab_dist.items():
                ab_un_dist[k] = apply_fn_to_dist(v, fn_to_apply, sub=sub)
            final_dist = ab_un_dist

        if max_depth &gt;= 2:
            final_dist = OrderedDict()
            start_inter_dist = kwargs.get(&#34;start_inter_dist&#34;)
            end_inter_dist = kwargs.get(&#34;end_inter_dist&#34;)
            ab_dist_from_probe = kwargs.get(
                &#34;out_connections_dist_A&#34;, out_connections_dist_probe
            )

            start_mean = get_dist_mean(out_connections_dist)
            start_var = get_dist_var(out_connections_dist)
            ABprobe_mean = get_dist_mean(ab_dist_from_probe)
            ABprobe_var = get_dist_var(ab_dist_from_probe)

            start_inter_mean = get_dist_mean(start_inter_dist)
            start_inter_var = get_dist_var(start_inter_dist)
            end_inter_mean = get_dist_mean(end_inter_dist)
            end_inter_var = get_dist_var(end_inter_dist)

            # Raw AB cache
            ab_cache = OrderedDict()
            ab_cache[0] = OrderedDict()
            ab_cache[0][0] = 1.0
            start_max_val = max(list(out_connections_dist.keys()))
            for i in range(1, num_senders + 1):
                if i &lt; clt_start:
                    ab_cache[i] = convolution(
                        out_connections_dist, ab_cache[i - 1], sub=sub
                    )
                else:
                    ab_cache[i] = create_normal(
                        range((start_max_val * i) + 1),
                        start_mean * i,
                        start_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            # Probe AB cache
            ab_cache_from_a = OrderedDict()
            ab_cache_from_a[0] = OrderedDict()
            ab_cache_from_a[0][0] = 1.0
            start_max_val_a = max(list(ab_dist_from_probe.keys()))
            for i in range(1, num_senders_probe + 1):
                if i &lt; clt_start:
                    ab_cache_from_a[i] = convolution(
                        ab_dist_from_probe, ab_cache_from_a[i - 1], sub=sub
                    )
                else:
                    ab_cache_from_a[i] = create_normal(
                        range((start_max_val_a * i) + 1),
                        ABprobe_mean * i,
                        ABprobe_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            def fn_un_b(k):
                return expected_unique(num_end, k)

            ab_from_a_un = OrderedDict()
            for k, v in ab_cache_from_a.items():
                ab_from_a_un[k] = apply_fn_to_dist(v, fn_un_b, sub=sub)

            # Raw BB cache
            bb_cache = OrderedDict()
            bb_cache[0] = OrderedDict()
            bb_cache[0][0] = 1.0
            end_inter_max_val = max(list(end_inter_dist.keys()))
            for i in range(1, num_end + 1):
                if i &lt; clt_start:
                    bb_cache[i] = convolution(end_inter_dist, bb_cache[i - 1], sub=sub)
                else:
                    bb_cache[i] = create_normal(
                        range((end_inter_max_val * i) + 1),
                        end_inter_mean * i,
                        end_inter_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            # AAB calculation
            if total_samples &lt; clt_start:
                aa_dist = nfold_conv([start_inter_dist] * total_samples, sub=sub)
            else:
                max_val = max(list(start_inter_dist.keys()))
                aa_dist = create_normal(
                    range((max_val * total_samples) + 1),
                    start_inter_mean * total_samples,
                    start_inter_var * total_samples,
                    sub=sub,
                    interp_after=True,
                )
            aa_sender_dist = OrderedDict()

            aab_dist = OrderedDict()
            abb_dist = OrderedDict()

            for i in range(total_samples + 1):

                def inside_fn(x):
                    aa_sampled = expected_unique(num_start, x)
                    aa_new = expected_non_overlapping(
                        num_start, total_samples, aa_sampled
                    )
                    aa_senders = expected_overlapping(
                        num_start,
                        num_senders - i,
                        aa_new,
                    )
                    return int(round(aa_senders))

                aa_sender_dist[i] = apply_fn_to_dist(aa_dist, inside_fn, sub=sub)

                aab_dist[i] = combine_dists(
                    range((start_max_val * num_senders) + 1),
                    ab_cache,
                    aa_sender_dist[i],
                    sub=None,
                )
                # NOTE this needs to be extended to consider abbb dist for e.g.
                abb_dist[i] = combine_dists(
                    range((end_inter_max_val * num_end) + 1),
                    bb_cache,
                    ab_from_a_un[i],
                    sub=None,
                )
                aab_dist[i] = apply_fn_to_dist(aab_dist[i], fn_to_apply, sub=sub)
                abb_dist[i] = apply_fn_to_dist(abb_dist[i], fn_to_apply, sub=sub)

                aab_cache = OrderedDict()
                abb_cache = OrderedDict()

                for j in range(num_end_probe + 1):

                    def to_app(x):
                        return min(
                            j + round(expected_non_overlapping(num_end_probe, j, x)),
                            num_end_probe,
                        )

                    if j == num_end_probe:
                        to_add = OrderedDict()
                        to_add[num_end_probe] = 1
                        aab_cache[j] = to_add
                        abb_cache[j] = to_add
                    else:
                        aab_cache[j] = apply_fn_to_dist(aab_dist[i], to_app, sub=sub)
                        abb_cache[j] = apply_fn_to_dist(abb_dist[i], to_app, sub=sub)

                in_prog = OrderedDict()
                in_prog = combine_dists(
                    range(num_end_probe + 1), aab_cache, ab_un_dist[i], sub=None
                )
                in_prog = combine_dists(
                    range(num_end_probe + 1), abb_cache, in_prog, sub=None
                )
                final_dist[i] = in_prog

        # if max_depth &gt;= 3:
        #     recurrent_connections_dist = kwargs.get(&#34;recurrent_connections_dist&#34;)
        #     num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
        #     end_mean = get_dist_mean(recurrent_connections_dist)
        #     end_var = get_dist_var(recurrent_connections_dist)

        #     aaab_dist = OrderedDict()
        #     aabb_dist = OrderedDict()
        #     abbb_dist = OrderedDict()
        #     abab_dist = OrderedDict()

        #     aaab_cache = OrderedDict()
        #     aabb_cache = OrderedDict()
        #     abbb_cache = OrderedDict()
        #     abab_cache = OrderedDict()

        #     aa_cache = OrderedDict()
        #     aa_cache[0] = OrderedDict()
        #     aa_cache[0][0] = 1.0
        #     start_inter_max_val = max(list(start_inter_dist.keys()))
        #     for i in range(1, num_start + 1):
        #         if i &lt; clt_start:
        #             aa_cache[i] = convolution(
        #                 start_inter_dist, aa_cache[i - 1], sub=sub
        #             )
        #         else:
        #             aa_cache[i] = create_normal(
        #                 range((start_inter_max_val * i) + 1),
        #                 start_inter_mean * i,
        #                 start_inter_var * i,
        #                 sub=sub,
        #                 interp_after=True,
        #             )

        #     ba_cache = OrderedDict()
        #     ba_cache[0] = OrderedDict()
        #     ba_cache[0][0] = 1.0
        #     end_max_val = max(list(recurrent_connections_dist.keys()))
        #     for i in range(1, num_recurrent + 1):
        #         if i &lt; clt_start:
        #             ba_cache[i] = convolution(
        #                 recurrent_connections_dist, ba_cache[i - 1], sub=sub
        #             )
        #         else:
        #             ba_cache[i] = create_normal(
        #                 range((end_max_val * i) + 1),
        #                 end_mean * i,
        #                 end_var * i,
        #                 sub=sub,
        #                 interp_after=True,
        #             )

        #     ab_sender_dist = OrderedDict()

        #     def new_fn(x):
        #         return int(round(expected_overlapping(num_end, num_recurrent, x)))

        #     for k, v in ab_un_dist.items():
        #         ab_sender_dist[k] = apply_fn_to_dist(v, new_fn, sub=sub)

        #     aaa_sender_dist = OrderedDict()

        #     def new_fn(x):
        #         return int(round(expected_unique(num_start, x)))

        #     aa_un_dist = apply_fn_to_dist(aa_dist, new_fn, sub=sub)
        #     aaa_dist = combine_dists(
        #         range((num_start * start_inter_max_val * start_inter_max_val) + 1),
        #         aa_cache,
        #         aa_un_dist,
        #         sub=None,
        #     )

        #     aba_dist = OrderedDict()
        #     aba_sender_dist = OrderedDict()

        #     for i in range(total_samples + 1):

        #         def inside_fn(x):
        #             aaa_sampled = expected_unique(num_start, x)
        #             aaa_new = expected_non_overlapping(
        #                 num_start,
        #                 total_samples + get_dist_mean(aa_un_dist),
        #                 aaa_sampled,
        #             )
        #             aaa_senders = expected_overlapping(
        #                 num_start,
        #                 num_senders - get_dist_mean(aa_sender_dist[i]) - i,
        #                 aaa_new,
        #             )
        #             return int(round(aaa_senders))

        #         def new_fn_k(x):
        #             aba_sampled = expected_unique(num_start, x)
        #             aba_new = expected_non_overlapping(
        #                 num_start,
        #                 total_samples
        #                 + get_dist_mean(aa_un_dist)
        #                 + get_dist_mean(aaa_dist),
        #                 aba_sampled,
        #             )
        #             aba_senders = expected_overlapping(
        #                 num_start,
        #                 num_senders
        #                 - get_dist_mean(aa_sender_dist[i])
        #                 - get_dist_mean(aaa_sender_dist[i])
        #                 - i,
        #                 aba_new,
        #             )
        #             return int(round(aba_senders))

        #         aaa_sender_dist[i] = apply_fn_to_dist(aaa_dist, inside_fn, sub=sub)

        #         aba_dist[i] = combine_dists(
        #             range((num_recurrent * end_max_val) + 1),
        #             ba_cache,
        #             ab_sender_dist[i],
        #             sub=None,
        #         )
        #         aba_sender_dist[i] = apply_fn_to_dist(
        #             aba_dist[i], new_fn_k, sub=sub
        #         )

        #         aaab_dist[i] = combine_dists(
        #             range((start_max_val * num_senders) + 1),
        #             ab_cache,
        #             aaa_sender_dist[i],
        #             sub=None,
        #         )
        #         abab_dist[i] = combine_dists(
        #             range((start_max_val * num_senders) + 1),
        #             ab_cache,
        #             aba_sender_dist[i],
        #             sub=None,
        #         )
        #         aabb_dist[i] = combine_dists(
        #             range((end_inter_max_val * num_end) + 1),
        #             bb_cache,
        #             aab_dist[i],
        #             sub=None,
        #         )
        #         abbb_dist[i] = combine_dists(
        #             range((end_inter_max_val * num_end) + 1),
        #             bb_cache,
        #             abb_dist[i],
        #             sub=None,
        #         )

        #         for j in range(num_end + 1):

        #             def to_app(x):
        #                 return min(
        #                     j + round(expected_non_overlapping(num_end, j, x)),
        #                     num_end,
        #                 )

        #             if j == num_end:
        #                 to_add = OrderedDict()
        #                 to_add[num_end] = 1
        #                 aaab_cache[j] = to_add
        #                 aabb_cache[j] = to_add
        #                 abab_cache[j] = to_add
        #                 abbb_cache[j] = to_add
        #             else:
        #                 aaab_cache[j] = apply_fn_to_dist(
        #                     aaab_dist[i], to_app, sub=sub
        #                 )
        #                 aabb_cache[j] = apply_fn_to_dist(
        #                     aabb_dist[i], to_app, sub=sub
        #                 )
        #                 abab_cache[j] = apply_fn_to_dist(
        #                     abab_dist[i], to_app, sub=sub
        #                 )
        #                 abbb_cache[j] = apply_fn_to_dist(
        #                     abbb_dist[i], to_app, sub=sub
        #                 )

        #         in_prog = OrderedDict()
        #         in_prog = combine_dists(
        #             range(num_end + 1), aaab_cache, final_dist[i], sub=None
        #         )
        #         in_prog = combine_dists(
        #             range(num_end + 1), aabb_cache, in_prog, sub=None
        #         )
        #         in_prog = combine_dists(
        #             range(num_end + 1), abab_cache, in_prog, sub=None
        #         )
        #         in_prog = combine_dists(
        #             range(num_end + 1), abbb_cache, in_prog, sub=None
        #         )
        #         final_dist[i] = in_prog

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start_probe, num_senders_probe, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end_probe + 1), final_dist, prob_a_senders, sub=None
        )

        return ab_un_dist, weighted_dist

    @staticmethod
    def nfmt(start, *args):
        start = str(start) + &#34;: (&#34;
        for arg in args:
            start = start + nstr(arg, 5) + &#34;, &#34;
        start = start[:-2] + &#34;)&#34;

        return start


class MeanRecurrentConnectivity(RecurrentConnectivity):
    &#34;&#34;&#34;
    Similar to RecurrentConnectivity, but uses the mean instead of full dists.

    In this way, it is less accurate than the RecurrentConnectivity, but it will
    be faster to compute, and can be performed without knowledge of the variance
    of the underlying distribution.

    &#34;&#34;&#34;

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return MeanRecurrentConnectivity.static_expected_connections(
            num_samples, **kwargs
        )

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Distribution of connections from the mean.&#34;&#34;&#34;
        num_end = kwargs.get(&#34;N&#34;)
        num_connections = get_dist_mean(kwargs.get(&#34;out_connections_dist&#34;))
        num_recurrent_synapses = get_dist_mean(kwargs.get(&#34;recurrent_connections_dist&#34;))
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)
        num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
        inter_connections_start = get_dist_mean(kwargs.get(&#34;start_inter_dist&#34;))
        inter_connections_end = get_dist_mean(kwargs.get(&#34;end_inter_dist&#34;))
        total_samples = kwargs.get(&#34;total_samples&#34;)
        max_depth = kwargs.get(&#34;max_depth&#34;, 3)

        plist = []
        if max_depth &gt; 3:
            raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

        dists = OrderedDict()

        # Parse config information
        if max_depth &gt;= 1:
            num_start_probe = kwargs.get(&#34;num_start_probe&#34;, num_start)
            num_senders_probe = kwargs.get(&#34;num_senders_probe&#34;, num_senders)
            out_connects = kwargs.get(&#34;out_connections_dist_probe&#34;, None)
            num_senders_Aprobe_to_B = kwargs.get(&#34;num_senders_A&#34;, num_senders)
            num_connections_probe = (
                get_dist_mean(out_connects)
                if out_connects is not None
                else num_connections
            )
            num_end_probe = kwargs.get(&#34;num_end_probe&#34;, num_end)
        if max_depth &gt;= 2:
            out_connects_B = kwargs.get(&#34;out_connections_dist_B&#34;, None)
            num_connections_from_A_to_Bprobe = (
                get_dist_mean(out_connects_B)
                if out_connects_B is not None
                else num_connections
            )
            out_connects_A = kwargs.get(&#34;out_connections_dist_A&#34;, None)
            num_connections_from_Aprobe_to_B = (
                get_dist_mean(out_connects_A)
                if out_connects_A is not None
                else num_connections
            )

            num_senders_from_A_to_Bprobe = kwargs.get(&#34;num_senders_B&#34;, num_senders)

            inter_connects_start_probe_dist = kwargs.get(&#34;start_probe_to_outside&#34;, None)
            inter_connects_start_probe = (
                get_dist_mean(inter_connects_start_probe_dist)
                if inter_connects_start_probe_dist is not None
                else inter_connections_start
            )
            inter_connects_end_probe_dist = kwargs.get(&#34;end_outside_to_probe&#34;, None)
            inter_connects_end_probe = (
                get_dist_mean(inter_connects_end_probe_dist)
                if inter_connects_end_probe_dist is not None
                else inter_connections_end
            )

        # Do the actual calculation
        for num_sender_samples in range(total_samples + 1):
            final = 0
            if max_depth == 1:
                num_sender_direct = num_sender_samples
            else:
                num_sender_direct = expected_overlapping(
                    num_senders_Aprobe_to_B, num_senders_probe, num_sender_samples
                )
            if max_depth &gt;= 1:
                # AB
                ab = expected_unique(
                    num_end_probe, num_sender_direct * num_connections_probe
                )
                plist.append(ab)
                final = final + ab

            if max_depth &gt;= 2:

                # AAB
                aa_sampled = expected_unique(
                    num_start, total_samples * inter_connects_start_probe
                )
                aa_new = expected_non_overlapping(num_start, total_samples, aa_sampled)
                aa_senders = expected_overlapping(
                    num_start,
                    max(num_senders_from_A_to_Bprobe - num_sender_direct, 0),
                    aa_new,
                )
                aab_in_probe = expected_unique(
                    num_end_probe, aa_senders * num_connections_from_A_to_Bprobe
                )
                aab_less_ab_in_probe = expected_non_overlapping(
                    num_end_probe, final, aab_in_probe
                )
                plist.append(aab_in_probe)
                final = final + aab_less_ab_in_probe

                # ABB
                ab_full = expected_unique(
                    num_end, num_sender_samples * num_connections_from_Aprobe_to_B
                )
                abb_in_probe = expected_unique(
                    num_end_probe, ab_full * inter_connects_end_probe
                )
                # abb_in_probe = expected_overlapping(num_end, num_end_probe, abb_total)
                abb_less_prev = expected_non_overlapping(
                    num_end_probe, final, abb_in_probe
                )
                plist.append(abb_in_probe)
                final = final + abb_less_prev

            if max_depth &gt;= 3:
                # AAAB
                aaa_sampled = expected_unique(
                    num_start, aa_sampled * inter_connections_start
                )
                aaa_new = expected_non_overlapping(
                    num_start, aa_new + total_samples, aaa_sampled
                )
                num_senders_new_aaa = (
                    num_senders_from_A_to_Bprobe - aa_senders - num_sender_samples
                )
                aaa_senders = expected_overlapping(
                    num_start,
                    max(num_senders_new_aaa, 0),
                    aaa_new,
                )
                aaab_total = expected_unique(
                    num_end_probe, aaa_senders * num_connections_from_A_to_Bprobe
                )
                aaab_less_prev = expected_non_overlapping(
                    num_end_probe, final, aaab_total
                )
                plist.append(aaab_total)
                final = final + aaab_less_prev

                # AABB
                aab_total = expected_unique(num_end, aa_senders * num_connections)
                aab_less_ab = expected_non_overlapping(num_end, ab_full, aab_total)
                aabb_in_probe = expected_unique(
                    num_end_probe, aab_less_ab * inter_connects_end_probe
                )
                aabb_less_prev = expected_non_overlapping(
                    num_end_probe, final, aabb_in_probe
                )
                plist.append(aabb_in_probe)
                final = final + aabb_less_prev

                # ABAB
                ab_recurrent = expected_overlapping(num_end, num_recurrent, ab_full)
                aba = expected_unique(num_start, ab_recurrent * num_recurrent_synapses)
                aba_new = expected_non_overlapping(
                    num_start, aaa_new + aa_new + total_samples, aba
                )
                aba_senders_probe = num_senders_from_A_to_Bprobe - (
                    aaa_senders + aa_senders + num_sender_samples
                )
                aba_send_connections = expected_overlapping(
                    num_start,
                    max(aba_senders_probe, 0),
                    aba_new,
                )
                abab_total = expected_unique(
                    num_end_probe,
                    aba_send_connections * num_connections_from_A_to_Bprobe,
                )
                abab_less_prev = expected_non_overlapping(
                    num_end_probe, final, abab_total
                )
                plist.append(abab_total)
                final = final + abab_less_prev

                # ABBB
                abb_total = expected_unique(num_end, ab_full * inter_connections_end)
                abb_new = expected_non_overlapping(num_end, aab_total, abb_total)
                abbb_total = expected_unique(
                    num_end_probe, abb_new * inter_connects_end_probe
                )
                abbb_less_prev = expected_non_overlapping(
                    num_end_probe, final, abbb_total
                )
                plist.append(abbb_total)
                final = final + abbb_less_prev

            dists[num_sender_samples] = OrderedDict()
            dists[num_sender_samples][int(final)] = 1.0

        # Sums the above distributions to get the marginal
        prob_a_senders = OrderedDict()

        if max_depth == 1:
            for i in range(total_samples + 1):
                prob_a_senders[i] = float(
                    hypergeometric_pmf(
                        num_start_probe,
                        num_senders_probe,
                        total_samples,
                        i,
                    )
                )
        if max_depth &gt; 1:
            for i in range(total_samples + 1):
                prob_a_senders[i] = float(
                    hypergeometric_pmf(
                        num_start_probe,
                        num_senders_Aprobe_to_B,
                        total_samples,
                        i,
                    )
                )

        weighted_dist = combine_dists(range(num_end_probe + 1), dists, prob_a_senders)

        return dists, weighted_dist


class MatrixConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Connections from sparse matrices describing the connectivity.

    Attributes
    ----------
    self.ab : scipy.sparse.csr_matrix
        sparse matrix describing forward connections
    self.ba : scipy.sparse.csr_matrix
        sparse matrix describing backward connections
    self.aa : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.bb : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.to_use : list of bool
        Which matrices to use in the order [ab, ba, aa, bb]
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.ab = kwargs.get(&#34;ab&#34;)
        self.ba = kwargs.get(&#34;ba&#34;)
        self.aa = kwargs.get(&#34;aa&#34;)
        self.bb = kwargs.get(&#34;bb&#34;)
        self.to_use = kwargs.get(&#34;to_use&#34;, [True, True, True, True])

        self.load()

        self.num_a, self.num_b = self.ab.shape
        self.a_indices = np.array([i for i in range(self.num_a)])
        self.b_indices = np.array([i for i in range(self.num_b)])

    def load(self):
        &#34;&#34;&#34;Load the sparse matrices if they are paths to npz files.&#34;&#34;&#34;
        if self.to_use[0]:
            if isinstance(self.ab, str):
                self.ab = sparse.load_npz(self.ab)
        if self.to_use[1]:
            if isinstance(self.ba, str):
                self.ba = sparse.load_npz(self.ba)
        if self.to_use[2]:
            if isinstance(self.aa, str):
                self.aa = sparse.load_npz(self.aa)
        if self.to_use[3]:
            if isinstance(self.bb, str):
                self.bb = sparse.load_npz(self.bb)

    def create_connections(self):
        &#34;&#34;&#34;Create a simple graph representation from the matrices.&#34;&#34;&#34;
        self.graph = from_matrix(self.ab, self.ba, self.aa, self.bb, self.to_use)

    def compute_stats(self):
        &#34;&#34;&#34;
        Compute descriptive stats on the matrix connectivity.

        Returns
        -------
        dict
            Descriptive statistics on the matrix connectivity.

        &#34;&#34;&#34;
        args_dict = {}
        args_dict[&#34;N&#34;] = self.num_b
        args_dict[&#34;num_start&#34;] = self.num_a
        args_dict[&#34;num_end&#34;] = self.num_b

        zero_dist = OrderedDict()
        zero_dist[0] = 1.0

        if self.to_use[0]:
            ab_sum = np.squeeze(np.array(self.ab.sum(axis=1).astype(np.int64)))
            self.num_senders = np.count_nonzero(ab_sum)
            if self.num_senders != 0:
                args_dict[&#34;num_senders&#34;] = self.num_senders
                self.num_connections = OrderedDict()
                dist = np.bincount(ab_sum)
                for i in range(
                    int(np.amin(ab_sum[ab_sum != 0])), int(np.amax(ab_sum) + 1)
                ):
                    self.num_connections[i] = dist[i] / float(self.num_senders)
                args_dict[&#34;out_connections_dist&#34;] = self.num_connections
            else:
                args_dict[&#34;num_senders&#34;] = 0
                args_dict[&#34;out_connections_dist&#34;] = zero_dist
        if self.to_use[1]:
            ba_sum = np.squeeze(np.array(self.ba.sum(axis=1).astype(np.int64)))
            self.num_recurrent = np.count_nonzero(ba_sum)
            args_dict[&#34;num_recurrent&#34;] = self.num_recurrent
            if self.num_recurrent != 0:
                dist = np.bincount(ba_sum)
                self.num_recurrent_connections = OrderedDict()
                for i in range(
                    int(np.amin(ba_sum[ba_sum != 0])), int(np.amax(ba_sum) + 1)
                ):
                    self.num_recurrent_connections[i] = dist[i] / float(
                        self.num_recurrent
                    )
                args_dict[&#34;recurrent_connections_dist&#34;] = self.num_recurrent_connections
            else:
                args_dict[&#34;num_recurrent&#34;] = 0
                args_dict[&#34;recurrent_connections_dist&#34;] = zero_dist
        if self.to_use[2]:
            aa_sum = np.squeeze(np.array(self.aa.sum(axis=1).astype(np.int64)))
            dist = np.bincount(aa_sum)
            total = aa_sum.shape[0]
            self.inter_connections_start = OrderedDict()
            for i in range(int(np.amin(aa_sum)), int(np.amax(aa_sum) + 1)):
                self.inter_connections_start[i] = dist[i] / float(total)
            args_dict[&#34;start_inter_dist&#34;] = self.inter_connections_start
        if self.to_use[3]:
            bb_sum = np.squeeze(np.array(self.bb.sum(axis=1).astype(np.int64)))
            dist = np.bincount(bb_sum)
            total = bb_sum.shape[0]
            self.inter_connections_end = OrderedDict()
            for i in range(int(np.amin(bb_sum)), int(np.amax(bb_sum) + 1)):
                self.inter_connections_end[i] = dist[i] / float(total)
            args_dict[&#34;end_inter_dist&#34;] = self.inter_connections_end

        return args_dict

    def compute_probe_stats(self, A_idx, B_idx):
        &#34;&#34;&#34;
        Compute descriptive stats on the matrix connectivity relative to device.

        Parameters
        ----------
        A_idx : list of int
            The list of integers inside the recording device in region A.
        B_idx : list of int
            The list of integers inside the recording device in region B.

        Returns
        -------
        MatrixConnectivity
            The subsampled connectivity matrix.
        dict
            Descriptive statistics on the matrix connectivity relative to device.

        &#34;&#34;&#34;
        subsampled_to_probes_only = self.subsample(A_idx, B_idx)
        subsampled_to_probes_A = self.subsample(A_idx, None)
        subsampled_to_probes_B = self.subsample(None, B_idx)

        only_probes = subsampled_to_probes_only.compute_stats()
        only_A = subsampled_to_probes_A.compute_stats()
        only_B = subsampled_to_probes_B.compute_stats()

        inter_probes = {}
        # A in probe to rest of A
        if self.to_use[2]:
            aa_subbed = self.aa[A_idx, :]
            a_sum = np.squeeze(np.array(aa_subbed.sum(axis=1).astype(np.int64)))
            dist = np.bincount(a_sum)
            total = a_sum.shape[0]
            inter_connections_start = OrderedDict()
            for i in range(int(np.amin(a_sum)), int(np.amax(a_sum) + 1)):
                inter_connections_start[i] = dist[i] / float(total)
            inter_probes[&#34;start_probe_to_outside&#34;] = inter_connections_start

        # rest of B to B in probe
        if self.to_use[3]:
            bb_subbed = self.bb[:, B_idx]
            b_sum = np.squeeze(np.array(bb_subbed.sum(axis=1).astype(np.int64)))
            dist = np.bincount(b_sum)
            total = b_sum.shape[0]
            inter_connections_start = OrderedDict()
            for i in range(int(np.amin(b_sum)), int(np.amax(b_sum) + 1)):
                inter_connections_start[i] = dist[i] / float(total)
            inter_probes[&#34;end_outside_to_probe&#34;] = inter_connections_start

        results = dict(
            probes=subsampled_to_probes_only,
            A=subsampled_to_probes_A,
            B=subsampled_to_probes_B,
            stats=only_probes,
            inter=inter_probes,
            A_stats=only_A,
            B_stats=only_B,
        )
        return results

    def expected_connections(self, total_samples, max_depth):
        &#34;&#34;&#34;Call to static_expected_connections.&#34;&#34;&#34;
        args_dict = self.compute_stats()
        args_dict[&#34;total_samples&#34;] = total_samples
        args_dict[&#34;max_depth&#34;] = max_depth
        return MatrixConnectivity.static_expected_connections(**args_dict)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Calls RecurrentConnectivity with the matrix stats.&#34;&#34;&#34;
        if kwargs.get(&#34;mean_estimate&#34;, False) is True:
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        else:
            return RecurrentConnectivity.static_expected_connections(**kwargs)

    def subsample(self, num_a, num_b):
        &#34;&#34;&#34;
        Subsample the connectivity matrices.

        Parameters
        ----------
        num_a : int or list
            The number of indices to randomly select
            OR the actual indices
            must be the same type as num_b
        num_b : int or list
            The number of indices to randomly select
            OR the actual indices
            must be the same type as num_a

        Returns
        -------
        MatrixConnectivity
            The subsampled connectivity matrix.

        &#34;&#34;&#34;
        if type(num_a) is int:
            a_samples, b_samples = self.gen_random_samples((num_a, num_b))
        else:
            a_samples, b_samples = num_a, num_b

        if self.to_use[0]:
            if a_samples is None:
                ab = self.ab[:, b_samples]
            elif b_samples is None:
                ab = self.ab[a_samples, :]
            else:
                ab_grid = np.ix_(a_samples, b_samples)
                ab = self.ab[ab_grid]
        if self.to_use[1]:
            if a_samples is None:
                ba = self.ba[b_samples, :]
            elif b_samples is None:
                ba = self.ba[:, a_samples]
            else:
                ba_grid = np.ix_(b_samples, a_samples)
                ba = self.ba[ba_grid]
        if self.to_use[2]:
            if a_samples is not None:
                aa_grid = np.ix_(a_samples, a_samples)
                aa = self.aa[aa_grid]
            else:
                aa = self.aa
        if self.to_use[3]:
            if b_samples is not None:
                bb_grid = np.ix_(b_samples, b_samples)
                bb = self.bb[bb_grid]
            else:
                bb = self.bb

        new_mc = MatrixConnectivity(
            aa=aa,
            bb=bb,
            ab=ab,
            ba=ba,
            to_use=self.to_use,
        )

        return new_mc

    def gen_random_samples(self, num_sampled, zeroed=True):
        &#34;&#34;&#34;Generate random sample indices from both regions.&#34;&#34;&#34;
        start = np.random.choice(self.a_indices, size=num_sampled[0], replace=False)
        end = np.random.choice(self.b_indices, size=num_sampled[1], replace=False)
        if not zeroed:
            end = end + self.num_a

        return start, end

    def __str__(self):
        return f&#34;AA: {self.aa.shape}, BB: {self.bb.shape}, AB: {self.ab.shape}, BA: {self.ba.shape}&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="neuroconnect.connectivity_patterns.get_by_name"><code class="name flex">
<span>def <span class="ident">get_by_name</span></span>(<span>name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve a connection strategy by name.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_by_name(name):
    &#34;&#34;&#34;Retrieve a connection strategy by name.&#34;&#34;&#34;
    classes = {
        &#34;recurrent_connectivity&#34;: RecurrentConnectivity,
        &#34;matrix_connectivity&#34;: MatrixConnectivity,
        &#34;mean_connectivity&#34;: MeanRecurrentConnectivity,
        &#34;unique_connectivity&#34;: UniqueConnectivity,
    }
    return classes[name]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy"><code class="flex name class">
<span>class <span class="ident">ConnectionStrategy</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract class to describe the connection strategy between two regions.</p>
<p>Must define:
1. create_connections:
How to form connections between neurons in the regions.
Expected to return graph, connections
2. expected_connections:
How many connections would be expected between neurons in the regions.
3. static_expected_connections:
An interface into expected_connections that can be statically called.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConnectionStrategy(ABC):
    &#34;&#34;&#34;
    Abstract class to describe the connection strategy between two regions.

    Must define:
    1. create_connections:
        How to form connections between neurons in the regions.
        Expected to return graph, connections
    2. expected_connections:
        How many connections would be expected between neurons in the regions.
    3. static_expected_connections:
        An interface into expected_connections that can be statically called.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        super().__init__()
        pass

    @abstractmethod
    def create_connections(self, *args, **kwargs):
        &#34;&#34;&#34;How to form connections between neurons in the regions.&#34;&#34;&#34;
        pass

    @abstractmethod
    def expected_connections(self, *args, **kwargs):
        &#34;&#34;&#34;The distribution of connections.&#34;&#34;&#34;
        pass

    @staticmethod
    @abstractmethod
    def static_expected_connections(*args, **kwargs):
        &#34;&#34;&#34;The distribution of connections called statically.&#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.MatrixConnectivity" href="#neuroconnect.connectivity_patterns.MatrixConnectivity">MatrixConnectivity</a></li>
<li><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></li>
<li><a title="neuroconnect.connectivity_patterns.UniqueConnectivity" href="#neuroconnect.connectivity_patterns.UniqueConnectivity">UniqueConnectivity</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>The distribution of connections called statically.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@abstractmethod
def static_expected_connections(*args, **kwargs):
    &#34;&#34;&#34;The distribution of connections called statically.&#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>How to form connections between neurons in the regions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def create_connections(self, *args, **kwargs):
    &#34;&#34;&#34;How to form connections between neurons in the regions.&#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>The distribution of connections.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def expected_connections(self, *args, **kwargs):
    &#34;&#34;&#34;The distribution of connections.&#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity"><code class="flex name class">
<span>class <span class="ident">MatrixConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Connections from sparse matrices describing the connectivity.</p>
<h2 id="attributes">Attributes</h2>
<p>self.ab : scipy.sparse.csr_matrix
sparse matrix describing forward connections
self.ba : scipy.sparse.csr_matrix
sparse matrix describing backward connections
self.aa : scipy.sparse.csr_matrix
sparse matrix describing self connections
self.bb : scipy.sparse.csr_matrix
sparse matrix describing self connections
self.to_use : list of bool
Which matrices to use in the order [ab, ba, aa, bb]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MatrixConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Connections from sparse matrices describing the connectivity.

    Attributes
    ----------
    self.ab : scipy.sparse.csr_matrix
        sparse matrix describing forward connections
    self.ba : scipy.sparse.csr_matrix
        sparse matrix describing backward connections
    self.aa : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.bb : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.to_use : list of bool
        Which matrices to use in the order [ab, ba, aa, bb]
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.ab = kwargs.get(&#34;ab&#34;)
        self.ba = kwargs.get(&#34;ba&#34;)
        self.aa = kwargs.get(&#34;aa&#34;)
        self.bb = kwargs.get(&#34;bb&#34;)
        self.to_use = kwargs.get(&#34;to_use&#34;, [True, True, True, True])

        self.load()

        self.num_a, self.num_b = self.ab.shape
        self.a_indices = np.array([i for i in range(self.num_a)])
        self.b_indices = np.array([i for i in range(self.num_b)])

    def load(self):
        &#34;&#34;&#34;Load the sparse matrices if they are paths to npz files.&#34;&#34;&#34;
        if self.to_use[0]:
            if isinstance(self.ab, str):
                self.ab = sparse.load_npz(self.ab)
        if self.to_use[1]:
            if isinstance(self.ba, str):
                self.ba = sparse.load_npz(self.ba)
        if self.to_use[2]:
            if isinstance(self.aa, str):
                self.aa = sparse.load_npz(self.aa)
        if self.to_use[3]:
            if isinstance(self.bb, str):
                self.bb = sparse.load_npz(self.bb)

    def create_connections(self):
        &#34;&#34;&#34;Create a simple graph representation from the matrices.&#34;&#34;&#34;
        self.graph = from_matrix(self.ab, self.ba, self.aa, self.bb, self.to_use)

    def compute_stats(self):
        &#34;&#34;&#34;
        Compute descriptive stats on the matrix connectivity.

        Returns
        -------
        dict
            Descriptive statistics on the matrix connectivity.

        &#34;&#34;&#34;
        args_dict = {}
        args_dict[&#34;N&#34;] = self.num_b
        args_dict[&#34;num_start&#34;] = self.num_a
        args_dict[&#34;num_end&#34;] = self.num_b

        zero_dist = OrderedDict()
        zero_dist[0] = 1.0

        if self.to_use[0]:
            ab_sum = np.squeeze(np.array(self.ab.sum(axis=1).astype(np.int64)))
            self.num_senders = np.count_nonzero(ab_sum)
            if self.num_senders != 0:
                args_dict[&#34;num_senders&#34;] = self.num_senders
                self.num_connections = OrderedDict()
                dist = np.bincount(ab_sum)
                for i in range(
                    int(np.amin(ab_sum[ab_sum != 0])), int(np.amax(ab_sum) + 1)
                ):
                    self.num_connections[i] = dist[i] / float(self.num_senders)
                args_dict[&#34;out_connections_dist&#34;] = self.num_connections
            else:
                args_dict[&#34;num_senders&#34;] = 0
                args_dict[&#34;out_connections_dist&#34;] = zero_dist
        if self.to_use[1]:
            ba_sum = np.squeeze(np.array(self.ba.sum(axis=1).astype(np.int64)))
            self.num_recurrent = np.count_nonzero(ba_sum)
            args_dict[&#34;num_recurrent&#34;] = self.num_recurrent
            if self.num_recurrent != 0:
                dist = np.bincount(ba_sum)
                self.num_recurrent_connections = OrderedDict()
                for i in range(
                    int(np.amin(ba_sum[ba_sum != 0])), int(np.amax(ba_sum) + 1)
                ):
                    self.num_recurrent_connections[i] = dist[i] / float(
                        self.num_recurrent
                    )
                args_dict[&#34;recurrent_connections_dist&#34;] = self.num_recurrent_connections
            else:
                args_dict[&#34;num_recurrent&#34;] = 0
                args_dict[&#34;recurrent_connections_dist&#34;] = zero_dist
        if self.to_use[2]:
            aa_sum = np.squeeze(np.array(self.aa.sum(axis=1).astype(np.int64)))
            dist = np.bincount(aa_sum)
            total = aa_sum.shape[0]
            self.inter_connections_start = OrderedDict()
            for i in range(int(np.amin(aa_sum)), int(np.amax(aa_sum) + 1)):
                self.inter_connections_start[i] = dist[i] / float(total)
            args_dict[&#34;start_inter_dist&#34;] = self.inter_connections_start
        if self.to_use[3]:
            bb_sum = np.squeeze(np.array(self.bb.sum(axis=1).astype(np.int64)))
            dist = np.bincount(bb_sum)
            total = bb_sum.shape[0]
            self.inter_connections_end = OrderedDict()
            for i in range(int(np.amin(bb_sum)), int(np.amax(bb_sum) + 1)):
                self.inter_connections_end[i] = dist[i] / float(total)
            args_dict[&#34;end_inter_dist&#34;] = self.inter_connections_end

        return args_dict

    def compute_probe_stats(self, A_idx, B_idx):
        &#34;&#34;&#34;
        Compute descriptive stats on the matrix connectivity relative to device.

        Parameters
        ----------
        A_idx : list of int
            The list of integers inside the recording device in region A.
        B_idx : list of int
            The list of integers inside the recording device in region B.

        Returns
        -------
        MatrixConnectivity
            The subsampled connectivity matrix.
        dict
            Descriptive statistics on the matrix connectivity relative to device.

        &#34;&#34;&#34;
        subsampled_to_probes_only = self.subsample(A_idx, B_idx)
        subsampled_to_probes_A = self.subsample(A_idx, None)
        subsampled_to_probes_B = self.subsample(None, B_idx)

        only_probes = subsampled_to_probes_only.compute_stats()
        only_A = subsampled_to_probes_A.compute_stats()
        only_B = subsampled_to_probes_B.compute_stats()

        inter_probes = {}
        # A in probe to rest of A
        if self.to_use[2]:
            aa_subbed = self.aa[A_idx, :]
            a_sum = np.squeeze(np.array(aa_subbed.sum(axis=1).astype(np.int64)))
            dist = np.bincount(a_sum)
            total = a_sum.shape[0]
            inter_connections_start = OrderedDict()
            for i in range(int(np.amin(a_sum)), int(np.amax(a_sum) + 1)):
                inter_connections_start[i] = dist[i] / float(total)
            inter_probes[&#34;start_probe_to_outside&#34;] = inter_connections_start

        # rest of B to B in probe
        if self.to_use[3]:
            bb_subbed = self.bb[:, B_idx]
            b_sum = np.squeeze(np.array(bb_subbed.sum(axis=1).astype(np.int64)))
            dist = np.bincount(b_sum)
            total = b_sum.shape[0]
            inter_connections_start = OrderedDict()
            for i in range(int(np.amin(b_sum)), int(np.amax(b_sum) + 1)):
                inter_connections_start[i] = dist[i] / float(total)
            inter_probes[&#34;end_outside_to_probe&#34;] = inter_connections_start

        results = dict(
            probes=subsampled_to_probes_only,
            A=subsampled_to_probes_A,
            B=subsampled_to_probes_B,
            stats=only_probes,
            inter=inter_probes,
            A_stats=only_A,
            B_stats=only_B,
        )
        return results

    def expected_connections(self, total_samples, max_depth):
        &#34;&#34;&#34;Call to static_expected_connections.&#34;&#34;&#34;
        args_dict = self.compute_stats()
        args_dict[&#34;total_samples&#34;] = total_samples
        args_dict[&#34;max_depth&#34;] = max_depth
        return MatrixConnectivity.static_expected_connections(**args_dict)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Calls RecurrentConnectivity with the matrix stats.&#34;&#34;&#34;
        if kwargs.get(&#34;mean_estimate&#34;, False) is True:
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        else:
            return RecurrentConnectivity.static_expected_connections(**kwargs)

    def subsample(self, num_a, num_b):
        &#34;&#34;&#34;
        Subsample the connectivity matrices.

        Parameters
        ----------
        num_a : int or list
            The number of indices to randomly select
            OR the actual indices
            must be the same type as num_b
        num_b : int or list
            The number of indices to randomly select
            OR the actual indices
            must be the same type as num_a

        Returns
        -------
        MatrixConnectivity
            The subsampled connectivity matrix.

        &#34;&#34;&#34;
        if type(num_a) is int:
            a_samples, b_samples = self.gen_random_samples((num_a, num_b))
        else:
            a_samples, b_samples = num_a, num_b

        if self.to_use[0]:
            if a_samples is None:
                ab = self.ab[:, b_samples]
            elif b_samples is None:
                ab = self.ab[a_samples, :]
            else:
                ab_grid = np.ix_(a_samples, b_samples)
                ab = self.ab[ab_grid]
        if self.to_use[1]:
            if a_samples is None:
                ba = self.ba[b_samples, :]
            elif b_samples is None:
                ba = self.ba[:, a_samples]
            else:
                ba_grid = np.ix_(b_samples, a_samples)
                ba = self.ba[ba_grid]
        if self.to_use[2]:
            if a_samples is not None:
                aa_grid = np.ix_(a_samples, a_samples)
                aa = self.aa[aa_grid]
            else:
                aa = self.aa
        if self.to_use[3]:
            if b_samples is not None:
                bb_grid = np.ix_(b_samples, b_samples)
                bb = self.bb[bb_grid]
            else:
                bb = self.bb

        new_mc = MatrixConnectivity(
            aa=aa,
            bb=bb,
            ab=ab,
            ba=ba,
            to_use=self.to_use,
        )

        return new_mc

    def gen_random_samples(self, num_sampled, zeroed=True):
        &#34;&#34;&#34;Generate random sample indices from both regions.&#34;&#34;&#34;
        start = np.random.choice(self.a_indices, size=num_sampled[0], replace=False)
        end = np.random.choice(self.b_indices, size=num_sampled[1], replace=False)
        if not zeroed:
            end = end + self.num_a

        return start, end

    def __str__(self):
        return f&#34;AA: {self.aa.shape}, BB: {self.bb.shape}, AB: {self.ab.shape}, BA: {self.ba.shape}&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls RecurrentConnectivity with the matrix stats.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Calls RecurrentConnectivity with the matrix stats.&#34;&#34;&#34;
    if kwargs.get(&#34;mean_estimate&#34;, False) is True:
        return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
    else:
        return RecurrentConnectivity.static_expected_connections(**kwargs)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.compute_probe_stats"><code class="name flex">
<span>def <span class="ident">compute_probe_stats</span></span>(<span>self, A_idx, B_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute descriptive stats on the matrix connectivity relative to device.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>A_idx</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>The list of integers inside the recording device in region A.</dd>
<dt><strong><code>B_idx</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>The list of integers inside the recording device in region B.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity" href="#neuroconnect.connectivity_patterns.MatrixConnectivity">MatrixConnectivity</a></code></dt>
<dd>The subsampled connectivity matrix.</dd>
<dt><code>dict</code></dt>
<dd>Descriptive statistics on the matrix connectivity relative to device.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_probe_stats(self, A_idx, B_idx):
    &#34;&#34;&#34;
    Compute descriptive stats on the matrix connectivity relative to device.

    Parameters
    ----------
    A_idx : list of int
        The list of integers inside the recording device in region A.
    B_idx : list of int
        The list of integers inside the recording device in region B.

    Returns
    -------
    MatrixConnectivity
        The subsampled connectivity matrix.
    dict
        Descriptive statistics on the matrix connectivity relative to device.

    &#34;&#34;&#34;
    subsampled_to_probes_only = self.subsample(A_idx, B_idx)
    subsampled_to_probes_A = self.subsample(A_idx, None)
    subsampled_to_probes_B = self.subsample(None, B_idx)

    only_probes = subsampled_to_probes_only.compute_stats()
    only_A = subsampled_to_probes_A.compute_stats()
    only_B = subsampled_to_probes_B.compute_stats()

    inter_probes = {}
    # A in probe to rest of A
    if self.to_use[2]:
        aa_subbed = self.aa[A_idx, :]
        a_sum = np.squeeze(np.array(aa_subbed.sum(axis=1).astype(np.int64)))
        dist = np.bincount(a_sum)
        total = a_sum.shape[0]
        inter_connections_start = OrderedDict()
        for i in range(int(np.amin(a_sum)), int(np.amax(a_sum) + 1)):
            inter_connections_start[i] = dist[i] / float(total)
        inter_probes[&#34;start_probe_to_outside&#34;] = inter_connections_start

    # rest of B to B in probe
    if self.to_use[3]:
        bb_subbed = self.bb[:, B_idx]
        b_sum = np.squeeze(np.array(bb_subbed.sum(axis=1).astype(np.int64)))
        dist = np.bincount(b_sum)
        total = b_sum.shape[0]
        inter_connections_start = OrderedDict()
        for i in range(int(np.amin(b_sum)), int(np.amax(b_sum) + 1)):
            inter_connections_start[i] = dist[i] / float(total)
        inter_probes[&#34;end_outside_to_probe&#34;] = inter_connections_start

    results = dict(
        probes=subsampled_to_probes_only,
        A=subsampled_to_probes_A,
        B=subsampled_to_probes_B,
        stats=only_probes,
        inter=inter_probes,
        A_stats=only_A,
        B_stats=only_B,
    )
    return results</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.compute_stats"><code class="name flex">
<span>def <span class="ident">compute_stats</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute descriptive stats on the matrix connectivity.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Descriptive statistics on the matrix connectivity.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_stats(self):
    &#34;&#34;&#34;
    Compute descriptive stats on the matrix connectivity.

    Returns
    -------
    dict
        Descriptive statistics on the matrix connectivity.

    &#34;&#34;&#34;
    args_dict = {}
    args_dict[&#34;N&#34;] = self.num_b
    args_dict[&#34;num_start&#34;] = self.num_a
    args_dict[&#34;num_end&#34;] = self.num_b

    zero_dist = OrderedDict()
    zero_dist[0] = 1.0

    if self.to_use[0]:
        ab_sum = np.squeeze(np.array(self.ab.sum(axis=1).astype(np.int64)))
        self.num_senders = np.count_nonzero(ab_sum)
        if self.num_senders != 0:
            args_dict[&#34;num_senders&#34;] = self.num_senders
            self.num_connections = OrderedDict()
            dist = np.bincount(ab_sum)
            for i in range(
                int(np.amin(ab_sum[ab_sum != 0])), int(np.amax(ab_sum) + 1)
            ):
                self.num_connections[i] = dist[i] / float(self.num_senders)
            args_dict[&#34;out_connections_dist&#34;] = self.num_connections
        else:
            args_dict[&#34;num_senders&#34;] = 0
            args_dict[&#34;out_connections_dist&#34;] = zero_dist
    if self.to_use[1]:
        ba_sum = np.squeeze(np.array(self.ba.sum(axis=1).astype(np.int64)))
        self.num_recurrent = np.count_nonzero(ba_sum)
        args_dict[&#34;num_recurrent&#34;] = self.num_recurrent
        if self.num_recurrent != 0:
            dist = np.bincount(ba_sum)
            self.num_recurrent_connections = OrderedDict()
            for i in range(
                int(np.amin(ba_sum[ba_sum != 0])), int(np.amax(ba_sum) + 1)
            ):
                self.num_recurrent_connections[i] = dist[i] / float(
                    self.num_recurrent
                )
            args_dict[&#34;recurrent_connections_dist&#34;] = self.num_recurrent_connections
        else:
            args_dict[&#34;num_recurrent&#34;] = 0
            args_dict[&#34;recurrent_connections_dist&#34;] = zero_dist
    if self.to_use[2]:
        aa_sum = np.squeeze(np.array(self.aa.sum(axis=1).astype(np.int64)))
        dist = np.bincount(aa_sum)
        total = aa_sum.shape[0]
        self.inter_connections_start = OrderedDict()
        for i in range(int(np.amin(aa_sum)), int(np.amax(aa_sum) + 1)):
            self.inter_connections_start[i] = dist[i] / float(total)
        args_dict[&#34;start_inter_dist&#34;] = self.inter_connections_start
    if self.to_use[3]:
        bb_sum = np.squeeze(np.array(self.bb.sum(axis=1).astype(np.int64)))
        dist = np.bincount(bb_sum)
        total = bb_sum.shape[0]
        self.inter_connections_end = OrderedDict()
        for i in range(int(np.amin(bb_sum)), int(np.amax(bb_sum) + 1)):
            self.inter_connections_end[i] = dist[i] / float(total)
        args_dict[&#34;end_inter_dist&#34;] = self.inter_connections_end

    return args_dict</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a simple graph representation from the matrices.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_connections(self):
    &#34;&#34;&#34;Create a simple graph representation from the matrices.&#34;&#34;&#34;
    self.graph = from_matrix(self.ab, self.ba, self.aa, self.bb, self.to_use)</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, total_samples, max_depth)</span>
</code></dt>
<dd>
<div class="desc"><p>Call to static_expected_connections.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expected_connections(self, total_samples, max_depth):
    &#34;&#34;&#34;Call to static_expected_connections.&#34;&#34;&#34;
    args_dict = self.compute_stats()
    args_dict[&#34;total_samples&#34;] = total_samples
    args_dict[&#34;max_depth&#34;] = max_depth
    return MatrixConnectivity.static_expected_connections(**args_dict)</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.gen_random_samples"><code class="name flex">
<span>def <span class="ident">gen_random_samples</span></span>(<span>self, num_sampled, zeroed=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate random sample indices from both regions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_random_samples(self, num_sampled, zeroed=True):
    &#34;&#34;&#34;Generate random sample indices from both regions.&#34;&#34;&#34;
    start = np.random.choice(self.a_indices, size=num_sampled[0], replace=False)
    end = np.random.choice(self.b_indices, size=num_sampled[1], replace=False)
    if not zeroed:
        end = end + self.num_a

    return start, end</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the sparse matrices if they are paths to npz files.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(self):
    &#34;&#34;&#34;Load the sparse matrices if they are paths to npz files.&#34;&#34;&#34;
    if self.to_use[0]:
        if isinstance(self.ab, str):
            self.ab = sparse.load_npz(self.ab)
    if self.to_use[1]:
        if isinstance(self.ba, str):
            self.ba = sparse.load_npz(self.ba)
    if self.to_use[2]:
        if isinstance(self.aa, str):
            self.aa = sparse.load_npz(self.aa)
    if self.to_use[3]:
        if isinstance(self.bb, str):
            self.bb = sparse.load_npz(self.bb)</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.subsample"><code class="name flex">
<span>def <span class="ident">subsample</span></span>(<span>self, num_a, num_b)</span>
</code></dt>
<dd>
<div class="desc"><p>Subsample the connectivity matrices.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>num_a</code></strong> :&ensp;<code>int</code> or <code>list</code></dt>
<dd>The number of indices to randomly select
OR the actual indices
must be the same type as num_b</dd>
<dt><strong><code>num_b</code></strong> :&ensp;<code>int</code> or <code>list</code></dt>
<dd>The number of indices to randomly select
OR the actual indices
must be the same type as num_a</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity" href="#neuroconnect.connectivity_patterns.MatrixConnectivity">MatrixConnectivity</a></code></dt>
<dd>The subsampled connectivity matrix.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subsample(self, num_a, num_b):
    &#34;&#34;&#34;
    Subsample the connectivity matrices.

    Parameters
    ----------
    num_a : int or list
        The number of indices to randomly select
        OR the actual indices
        must be the same type as num_b
    num_b : int or list
        The number of indices to randomly select
        OR the actual indices
        must be the same type as num_a

    Returns
    -------
    MatrixConnectivity
        The subsampled connectivity matrix.

    &#34;&#34;&#34;
    if type(num_a) is int:
        a_samples, b_samples = self.gen_random_samples((num_a, num_b))
    else:
        a_samples, b_samples = num_a, num_b

    if self.to_use[0]:
        if a_samples is None:
            ab = self.ab[:, b_samples]
        elif b_samples is None:
            ab = self.ab[a_samples, :]
        else:
            ab_grid = np.ix_(a_samples, b_samples)
            ab = self.ab[ab_grid]
    if self.to_use[1]:
        if a_samples is None:
            ba = self.ba[b_samples, :]
        elif b_samples is None:
            ba = self.ba[:, a_samples]
        else:
            ba_grid = np.ix_(b_samples, a_samples)
            ba = self.ba[ba_grid]
    if self.to_use[2]:
        if a_samples is not None:
            aa_grid = np.ix_(a_samples, a_samples)
            aa = self.aa[aa_grid]
        else:
            aa = self.aa
    if self.to_use[3]:
        if b_samples is not None:
            bb_grid = np.ix_(b_samples, b_samples)
            bb = self.bb[bb_grid]
        else:
            bb = self.bb

    new_mc = MatrixConnectivity(
        aa=aa,
        bb=bb,
        ab=ab,
        ba=ba,
        to_use=self.to_use,
    )

    return new_mc</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity"><code class="flex name class">
<span>class <span class="ident">MeanRecurrentConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Similar to RecurrentConnectivity, but uses the mean instead of full dists.</p>
<p>In this way, it is less accurate than the RecurrentConnectivity, but it will
be faster to compute, and can be performed without knowledge of the variance
of the underlying distribution.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MeanRecurrentConnectivity(RecurrentConnectivity):
    &#34;&#34;&#34;
    Similar to RecurrentConnectivity, but uses the mean instead of full dists.

    In this way, it is less accurate than the RecurrentConnectivity, but it will
    be faster to compute, and can be performed without knowledge of the variance
    of the underlying distribution.

    &#34;&#34;&#34;

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return MeanRecurrentConnectivity.static_expected_connections(
            num_samples, **kwargs
        )

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Distribution of connections from the mean.&#34;&#34;&#34;
        num_end = kwargs.get(&#34;N&#34;)
        num_connections = get_dist_mean(kwargs.get(&#34;out_connections_dist&#34;))
        num_recurrent_synapses = get_dist_mean(kwargs.get(&#34;recurrent_connections_dist&#34;))
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)
        num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
        inter_connections_start = get_dist_mean(kwargs.get(&#34;start_inter_dist&#34;))
        inter_connections_end = get_dist_mean(kwargs.get(&#34;end_inter_dist&#34;))
        total_samples = kwargs.get(&#34;total_samples&#34;)
        max_depth = kwargs.get(&#34;max_depth&#34;, 3)

        plist = []
        if max_depth &gt; 3:
            raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

        dists = OrderedDict()

        # Parse config information
        if max_depth &gt;= 1:
            num_start_probe = kwargs.get(&#34;num_start_probe&#34;, num_start)
            num_senders_probe = kwargs.get(&#34;num_senders_probe&#34;, num_senders)
            out_connects = kwargs.get(&#34;out_connections_dist_probe&#34;, None)
            num_senders_Aprobe_to_B = kwargs.get(&#34;num_senders_A&#34;, num_senders)
            num_connections_probe = (
                get_dist_mean(out_connects)
                if out_connects is not None
                else num_connections
            )
            num_end_probe = kwargs.get(&#34;num_end_probe&#34;, num_end)
        if max_depth &gt;= 2:
            out_connects_B = kwargs.get(&#34;out_connections_dist_B&#34;, None)
            num_connections_from_A_to_Bprobe = (
                get_dist_mean(out_connects_B)
                if out_connects_B is not None
                else num_connections
            )
            out_connects_A = kwargs.get(&#34;out_connections_dist_A&#34;, None)
            num_connections_from_Aprobe_to_B = (
                get_dist_mean(out_connects_A)
                if out_connects_A is not None
                else num_connections
            )

            num_senders_from_A_to_Bprobe = kwargs.get(&#34;num_senders_B&#34;, num_senders)

            inter_connects_start_probe_dist = kwargs.get(&#34;start_probe_to_outside&#34;, None)
            inter_connects_start_probe = (
                get_dist_mean(inter_connects_start_probe_dist)
                if inter_connects_start_probe_dist is not None
                else inter_connections_start
            )
            inter_connects_end_probe_dist = kwargs.get(&#34;end_outside_to_probe&#34;, None)
            inter_connects_end_probe = (
                get_dist_mean(inter_connects_end_probe_dist)
                if inter_connects_end_probe_dist is not None
                else inter_connections_end
            )

        # Do the actual calculation
        for num_sender_samples in range(total_samples + 1):
            final = 0
            if max_depth == 1:
                num_sender_direct = num_sender_samples
            else:
                num_sender_direct = expected_overlapping(
                    num_senders_Aprobe_to_B, num_senders_probe, num_sender_samples
                )
            if max_depth &gt;= 1:
                # AB
                ab = expected_unique(
                    num_end_probe, num_sender_direct * num_connections_probe
                )
                plist.append(ab)
                final = final + ab

            if max_depth &gt;= 2:

                # AAB
                aa_sampled = expected_unique(
                    num_start, total_samples * inter_connects_start_probe
                )
                aa_new = expected_non_overlapping(num_start, total_samples, aa_sampled)
                aa_senders = expected_overlapping(
                    num_start,
                    max(num_senders_from_A_to_Bprobe - num_sender_direct, 0),
                    aa_new,
                )
                aab_in_probe = expected_unique(
                    num_end_probe, aa_senders * num_connections_from_A_to_Bprobe
                )
                aab_less_ab_in_probe = expected_non_overlapping(
                    num_end_probe, final, aab_in_probe
                )
                plist.append(aab_in_probe)
                final = final + aab_less_ab_in_probe

                # ABB
                ab_full = expected_unique(
                    num_end, num_sender_samples * num_connections_from_Aprobe_to_B
                )
                abb_in_probe = expected_unique(
                    num_end_probe, ab_full * inter_connects_end_probe
                )
                # abb_in_probe = expected_overlapping(num_end, num_end_probe, abb_total)
                abb_less_prev = expected_non_overlapping(
                    num_end_probe, final, abb_in_probe
                )
                plist.append(abb_in_probe)
                final = final + abb_less_prev

            if max_depth &gt;= 3:
                # AAAB
                aaa_sampled = expected_unique(
                    num_start, aa_sampled * inter_connections_start
                )
                aaa_new = expected_non_overlapping(
                    num_start, aa_new + total_samples, aaa_sampled
                )
                num_senders_new_aaa = (
                    num_senders_from_A_to_Bprobe - aa_senders - num_sender_samples
                )
                aaa_senders = expected_overlapping(
                    num_start,
                    max(num_senders_new_aaa, 0),
                    aaa_new,
                )
                aaab_total = expected_unique(
                    num_end_probe, aaa_senders * num_connections_from_A_to_Bprobe
                )
                aaab_less_prev = expected_non_overlapping(
                    num_end_probe, final, aaab_total
                )
                plist.append(aaab_total)
                final = final + aaab_less_prev

                # AABB
                aab_total = expected_unique(num_end, aa_senders * num_connections)
                aab_less_ab = expected_non_overlapping(num_end, ab_full, aab_total)
                aabb_in_probe = expected_unique(
                    num_end_probe, aab_less_ab * inter_connects_end_probe
                )
                aabb_less_prev = expected_non_overlapping(
                    num_end_probe, final, aabb_in_probe
                )
                plist.append(aabb_in_probe)
                final = final + aabb_less_prev

                # ABAB
                ab_recurrent = expected_overlapping(num_end, num_recurrent, ab_full)
                aba = expected_unique(num_start, ab_recurrent * num_recurrent_synapses)
                aba_new = expected_non_overlapping(
                    num_start, aaa_new + aa_new + total_samples, aba
                )
                aba_senders_probe = num_senders_from_A_to_Bprobe - (
                    aaa_senders + aa_senders + num_sender_samples
                )
                aba_send_connections = expected_overlapping(
                    num_start,
                    max(aba_senders_probe, 0),
                    aba_new,
                )
                abab_total = expected_unique(
                    num_end_probe,
                    aba_send_connections * num_connections_from_A_to_Bprobe,
                )
                abab_less_prev = expected_non_overlapping(
                    num_end_probe, final, abab_total
                )
                plist.append(abab_total)
                final = final + abab_less_prev

                # ABBB
                abb_total = expected_unique(num_end, ab_full * inter_connections_end)
                abb_new = expected_non_overlapping(num_end, aab_total, abb_total)
                abbb_total = expected_unique(
                    num_end_probe, abb_new * inter_connects_end_probe
                )
                abbb_less_prev = expected_non_overlapping(
                    num_end_probe, final, abbb_total
                )
                plist.append(abbb_total)
                final = final + abbb_less_prev

            dists[num_sender_samples] = OrderedDict()
            dists[num_sender_samples][int(final)] = 1.0

        # Sums the above distributions to get the marginal
        prob_a_senders = OrderedDict()

        if max_depth == 1:
            for i in range(total_samples + 1):
                prob_a_senders[i] = float(
                    hypergeometric_pmf(
                        num_start_probe,
                        num_senders_probe,
                        total_samples,
                        i,
                    )
                )
        if max_depth &gt; 1:
            for i in range(total_samples + 1):
                prob_a_senders[i] = float(
                    hypergeometric_pmf(
                        num_start_probe,
                        num_senders_Aprobe_to_B,
                        total_samples,
                        i,
                    )
                )

        weighted_dist = combine_dists(range(num_end_probe + 1), dists, prob_a_senders)

        return dists, weighted_dist</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></li>
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Distribution of connections from the mean.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Distribution of connections from the mean.&#34;&#34;&#34;
    num_end = kwargs.get(&#34;N&#34;)
    num_connections = get_dist_mean(kwargs.get(&#34;out_connections_dist&#34;))
    num_recurrent_synapses = get_dist_mean(kwargs.get(&#34;recurrent_connections_dist&#34;))
    num_start = kwargs.get(&#34;num_start&#34;)
    num_senders = kwargs.get(&#34;num_senders&#34;)
    num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
    inter_connections_start = get_dist_mean(kwargs.get(&#34;start_inter_dist&#34;))
    inter_connections_end = get_dist_mean(kwargs.get(&#34;end_inter_dist&#34;))
    total_samples = kwargs.get(&#34;total_samples&#34;)
    max_depth = kwargs.get(&#34;max_depth&#34;, 3)

    plist = []
    if max_depth &gt; 3:
        raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

    dists = OrderedDict()

    # Parse config information
    if max_depth &gt;= 1:
        num_start_probe = kwargs.get(&#34;num_start_probe&#34;, num_start)
        num_senders_probe = kwargs.get(&#34;num_senders_probe&#34;, num_senders)
        out_connects = kwargs.get(&#34;out_connections_dist_probe&#34;, None)
        num_senders_Aprobe_to_B = kwargs.get(&#34;num_senders_A&#34;, num_senders)
        num_connections_probe = (
            get_dist_mean(out_connects)
            if out_connects is not None
            else num_connections
        )
        num_end_probe = kwargs.get(&#34;num_end_probe&#34;, num_end)
    if max_depth &gt;= 2:
        out_connects_B = kwargs.get(&#34;out_connections_dist_B&#34;, None)
        num_connections_from_A_to_Bprobe = (
            get_dist_mean(out_connects_B)
            if out_connects_B is not None
            else num_connections
        )
        out_connects_A = kwargs.get(&#34;out_connections_dist_A&#34;, None)
        num_connections_from_Aprobe_to_B = (
            get_dist_mean(out_connects_A)
            if out_connects_A is not None
            else num_connections
        )

        num_senders_from_A_to_Bprobe = kwargs.get(&#34;num_senders_B&#34;, num_senders)

        inter_connects_start_probe_dist = kwargs.get(&#34;start_probe_to_outside&#34;, None)
        inter_connects_start_probe = (
            get_dist_mean(inter_connects_start_probe_dist)
            if inter_connects_start_probe_dist is not None
            else inter_connections_start
        )
        inter_connects_end_probe_dist = kwargs.get(&#34;end_outside_to_probe&#34;, None)
        inter_connects_end_probe = (
            get_dist_mean(inter_connects_end_probe_dist)
            if inter_connects_end_probe_dist is not None
            else inter_connections_end
        )

    # Do the actual calculation
    for num_sender_samples in range(total_samples + 1):
        final = 0
        if max_depth == 1:
            num_sender_direct = num_sender_samples
        else:
            num_sender_direct = expected_overlapping(
                num_senders_Aprobe_to_B, num_senders_probe, num_sender_samples
            )
        if max_depth &gt;= 1:
            # AB
            ab = expected_unique(
                num_end_probe, num_sender_direct * num_connections_probe
            )
            plist.append(ab)
            final = final + ab

        if max_depth &gt;= 2:

            # AAB
            aa_sampled = expected_unique(
                num_start, total_samples * inter_connects_start_probe
            )
            aa_new = expected_non_overlapping(num_start, total_samples, aa_sampled)
            aa_senders = expected_overlapping(
                num_start,
                max(num_senders_from_A_to_Bprobe - num_sender_direct, 0),
                aa_new,
            )
            aab_in_probe = expected_unique(
                num_end_probe, aa_senders * num_connections_from_A_to_Bprobe
            )
            aab_less_ab_in_probe = expected_non_overlapping(
                num_end_probe, final, aab_in_probe
            )
            plist.append(aab_in_probe)
            final = final + aab_less_ab_in_probe

            # ABB
            ab_full = expected_unique(
                num_end, num_sender_samples * num_connections_from_Aprobe_to_B
            )
            abb_in_probe = expected_unique(
                num_end_probe, ab_full * inter_connects_end_probe
            )
            # abb_in_probe = expected_overlapping(num_end, num_end_probe, abb_total)
            abb_less_prev = expected_non_overlapping(
                num_end_probe, final, abb_in_probe
            )
            plist.append(abb_in_probe)
            final = final + abb_less_prev

        if max_depth &gt;= 3:
            # AAAB
            aaa_sampled = expected_unique(
                num_start, aa_sampled * inter_connections_start
            )
            aaa_new = expected_non_overlapping(
                num_start, aa_new + total_samples, aaa_sampled
            )
            num_senders_new_aaa = (
                num_senders_from_A_to_Bprobe - aa_senders - num_sender_samples
            )
            aaa_senders = expected_overlapping(
                num_start,
                max(num_senders_new_aaa, 0),
                aaa_new,
            )
            aaab_total = expected_unique(
                num_end_probe, aaa_senders * num_connections_from_A_to_Bprobe
            )
            aaab_less_prev = expected_non_overlapping(
                num_end_probe, final, aaab_total
            )
            plist.append(aaab_total)
            final = final + aaab_less_prev

            # AABB
            aab_total = expected_unique(num_end, aa_senders * num_connections)
            aab_less_ab = expected_non_overlapping(num_end, ab_full, aab_total)
            aabb_in_probe = expected_unique(
                num_end_probe, aab_less_ab * inter_connects_end_probe
            )
            aabb_less_prev = expected_non_overlapping(
                num_end_probe, final, aabb_in_probe
            )
            plist.append(aabb_in_probe)
            final = final + aabb_less_prev

            # ABAB
            ab_recurrent = expected_overlapping(num_end, num_recurrent, ab_full)
            aba = expected_unique(num_start, ab_recurrent * num_recurrent_synapses)
            aba_new = expected_non_overlapping(
                num_start, aaa_new + aa_new + total_samples, aba
            )
            aba_senders_probe = num_senders_from_A_to_Bprobe - (
                aaa_senders + aa_senders + num_sender_samples
            )
            aba_send_connections = expected_overlapping(
                num_start,
                max(aba_senders_probe, 0),
                aba_new,
            )
            abab_total = expected_unique(
                num_end_probe,
                aba_send_connections * num_connections_from_A_to_Bprobe,
            )
            abab_less_prev = expected_non_overlapping(
                num_end_probe, final, abab_total
            )
            plist.append(abab_total)
            final = final + abab_less_prev

            # ABBB
            abb_total = expected_unique(num_end, ab_full * inter_connections_end)
            abb_new = expected_non_overlapping(num_end, aab_total, abb_total)
            abbb_total = expected_unique(
                num_end_probe, abb_new * inter_connects_end_probe
            )
            abbb_less_prev = expected_non_overlapping(
                num_end_probe, final, abbb_total
            )
            plist.append(abbb_total)
            final = final + abbb_less_prev

        dists[num_sender_samples] = OrderedDict()
        dists[num_sender_samples][int(final)] = 1.0

    # Sums the above distributions to get the marginal
    prob_a_senders = OrderedDict()

    if max_depth == 1:
        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(
                    num_start_probe,
                    num_senders_probe,
                    total_samples,
                    i,
                )
            )
    if max_depth &gt; 1:
        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(
                    num_start_probe,
                    num_senders_Aprobe_to_B,
                    total_samples,
                    i,
                )
            )

    weighted_dist = combine_dists(range(num_end_probe + 1), dists, prob_a_senders)

    return dists, weighted_dist</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></b></code>:
<ul class="hlist">
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections">expected_connections</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity"><code class="flex name class">
<span>class <span class="ident">RecurrentConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Random connection with recursive connections and interconnections allowed.</p>
<p>In this, a certain number of neurons output a random number of connections
to completely random neurons with repetition possible.
This handles both forward and backward connections.
interconnections are handled by randomly sampling a set of
neurons for each neuron.
The rate at which interconnected synapses are formed is kept fixed
but the number of connections varies as multiple synapses can be formed.</p>
<p>Should pass the following keyword arguments on initialisation:
num_senders : int
The number of neurons which send a connection
min_inter : float
The minimum interconnection rate
max_inter : float
The maximum interconnection rate
min_forward : int
The minimum number of forward connections from one neuron
max_forward : int
The maximum number of forward connections from one neuron</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RecurrentConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connection with recursive connections and interconnections allowed.

    In this, a certain number of neurons output a random number of connections
    to completely random neurons with repetition possible.
    This handles both forward and backward connections.
    interconnections are handled by randomly sampling a set of
    neurons for each neuron.
    The rate at which interconnected synapses are formed is kept fixed
    but the number of connections varies as multiple synapses can be formed.

    Should pass the following keyword arguments on initialisation:
    num_senders : int
        The number of neurons which send a connection
    min_inter : float
        The minimum interconnection rate
    max_inter : float
        The maximum interconnection rate
    min_forward : int
        The minimum number of forward connections from one neuron
    max_forward : int
        The maximum number of forward connections from one neuron

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_inter = kwargs.get(&#34;min_inter&#34;)
        self.max_inter = kwargs.get(&#34;max_inter&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)
        self.recursive = kwargs.get(&#34;recursive&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        box = kwargs.get(&#34;box&#34;, False)  # for performance reasons

        if kwargs.get(&#34;use_full_region&#34;, True):
            graph, connected = self.gen_full_graph(choices, region_verts, box)
        else:
            if self.recursive:
                graph, connected = self.gen_graph_recursive(choices, **kwargs)
            else:
                graph, connected = self.gen_graph(choices, **kwargs)

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return RecurrentConnectivity.static_expected_connections(
            total_samples=num_samples, **kwargs
        )

    def gen_full_graph(self, choices, region_verts, box):
        graph = []
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create connections between neurons in the same region
        if self.max_inter &gt; 0:
            if box:
                num_boxes = 5
                box_like = 4
                box_size = int(math.ceil(len(region_verts) / num_boxes))
                out_box_size = len(region_verts) - box_size

                # Represents in box being box_like times more likely than outside
                # e.g. for 5
                # x = 5y
                # 1 = (1 / num_boxes) * (5 * y) + (1 - 1 / num_boxes) * y
                y_mult = (1 / num_boxes) * (box_like) + (1 - (1 / num_boxes))
                out_box_mult = 1 / y_mult
                in_box_mult = box_like * out_box_mult
                mult = np.array(
                    [
                        (1 / num_boxes) * in_box_mult,
                        (1 - (1 / num_boxes)) * out_box_mult,
                    ]
                )
                rand_amt = self.min_inter + (
                    np.random.rand() * (self.max_inter - self.min_inter)
                )
                sample_sizes = np.ceil(rand_amt * mult * len(region_verts)).astype(int)

                in_box_idx = np.array([i for i in range(box_size)], dtype=np.int32)
                self_connects_box = np.random.choice(
                    in_box_idx,
                    size=(len(region_verts), sample_sizes[0]),
                    replace=True,
                )

                out_box_idx = np.array(
                    [i + box_size for i in range(out_box_size)], dtype=np.int32
                )
                self_connects_outside = np.random.choice(
                    out_box_idx,
                    size=(len(region_verts), sample_sizes[1]),
                    replace=True,
                )

            else:
                self_connects = np.random.choice(
                    region_verts,
                    size=(
                        len(region_verts),
                        int(round(self.max_inter * len(region_verts))),
                    ),
                    replace=True,
                )
                num_choices_inter = np.random.randint(
                    int(round(self.min_inter * len(region_verts))),
                    int(round(self.max_inter * len(region_verts))) + 1,
                    dtype=np.int32,
                    size=len(region_verts),
                )

        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            if self.max_inter &gt; 0:
                if box:
                    which_box = int(math.floor(i / box_size))
                    a = int(which_box * box_size)

                    self_connects_box_i = a + self_connects_box[i]

                    self_connects_out_i = self_connects_outside[i]
                    self_connects_out_i[
                        self_connects_out_i &lt; (a + box_size)
                    ] -= box_size

                    self_connections = np.array(
                        list(
                            set(
                                np.concatenate(
                                    (self_connects_box_i, self_connects_out_i)
                                    + np.min(region_verts)
                                )
                            )
                        ),
                        dtype=np.int32,
                    )

                else:
                    self_connections = np.array(
                        list(set(self_connects[i, : num_choices_inter[i]])),
                        dtype=np.int32,
                    )

                # Remove autaptic synapses
                self_connections = np.delete(
                    self_connections, np.where(self_connections == vert)
                )
                for val in self_connections:
                    if isinstance(val, float):
                        print(val, self_connections)
                        exit(-1)

            else:
                self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def gen_graph(self, choices, **kwargs):
        def d_minmax(dist):
            vals = list(dist.items())
            return vals[0][0], vals[-1][0]

        graph = []

        region_verts = kwargs.get(&#34;region_verts&#34;)
        idx_inA = kwargs.get(&#34;idx_in_deviceA&#34;)
        idx_outA = list(set(region_verts) - set(idx_inA))
        idx_inB = kwargs.get(&#34;idx_in_deviceB&#34;) + len(region_verts)
        idx_outB = list(set(choices) - set(idx_inB))
        num_senders_device = kwargs.get(&#34;num_senders_probe&#34;)
        num_senders_A = kwargs.get(&#34;num_senders_A&#34;)
        num_senders_B = kwargs.get(&#34;num_senders_B&#34;)
        forward_dist_device = kwargs.get(&#34;out_connections_dist_probe&#34;)
        forwardA_to_Bprobe = kwargs.get(&#34;out_connections_dist_B&#34;)
        forwardAprobe_to_B = kwargs.get(&#34;out_connections_dist_A&#34;)
        start_probe_to_outside = kwargs.get(&#34;start_probe_to_outside&#34;)

        forward_dist_device_min, forward_dist_device_max = d_minmax(forward_dist_device)
        forwardA_to_Bprobe_min, forwardA_to_Bprobe_max = d_minmax(forwardA_to_Bprobe)
        forwardAprobe_to_B_min, forwardAprobe_to_B_max = d_minmax(forwardAprobe_to_B)
        start_probe_to_outside_min, start_probe_to_outside_max = d_minmax(
            start_probe_to_outside
        )

        # A device to B device
        connected_device = np.random.choice(
            idx_inA, size=num_senders_device, replace=False
        )
        forward_connections_device = np.random.choice(
            idx_inB, size=(num_senders_device, forward_dist_device_max), replace=True
        )
        num_choices_device = np.random.randint(
            forward_dist_device_min,
            forward_dist_device_max + 1,
            dtype=np.int32,
            size=num_senders_device,
        )

        # A device to B
        if len(idx_outB) == 0:
            connected_Adevice = []
        else:
            connected_Adevice = np.random.choice(
                idx_inA, size=num_senders_A, replace=False
            )
            forward_connections_Adevice_B = np.random.choice(
                idx_outB, size=(num_senders_A, forwardAprobe_to_B_max), replace=True
            )
            num_choices_Adevice_B = np.random.randint(
                forwardAprobe_to_B_min,
                forwardAprobe_to_B_min + 1,
                dtype=np.int32,
                size=num_senders_A,
            )

        # A to B device
        if len(idx_outA) == 0:
            connected_Bdevice = []
        else:
            connected_Bdevice = np.random.choice(
                idx_outA, size=num_senders_B - num_senders_device, replace=False
            )
            forward_connections_A_Bdevice = np.random.choice(
                idx_inB,
                size=(num_senders_B - num_senders_device, forwardA_to_Bprobe_max),
                replace=True,
            )
            num_choices_A_Bdevice = np.random.randint(
                forwardA_to_Bprobe_min,
                forwardA_to_Bprobe_max + 1,
                dtype=np.int32,
                size=num_senders_B,
            )

        # A interconnections
        self_connects_Adevice = np.random.choice(
            region_verts,
            size=(
                len(idx_inA),
                int(round(start_probe_to_outside_max)),
            ),
            replace=True,
        )
        num_choices_inter_device = np.random.randint(
            int(round(start_probe_to_outside_min)),
            int(round(start_probe_to_outside_max)) + 1,
            dtype=np.int32,
            size=len(idx_inA),
        )
        self_connects_Arest = np.random.choice(
            region_verts,
            size=(
                len(region_verts) - len(idx_inA),
                int(round(self.max_inter * len(region_verts))),
            ),
            replace=True,
        )
        num_choices_inter = np.random.randint(
            int(round(self.min_inter * len(region_verts))),
            int(round(self.max_inter * len(region_verts))) + 1,
            dtype=np.int32,
            size=len(region_verts) - len(idx_inA),
        )

        # Create the connections
        a_idx = 0
        b_idx = 0
        c_idx = 0
        d_idx = 0
        e_idx = 0
        for i, vert in enumerate(region_verts):
            if vert in idx_inA:
                self_connections = np.array(
                    list(
                        set(
                            self_connects_Adevice[
                                d_idx, : num_choices_inter_device[d_idx]
                            ]
                        )
                    ),
                    dtype=np.int32,
                )
                d_idx = d_idx + 1
            else:
                self_connections = np.array(
                    list(set(self_connects_Arest[e_idx, : num_choices_inter[e_idx]])),
                    dtype=np.int32,
                )
                e_idx = e_idx + 1

            # Remove autaptic synapses
            self_connections = np.delete(
                self_connections, np.where(self_connections == vert)
            )
            for val in self_connections:
                if isinstance(val, float):
                    print(val, self_connections)
                    exit(-1)

            if vert in connected_device:
                forward_connection = forward_connections_device[
                    a_idx, : num_choices_device[a_idx]
                ]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                a_idx = a_idx + 1

            if vert in connected_Adevice:
                forward_connection = forward_connections_Adevice_B[
                    b_idx, : num_choices_Adevice_B[b_idx]
                ]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                b_idx = b_idx + 1

            if vert in connected_Bdevice:
                forward_connection = forward_connections_A_Bdevice[
                    c_idx, : num_choices_A_Bdevice[c_idx]
                ]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                c_idx = c_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return (
            graph,
            list(
                set(connected_device) | set(connected_Adevice) | set(connected_Bdevice)
            ),
        )

    def gen_graph_recursive(self, choices, **kwargs):
        region_verts = kwargs.get(&#34;region_verts&#34;)
        idx_inB = kwargs.get(&#34;idx_in_deviceB&#34;) + len(choices)
        idx_outB = list(set(choices) - set(idx_inB))
        outside_dist_inter = kwargs.get(&#34;end_outside_to_probe&#34;)
        vals = list(outside_dist_inter.items())
        min_inter = vals[0][0]
        max_inter = vals[-1][0]

        graph = []
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create connections between neurons in the same region
        if self.max_inter &gt; 0:

            self_connects_outside = np.random.choice(
                idx_outB,
                size=(
                    len(region_verts),
                    int(round(self.max_inter * len(region_verts))),
                ),
                replace=True,
            )
            num_choices_inter_outside = np.random.randint(
                int(round(self.min_inter * len(region_verts))),
                int(round(self.max_inter * len(region_verts))) + 1,
                dtype=np.int32,
                size=len(region_verts),
            )

            self_connects_inside = np.random.choice(
                idx_inB,
                size=(
                    len(region_verts),
                    int(round(max_inter * len(region_verts))),
                ),
                replace=True,
            )
            num_choices_inter_inside = np.random.randint(
                int(round(min_inter * len(region_verts))),
                int(round(max_inter * len(region_verts))) + 1,
                dtype=np.int32,
                size=len(region_verts),
            )

        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            if self.max_inter &gt; 0:
                self_connections = np.array(
                    list(set(self_connects_outside[i, : num_choices_inter_outside[i]])),
                    dtype=np.int32,
                )
                self_connections = np.append(
                    self_connections,
                    np.array(
                        list(
                            set(self_connects_inside[i, : num_choices_inter_inside[i]])
                        ),
                        dtype=np.int32,
                    ),
                )

                # Remove autaptic synapses
                self_connections = np.delete(
                    self_connections, np.where(self_connections == vert)
                )
                for val in self_connections:
                    if isinstance(val, float):
                        print(val, self_connections)
                        exit(-1)

            else:
                self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 1)

        use_mean = kwargs.get(&#34;use_mean&#34;, True)
        if max_depth &gt; 3:
            raise ValueError(
                &#34;max_depth must be less than 4 currently for recurrent no mean.&#34;
            )
        if (max_depth == 3) or (use_mean and (max_depth &gt; 1)):
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        if max_depth &gt;= 1:
            num_end = kwargs.get(&#34;N&#34;)
            out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
            num_start = kwargs.get(&#34;num_start&#34;)
            num_senders = kwargs.get(&#34;num_senders&#34;)

            total_samples = kwargs.get(&#34;total_samples&#34;)
            clt_start = kwargs.get(&#34;clt_start&#34;, 30)
            sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

            # Used to specify stats in relation to the recording device(s).
            num_start_probe = kwargs.get(&#34;num_start_probe&#34;, num_start)
            num_senders_probe = kwargs.get(&#34;num_senders_probe&#34;, num_senders)
            out_connections_dist_probe = kwargs.get(
                &#34;out_connections_dist_probe&#34;, out_connections_dist
            )
            num_end_probe = kwargs.get(&#34;num_end_probe&#34;, num_end)

            # Setup required regardless of the depth of the connection
            def fn_to_apply(k):
                # Ideally, here would use float if large var dist, and int otherwise.
                # Not a huge difference though
                # return expected_unique(num_end, k, do_round=False)
                return expected_unique(num_end_probe, k, do_round=True)

            # Gives dist of num outgoing connections from A
            # This tends towards normal distribution by CLT in most cases
            ab_dist = random_draw_dist(
                total_samples,
                out_connections_dist_probe,
                num_end_probe,
                apply_fn=False,
                keep_all=True,
                clt_start=clt_start,
                sub=sub,
            )

            ab_un_dist = OrderedDict()
            for k, v in ab_dist.items():
                ab_un_dist[k] = apply_fn_to_dist(v, fn_to_apply, sub=sub)
            final_dist = ab_un_dist

        if max_depth &gt;= 2:
            final_dist = OrderedDict()
            start_inter_dist = kwargs.get(&#34;start_inter_dist&#34;)
            end_inter_dist = kwargs.get(&#34;end_inter_dist&#34;)
            ab_dist_from_probe = kwargs.get(
                &#34;out_connections_dist_A&#34;, out_connections_dist_probe
            )

            start_mean = get_dist_mean(out_connections_dist)
            start_var = get_dist_var(out_connections_dist)
            ABprobe_mean = get_dist_mean(ab_dist_from_probe)
            ABprobe_var = get_dist_var(ab_dist_from_probe)

            start_inter_mean = get_dist_mean(start_inter_dist)
            start_inter_var = get_dist_var(start_inter_dist)
            end_inter_mean = get_dist_mean(end_inter_dist)
            end_inter_var = get_dist_var(end_inter_dist)

            # Raw AB cache
            ab_cache = OrderedDict()
            ab_cache[0] = OrderedDict()
            ab_cache[0][0] = 1.0
            start_max_val = max(list(out_connections_dist.keys()))
            for i in range(1, num_senders + 1):
                if i &lt; clt_start:
                    ab_cache[i] = convolution(
                        out_connections_dist, ab_cache[i - 1], sub=sub
                    )
                else:
                    ab_cache[i] = create_normal(
                        range((start_max_val * i) + 1),
                        start_mean * i,
                        start_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            # Probe AB cache
            ab_cache_from_a = OrderedDict()
            ab_cache_from_a[0] = OrderedDict()
            ab_cache_from_a[0][0] = 1.0
            start_max_val_a = max(list(ab_dist_from_probe.keys()))
            for i in range(1, num_senders_probe + 1):
                if i &lt; clt_start:
                    ab_cache_from_a[i] = convolution(
                        ab_dist_from_probe, ab_cache_from_a[i - 1], sub=sub
                    )
                else:
                    ab_cache_from_a[i] = create_normal(
                        range((start_max_val_a * i) + 1),
                        ABprobe_mean * i,
                        ABprobe_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            def fn_un_b(k):
                return expected_unique(num_end, k)

            ab_from_a_un = OrderedDict()
            for k, v in ab_cache_from_a.items():
                ab_from_a_un[k] = apply_fn_to_dist(v, fn_un_b, sub=sub)

            # Raw BB cache
            bb_cache = OrderedDict()
            bb_cache[0] = OrderedDict()
            bb_cache[0][0] = 1.0
            end_inter_max_val = max(list(end_inter_dist.keys()))
            for i in range(1, num_end + 1):
                if i &lt; clt_start:
                    bb_cache[i] = convolution(end_inter_dist, bb_cache[i - 1], sub=sub)
                else:
                    bb_cache[i] = create_normal(
                        range((end_inter_max_val * i) + 1),
                        end_inter_mean * i,
                        end_inter_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            # AAB calculation
            if total_samples &lt; clt_start:
                aa_dist = nfold_conv([start_inter_dist] * total_samples, sub=sub)
            else:
                max_val = max(list(start_inter_dist.keys()))
                aa_dist = create_normal(
                    range((max_val * total_samples) + 1),
                    start_inter_mean * total_samples,
                    start_inter_var * total_samples,
                    sub=sub,
                    interp_after=True,
                )
            aa_sender_dist = OrderedDict()

            aab_dist = OrderedDict()
            abb_dist = OrderedDict()

            for i in range(total_samples + 1):

                def inside_fn(x):
                    aa_sampled = expected_unique(num_start, x)
                    aa_new = expected_non_overlapping(
                        num_start, total_samples, aa_sampled
                    )
                    aa_senders = expected_overlapping(
                        num_start,
                        num_senders - i,
                        aa_new,
                    )
                    return int(round(aa_senders))

                aa_sender_dist[i] = apply_fn_to_dist(aa_dist, inside_fn, sub=sub)

                aab_dist[i] = combine_dists(
                    range((start_max_val * num_senders) + 1),
                    ab_cache,
                    aa_sender_dist[i],
                    sub=None,
                )
                # NOTE this needs to be extended to consider abbb dist for e.g.
                abb_dist[i] = combine_dists(
                    range((end_inter_max_val * num_end) + 1),
                    bb_cache,
                    ab_from_a_un[i],
                    sub=None,
                )
                aab_dist[i] = apply_fn_to_dist(aab_dist[i], fn_to_apply, sub=sub)
                abb_dist[i] = apply_fn_to_dist(abb_dist[i], fn_to_apply, sub=sub)

                aab_cache = OrderedDict()
                abb_cache = OrderedDict()

                for j in range(num_end_probe + 1):

                    def to_app(x):
                        return min(
                            j + round(expected_non_overlapping(num_end_probe, j, x)),
                            num_end_probe,
                        )

                    if j == num_end_probe:
                        to_add = OrderedDict()
                        to_add[num_end_probe] = 1
                        aab_cache[j] = to_add
                        abb_cache[j] = to_add
                    else:
                        aab_cache[j] = apply_fn_to_dist(aab_dist[i], to_app, sub=sub)
                        abb_cache[j] = apply_fn_to_dist(abb_dist[i], to_app, sub=sub)

                in_prog = OrderedDict()
                in_prog = combine_dists(
                    range(num_end_probe + 1), aab_cache, ab_un_dist[i], sub=None
                )
                in_prog = combine_dists(
                    range(num_end_probe + 1), abb_cache, in_prog, sub=None
                )
                final_dist[i] = in_prog

        # if max_depth &gt;= 3:
        #     recurrent_connections_dist = kwargs.get(&#34;recurrent_connections_dist&#34;)
        #     num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
        #     end_mean = get_dist_mean(recurrent_connections_dist)
        #     end_var = get_dist_var(recurrent_connections_dist)

        #     aaab_dist = OrderedDict()
        #     aabb_dist = OrderedDict()
        #     abbb_dist = OrderedDict()
        #     abab_dist = OrderedDict()

        #     aaab_cache = OrderedDict()
        #     aabb_cache = OrderedDict()
        #     abbb_cache = OrderedDict()
        #     abab_cache = OrderedDict()

        #     aa_cache = OrderedDict()
        #     aa_cache[0] = OrderedDict()
        #     aa_cache[0][0] = 1.0
        #     start_inter_max_val = max(list(start_inter_dist.keys()))
        #     for i in range(1, num_start + 1):
        #         if i &lt; clt_start:
        #             aa_cache[i] = convolution(
        #                 start_inter_dist, aa_cache[i - 1], sub=sub
        #             )
        #         else:
        #             aa_cache[i] = create_normal(
        #                 range((start_inter_max_val * i) + 1),
        #                 start_inter_mean * i,
        #                 start_inter_var * i,
        #                 sub=sub,
        #                 interp_after=True,
        #             )

        #     ba_cache = OrderedDict()
        #     ba_cache[0] = OrderedDict()
        #     ba_cache[0][0] = 1.0
        #     end_max_val = max(list(recurrent_connections_dist.keys()))
        #     for i in range(1, num_recurrent + 1):
        #         if i &lt; clt_start:
        #             ba_cache[i] = convolution(
        #                 recurrent_connections_dist, ba_cache[i - 1], sub=sub
        #             )
        #         else:
        #             ba_cache[i] = create_normal(
        #                 range((end_max_val * i) + 1),
        #                 end_mean * i,
        #                 end_var * i,
        #                 sub=sub,
        #                 interp_after=True,
        #             )

        #     ab_sender_dist = OrderedDict()

        #     def new_fn(x):
        #         return int(round(expected_overlapping(num_end, num_recurrent, x)))

        #     for k, v in ab_un_dist.items():
        #         ab_sender_dist[k] = apply_fn_to_dist(v, new_fn, sub=sub)

        #     aaa_sender_dist = OrderedDict()

        #     def new_fn(x):
        #         return int(round(expected_unique(num_start, x)))

        #     aa_un_dist = apply_fn_to_dist(aa_dist, new_fn, sub=sub)
        #     aaa_dist = combine_dists(
        #         range((num_start * start_inter_max_val * start_inter_max_val) + 1),
        #         aa_cache,
        #         aa_un_dist,
        #         sub=None,
        #     )

        #     aba_dist = OrderedDict()
        #     aba_sender_dist = OrderedDict()

        #     for i in range(total_samples + 1):

        #         def inside_fn(x):
        #             aaa_sampled = expected_unique(num_start, x)
        #             aaa_new = expected_non_overlapping(
        #                 num_start,
        #                 total_samples + get_dist_mean(aa_un_dist),
        #                 aaa_sampled,
        #             )
        #             aaa_senders = expected_overlapping(
        #                 num_start,
        #                 num_senders - get_dist_mean(aa_sender_dist[i]) - i,
        #                 aaa_new,
        #             )
        #             return int(round(aaa_senders))

        #         def new_fn_k(x):
        #             aba_sampled = expected_unique(num_start, x)
        #             aba_new = expected_non_overlapping(
        #                 num_start,
        #                 total_samples
        #                 + get_dist_mean(aa_un_dist)
        #                 + get_dist_mean(aaa_dist),
        #                 aba_sampled,
        #             )
        #             aba_senders = expected_overlapping(
        #                 num_start,
        #                 num_senders
        #                 - get_dist_mean(aa_sender_dist[i])
        #                 - get_dist_mean(aaa_sender_dist[i])
        #                 - i,
        #                 aba_new,
        #             )
        #             return int(round(aba_senders))

        #         aaa_sender_dist[i] = apply_fn_to_dist(aaa_dist, inside_fn, sub=sub)

        #         aba_dist[i] = combine_dists(
        #             range((num_recurrent * end_max_val) + 1),
        #             ba_cache,
        #             ab_sender_dist[i],
        #             sub=None,
        #         )
        #         aba_sender_dist[i] = apply_fn_to_dist(
        #             aba_dist[i], new_fn_k, sub=sub
        #         )

        #         aaab_dist[i] = combine_dists(
        #             range((start_max_val * num_senders) + 1),
        #             ab_cache,
        #             aaa_sender_dist[i],
        #             sub=None,
        #         )
        #         abab_dist[i] = combine_dists(
        #             range((start_max_val * num_senders) + 1),
        #             ab_cache,
        #             aba_sender_dist[i],
        #             sub=None,
        #         )
        #         aabb_dist[i] = combine_dists(
        #             range((end_inter_max_val * num_end) + 1),
        #             bb_cache,
        #             aab_dist[i],
        #             sub=None,
        #         )
        #         abbb_dist[i] = combine_dists(
        #             range((end_inter_max_val * num_end) + 1),
        #             bb_cache,
        #             abb_dist[i],
        #             sub=None,
        #         )

        #         for j in range(num_end + 1):

        #             def to_app(x):
        #                 return min(
        #                     j + round(expected_non_overlapping(num_end, j, x)),
        #                     num_end,
        #                 )

        #             if j == num_end:
        #                 to_add = OrderedDict()
        #                 to_add[num_end] = 1
        #                 aaab_cache[j] = to_add
        #                 aabb_cache[j] = to_add
        #                 abab_cache[j] = to_add
        #                 abbb_cache[j] = to_add
        #             else:
        #                 aaab_cache[j] = apply_fn_to_dist(
        #                     aaab_dist[i], to_app, sub=sub
        #                 )
        #                 aabb_cache[j] = apply_fn_to_dist(
        #                     aabb_dist[i], to_app, sub=sub
        #                 )
        #                 abab_cache[j] = apply_fn_to_dist(
        #                     abab_dist[i], to_app, sub=sub
        #                 )
        #                 abbb_cache[j] = apply_fn_to_dist(
        #                     abbb_dist[i], to_app, sub=sub
        #                 )

        #         in_prog = OrderedDict()
        #         in_prog = combine_dists(
        #             range(num_end + 1), aaab_cache, final_dist[i], sub=None
        #         )
        #         in_prog = combine_dists(
        #             range(num_end + 1), aabb_cache, in_prog, sub=None
        #         )
        #         in_prog = combine_dists(
        #             range(num_end + 1), abab_cache, in_prog, sub=None
        #         )
        #         in_prog = combine_dists(
        #             range(num_end + 1), abbb_cache, in_prog, sub=None
        #         )
        #         final_dist[i] = in_prog

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start_probe, num_senders_probe, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end_probe + 1), final_dist, prob_a_senders, sub=None
        )

        return ab_un_dist, weighted_dist

    @staticmethod
    def nfmt(start, *args):
        start = str(start) + &#34;: (&#34;
        for arg in args:
            start = start + nstr(arg, 5) + &#34;, &#34;
        start = start[:-2] + &#34;)&#34;

        return start</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity" href="#neuroconnect.connectivity_patterns.MeanRecurrentConnectivity">MeanRecurrentConnectivity</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.nfmt"><code class="name flex">
<span>def <span class="ident">nfmt</span></span>(<span>start, *args)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def nfmt(start, *args):
    start = str(start) + &#34;: (&#34;
    for arg in args:
        start = start + nstr(arg, 5) + &#34;, &#34;
    start = start[:-2] + &#34;)&#34;

    return start</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Return connection distribution.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
    # Parse out the relevant parameters
    max_depth = kwargs.get(&#34;max_depth&#34;, 1)

    use_mean = kwargs.get(&#34;use_mean&#34;, True)
    if max_depth &gt; 3:
        raise ValueError(
            &#34;max_depth must be less than 4 currently for recurrent no mean.&#34;
        )
    if (max_depth == 3) or (use_mean and (max_depth &gt; 1)):
        return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
    if max_depth &gt;= 1:
        num_end = kwargs.get(&#34;N&#34;)
        out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)

        total_samples = kwargs.get(&#34;total_samples&#34;)
        clt_start = kwargs.get(&#34;clt_start&#34;, 30)
        sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

        # Used to specify stats in relation to the recording device(s).
        num_start_probe = kwargs.get(&#34;num_start_probe&#34;, num_start)
        num_senders_probe = kwargs.get(&#34;num_senders_probe&#34;, num_senders)
        out_connections_dist_probe = kwargs.get(
            &#34;out_connections_dist_probe&#34;, out_connections_dist
        )
        num_end_probe = kwargs.get(&#34;num_end_probe&#34;, num_end)

        # Setup required regardless of the depth of the connection
        def fn_to_apply(k):
            # Ideally, here would use float if large var dist, and int otherwise.
            # Not a huge difference though
            # return expected_unique(num_end, k, do_round=False)
            return expected_unique(num_end_probe, k, do_round=True)

        # Gives dist of num outgoing connections from A
        # This tends towards normal distribution by CLT in most cases
        ab_dist = random_draw_dist(
            total_samples,
            out_connections_dist_probe,
            num_end_probe,
            apply_fn=False,
            keep_all=True,
            clt_start=clt_start,
            sub=sub,
        )

        ab_un_dist = OrderedDict()
        for k, v in ab_dist.items():
            ab_un_dist[k] = apply_fn_to_dist(v, fn_to_apply, sub=sub)
        final_dist = ab_un_dist

    if max_depth &gt;= 2:
        final_dist = OrderedDict()
        start_inter_dist = kwargs.get(&#34;start_inter_dist&#34;)
        end_inter_dist = kwargs.get(&#34;end_inter_dist&#34;)
        ab_dist_from_probe = kwargs.get(
            &#34;out_connections_dist_A&#34;, out_connections_dist_probe
        )

        start_mean = get_dist_mean(out_connections_dist)
        start_var = get_dist_var(out_connections_dist)
        ABprobe_mean = get_dist_mean(ab_dist_from_probe)
        ABprobe_var = get_dist_var(ab_dist_from_probe)

        start_inter_mean = get_dist_mean(start_inter_dist)
        start_inter_var = get_dist_var(start_inter_dist)
        end_inter_mean = get_dist_mean(end_inter_dist)
        end_inter_var = get_dist_var(end_inter_dist)

        # Raw AB cache
        ab_cache = OrderedDict()
        ab_cache[0] = OrderedDict()
        ab_cache[0][0] = 1.0
        start_max_val = max(list(out_connections_dist.keys()))
        for i in range(1, num_senders + 1):
            if i &lt; clt_start:
                ab_cache[i] = convolution(
                    out_connections_dist, ab_cache[i - 1], sub=sub
                )
            else:
                ab_cache[i] = create_normal(
                    range((start_max_val * i) + 1),
                    start_mean * i,
                    start_var * i,
                    sub=sub,
                    interp_after=True,
                )

        # Probe AB cache
        ab_cache_from_a = OrderedDict()
        ab_cache_from_a[0] = OrderedDict()
        ab_cache_from_a[0][0] = 1.0
        start_max_val_a = max(list(ab_dist_from_probe.keys()))
        for i in range(1, num_senders_probe + 1):
            if i &lt; clt_start:
                ab_cache_from_a[i] = convolution(
                    ab_dist_from_probe, ab_cache_from_a[i - 1], sub=sub
                )
            else:
                ab_cache_from_a[i] = create_normal(
                    range((start_max_val_a * i) + 1),
                    ABprobe_mean * i,
                    ABprobe_var * i,
                    sub=sub,
                    interp_after=True,
                )

        def fn_un_b(k):
            return expected_unique(num_end, k)

        ab_from_a_un = OrderedDict()
        for k, v in ab_cache_from_a.items():
            ab_from_a_un[k] = apply_fn_to_dist(v, fn_un_b, sub=sub)

        # Raw BB cache
        bb_cache = OrderedDict()
        bb_cache[0] = OrderedDict()
        bb_cache[0][0] = 1.0
        end_inter_max_val = max(list(end_inter_dist.keys()))
        for i in range(1, num_end + 1):
            if i &lt; clt_start:
                bb_cache[i] = convolution(end_inter_dist, bb_cache[i - 1], sub=sub)
            else:
                bb_cache[i] = create_normal(
                    range((end_inter_max_val * i) + 1),
                    end_inter_mean * i,
                    end_inter_var * i,
                    sub=sub,
                    interp_after=True,
                )

        # AAB calculation
        if total_samples &lt; clt_start:
            aa_dist = nfold_conv([start_inter_dist] * total_samples, sub=sub)
        else:
            max_val = max(list(start_inter_dist.keys()))
            aa_dist = create_normal(
                range((max_val * total_samples) + 1),
                start_inter_mean * total_samples,
                start_inter_var * total_samples,
                sub=sub,
                interp_after=True,
            )
        aa_sender_dist = OrderedDict()

        aab_dist = OrderedDict()
        abb_dist = OrderedDict()

        for i in range(total_samples + 1):

            def inside_fn(x):
                aa_sampled = expected_unique(num_start, x)
                aa_new = expected_non_overlapping(
                    num_start, total_samples, aa_sampled
                )
                aa_senders = expected_overlapping(
                    num_start,
                    num_senders - i,
                    aa_new,
                )
                return int(round(aa_senders))

            aa_sender_dist[i] = apply_fn_to_dist(aa_dist, inside_fn, sub=sub)

            aab_dist[i] = combine_dists(
                range((start_max_val * num_senders) + 1),
                ab_cache,
                aa_sender_dist[i],
                sub=None,
            )
            # NOTE this needs to be extended to consider abbb dist for e.g.
            abb_dist[i] = combine_dists(
                range((end_inter_max_val * num_end) + 1),
                bb_cache,
                ab_from_a_un[i],
                sub=None,
            )
            aab_dist[i] = apply_fn_to_dist(aab_dist[i], fn_to_apply, sub=sub)
            abb_dist[i] = apply_fn_to_dist(abb_dist[i], fn_to_apply, sub=sub)

            aab_cache = OrderedDict()
            abb_cache = OrderedDict()

            for j in range(num_end_probe + 1):

                def to_app(x):
                    return min(
                        j + round(expected_non_overlapping(num_end_probe, j, x)),
                        num_end_probe,
                    )

                if j == num_end_probe:
                    to_add = OrderedDict()
                    to_add[num_end_probe] = 1
                    aab_cache[j] = to_add
                    abb_cache[j] = to_add
                else:
                    aab_cache[j] = apply_fn_to_dist(aab_dist[i], to_app, sub=sub)
                    abb_cache[j] = apply_fn_to_dist(abb_dist[i], to_app, sub=sub)

            in_prog = OrderedDict()
            in_prog = combine_dists(
                range(num_end_probe + 1), aab_cache, ab_un_dist[i], sub=None
            )
            in_prog = combine_dists(
                range(num_end_probe + 1), abb_cache, in_prog, sub=None
            )
            final_dist[i] = in_prog

    # if max_depth &gt;= 3:
    #     recurrent_connections_dist = kwargs.get(&#34;recurrent_connections_dist&#34;)
    #     num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
    #     end_mean = get_dist_mean(recurrent_connections_dist)
    #     end_var = get_dist_var(recurrent_connections_dist)

    #     aaab_dist = OrderedDict()
    #     aabb_dist = OrderedDict()
    #     abbb_dist = OrderedDict()
    #     abab_dist = OrderedDict()

    #     aaab_cache = OrderedDict()
    #     aabb_cache = OrderedDict()
    #     abbb_cache = OrderedDict()
    #     abab_cache = OrderedDict()

    #     aa_cache = OrderedDict()
    #     aa_cache[0] = OrderedDict()
    #     aa_cache[0][0] = 1.0
    #     start_inter_max_val = max(list(start_inter_dist.keys()))
    #     for i in range(1, num_start + 1):
    #         if i &lt; clt_start:
    #             aa_cache[i] = convolution(
    #                 start_inter_dist, aa_cache[i - 1], sub=sub
    #             )
    #         else:
    #             aa_cache[i] = create_normal(
    #                 range((start_inter_max_val * i) + 1),
    #                 start_inter_mean * i,
    #                 start_inter_var * i,
    #                 sub=sub,
    #                 interp_after=True,
    #             )

    #     ba_cache = OrderedDict()
    #     ba_cache[0] = OrderedDict()
    #     ba_cache[0][0] = 1.0
    #     end_max_val = max(list(recurrent_connections_dist.keys()))
    #     for i in range(1, num_recurrent + 1):
    #         if i &lt; clt_start:
    #             ba_cache[i] = convolution(
    #                 recurrent_connections_dist, ba_cache[i - 1], sub=sub
    #             )
    #         else:
    #             ba_cache[i] = create_normal(
    #                 range((end_max_val * i) + 1),
    #                 end_mean * i,
    #                 end_var * i,
    #                 sub=sub,
    #                 interp_after=True,
    #             )

    #     ab_sender_dist = OrderedDict()

    #     def new_fn(x):
    #         return int(round(expected_overlapping(num_end, num_recurrent, x)))

    #     for k, v in ab_un_dist.items():
    #         ab_sender_dist[k] = apply_fn_to_dist(v, new_fn, sub=sub)

    #     aaa_sender_dist = OrderedDict()

    #     def new_fn(x):
    #         return int(round(expected_unique(num_start, x)))

    #     aa_un_dist = apply_fn_to_dist(aa_dist, new_fn, sub=sub)
    #     aaa_dist = combine_dists(
    #         range((num_start * start_inter_max_val * start_inter_max_val) + 1),
    #         aa_cache,
    #         aa_un_dist,
    #         sub=None,
    #     )

    #     aba_dist = OrderedDict()
    #     aba_sender_dist = OrderedDict()

    #     for i in range(total_samples + 1):

    #         def inside_fn(x):
    #             aaa_sampled = expected_unique(num_start, x)
    #             aaa_new = expected_non_overlapping(
    #                 num_start,
    #                 total_samples + get_dist_mean(aa_un_dist),
    #                 aaa_sampled,
    #             )
    #             aaa_senders = expected_overlapping(
    #                 num_start,
    #                 num_senders - get_dist_mean(aa_sender_dist[i]) - i,
    #                 aaa_new,
    #             )
    #             return int(round(aaa_senders))

    #         def new_fn_k(x):
    #             aba_sampled = expected_unique(num_start, x)
    #             aba_new = expected_non_overlapping(
    #                 num_start,
    #                 total_samples
    #                 + get_dist_mean(aa_un_dist)
    #                 + get_dist_mean(aaa_dist),
    #                 aba_sampled,
    #             )
    #             aba_senders = expected_overlapping(
    #                 num_start,
    #                 num_senders
    #                 - get_dist_mean(aa_sender_dist[i])
    #                 - get_dist_mean(aaa_sender_dist[i])
    #                 - i,
    #                 aba_new,
    #             )
    #             return int(round(aba_senders))

    #         aaa_sender_dist[i] = apply_fn_to_dist(aaa_dist, inside_fn, sub=sub)

    #         aba_dist[i] = combine_dists(
    #             range((num_recurrent * end_max_val) + 1),
    #             ba_cache,
    #             ab_sender_dist[i],
    #             sub=None,
    #         )
    #         aba_sender_dist[i] = apply_fn_to_dist(
    #             aba_dist[i], new_fn_k, sub=sub
    #         )

    #         aaab_dist[i] = combine_dists(
    #             range((start_max_val * num_senders) + 1),
    #             ab_cache,
    #             aaa_sender_dist[i],
    #             sub=None,
    #         )
    #         abab_dist[i] = combine_dists(
    #             range((start_max_val * num_senders) + 1),
    #             ab_cache,
    #             aba_sender_dist[i],
    #             sub=None,
    #         )
    #         aabb_dist[i] = combine_dists(
    #             range((end_inter_max_val * num_end) + 1),
    #             bb_cache,
    #             aab_dist[i],
    #             sub=None,
    #         )
    #         abbb_dist[i] = combine_dists(
    #             range((end_inter_max_val * num_end) + 1),
    #             bb_cache,
    #             abb_dist[i],
    #             sub=None,
    #         )

    #         for j in range(num_end + 1):

    #             def to_app(x):
    #                 return min(
    #                     j + round(expected_non_overlapping(num_end, j, x)),
    #                     num_end,
    #                 )

    #             if j == num_end:
    #                 to_add = OrderedDict()
    #                 to_add[num_end] = 1
    #                 aaab_cache[j] = to_add
    #                 aabb_cache[j] = to_add
    #                 abab_cache[j] = to_add
    #                 abbb_cache[j] = to_add
    #             else:
    #                 aaab_cache[j] = apply_fn_to_dist(
    #                     aaab_dist[i], to_app, sub=sub
    #                 )
    #                 aabb_cache[j] = apply_fn_to_dist(
    #                     aabb_dist[i], to_app, sub=sub
    #                 )
    #                 abab_cache[j] = apply_fn_to_dist(
    #                     abab_dist[i], to_app, sub=sub
    #                 )
    #                 abbb_cache[j] = apply_fn_to_dist(
    #                     abbb_dist[i], to_app, sub=sub
    #                 )

    #         in_prog = OrderedDict()
    #         in_prog = combine_dists(
    #             range(num_end + 1), aaab_cache, final_dist[i], sub=None
    #         )
    #         in_prog = combine_dists(
    #             range(num_end + 1), aabb_cache, in_prog, sub=None
    #         )
    #         in_prog = combine_dists(
    #             range(num_end + 1), abab_cache, in_prog, sub=None
    #         )
    #         in_prog = combine_dists(
    #             range(num_end + 1), abbb_cache, in_prog, sub=None
    #         )
    #         final_dist[i] = in_prog

    # PMF of num senders sampled
    prob_a_senders = OrderedDict()

    for i in range(total_samples + 1):
        prob_a_senders[i] = float(
            hypergeometric_pmf(num_start_probe, num_senders_probe, total_samples, i)
        )

    weighted_dist = combine_dists(
        range(num_end_probe + 1), final_dist, prob_a_senders, sub=None
    )

    return ab_un_dist, weighted_dist</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self, choices, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create connections randomly from model stats.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_connections(self, choices, **kwargs):
    &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
    region_verts = kwargs.get(&#34;region_verts&#34;)
    box = kwargs.get(&#34;box&#34;, False)  # for performance reasons

    if kwargs.get(&#34;use_full_region&#34;, True):
        graph, connected = self.gen_full_graph(choices, region_verts, box)
    else:
        if self.recursive:
            graph, connected = self.gen_graph_recursive(choices, **kwargs)
        else:
            graph, connected = self.gen_graph(choices, **kwargs)

    return graph, connected</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, num_samples, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls static_expected_connections</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expected_connections(self, num_samples, **kwargs):
    &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
    return RecurrentConnectivity.static_expected_connections(
        total_samples=num_samples, **kwargs
    )</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_full_graph"><code class="name flex">
<span>def <span class="ident">gen_full_graph</span></span>(<span>self, choices, region_verts, box)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_full_graph(self, choices, region_verts, box):
    graph = []
    connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
    forward_connections = np.random.choice(
        choices, size=(self.num_senders, self.max_forward), replace=True
    )
    num_choices = np.random.randint(
        self.min_forward,
        self.max_forward + 1,
        dtype=np.int32,
        size=self.num_senders,
    )

    f_idx = 0
    # Create connections between neurons in the same region
    if self.max_inter &gt; 0:
        if box:
            num_boxes = 5
            box_like = 4
            box_size = int(math.ceil(len(region_verts) / num_boxes))
            out_box_size = len(region_verts) - box_size

            # Represents in box being box_like times more likely than outside
            # e.g. for 5
            # x = 5y
            # 1 = (1 / num_boxes) * (5 * y) + (1 - 1 / num_boxes) * y
            y_mult = (1 / num_boxes) * (box_like) + (1 - (1 / num_boxes))
            out_box_mult = 1 / y_mult
            in_box_mult = box_like * out_box_mult
            mult = np.array(
                [
                    (1 / num_boxes) * in_box_mult,
                    (1 - (1 / num_boxes)) * out_box_mult,
                ]
            )
            rand_amt = self.min_inter + (
                np.random.rand() * (self.max_inter - self.min_inter)
            )
            sample_sizes = np.ceil(rand_amt * mult * len(region_verts)).astype(int)

            in_box_idx = np.array([i for i in range(box_size)], dtype=np.int32)
            self_connects_box = np.random.choice(
                in_box_idx,
                size=(len(region_verts), sample_sizes[0]),
                replace=True,
            )

            out_box_idx = np.array(
                [i + box_size for i in range(out_box_size)], dtype=np.int32
            )
            self_connects_outside = np.random.choice(
                out_box_idx,
                size=(len(region_verts), sample_sizes[1]),
                replace=True,
            )

        else:
            self_connects = np.random.choice(
                region_verts,
                size=(
                    len(region_verts),
                    int(round(self.max_inter * len(region_verts))),
                ),
                replace=True,
            )
            num_choices_inter = np.random.randint(
                int(round(self.min_inter * len(region_verts))),
                int(round(self.max_inter * len(region_verts))) + 1,
                dtype=np.int32,
                size=len(region_verts),
            )

    # Create forward_connections and inter_connections
    for i, vert in enumerate(region_verts):
        if self.max_inter &gt; 0:
            if box:
                which_box = int(math.floor(i / box_size))
                a = int(which_box * box_size)

                self_connects_box_i = a + self_connects_box[i]

                self_connects_out_i = self_connects_outside[i]
                self_connects_out_i[
                    self_connects_out_i &lt; (a + box_size)
                ] -= box_size

                self_connections = np.array(
                    list(
                        set(
                            np.concatenate(
                                (self_connects_box_i, self_connects_out_i)
                                + np.min(region_verts)
                            )
                        )
                    ),
                    dtype=np.int32,
                )

            else:
                self_connections = np.array(
                    list(set(self_connects[i, : num_choices_inter[i]])),
                    dtype=np.int32,
                )

            # Remove autaptic synapses
            self_connections = np.delete(
                self_connections, np.where(self_connections == vert)
            )
            for val in self_connections:
                if isinstance(val, float):
                    print(val, self_connections)
                    exit(-1)

        else:
            self_connections = np.array([], dtype=np.int32)

        # Create forward_connections
        if vert in connected:
            forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            f_idx = f_idx + 1

        if isinstance(self_connections, np.int32):
            graph.append(np.array([self_connections], dtype=np.int32))
        else:
            graph.append(self_connections.astype(np.int32))

    return graph, connected</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_graph"><code class="name flex">
<span>def <span class="ident">gen_graph</span></span>(<span>self, choices, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_graph(self, choices, **kwargs):
    def d_minmax(dist):
        vals = list(dist.items())
        return vals[0][0], vals[-1][0]

    graph = []

    region_verts = kwargs.get(&#34;region_verts&#34;)
    idx_inA = kwargs.get(&#34;idx_in_deviceA&#34;)
    idx_outA = list(set(region_verts) - set(idx_inA))
    idx_inB = kwargs.get(&#34;idx_in_deviceB&#34;) + len(region_verts)
    idx_outB = list(set(choices) - set(idx_inB))
    num_senders_device = kwargs.get(&#34;num_senders_probe&#34;)
    num_senders_A = kwargs.get(&#34;num_senders_A&#34;)
    num_senders_B = kwargs.get(&#34;num_senders_B&#34;)
    forward_dist_device = kwargs.get(&#34;out_connections_dist_probe&#34;)
    forwardA_to_Bprobe = kwargs.get(&#34;out_connections_dist_B&#34;)
    forwardAprobe_to_B = kwargs.get(&#34;out_connections_dist_A&#34;)
    start_probe_to_outside = kwargs.get(&#34;start_probe_to_outside&#34;)

    forward_dist_device_min, forward_dist_device_max = d_minmax(forward_dist_device)
    forwardA_to_Bprobe_min, forwardA_to_Bprobe_max = d_minmax(forwardA_to_Bprobe)
    forwardAprobe_to_B_min, forwardAprobe_to_B_max = d_minmax(forwardAprobe_to_B)
    start_probe_to_outside_min, start_probe_to_outside_max = d_minmax(
        start_probe_to_outside
    )

    # A device to B device
    connected_device = np.random.choice(
        idx_inA, size=num_senders_device, replace=False
    )
    forward_connections_device = np.random.choice(
        idx_inB, size=(num_senders_device, forward_dist_device_max), replace=True
    )
    num_choices_device = np.random.randint(
        forward_dist_device_min,
        forward_dist_device_max + 1,
        dtype=np.int32,
        size=num_senders_device,
    )

    # A device to B
    if len(idx_outB) == 0:
        connected_Adevice = []
    else:
        connected_Adevice = np.random.choice(
            idx_inA, size=num_senders_A, replace=False
        )
        forward_connections_Adevice_B = np.random.choice(
            idx_outB, size=(num_senders_A, forwardAprobe_to_B_max), replace=True
        )
        num_choices_Adevice_B = np.random.randint(
            forwardAprobe_to_B_min,
            forwardAprobe_to_B_min + 1,
            dtype=np.int32,
            size=num_senders_A,
        )

    # A to B device
    if len(idx_outA) == 0:
        connected_Bdevice = []
    else:
        connected_Bdevice = np.random.choice(
            idx_outA, size=num_senders_B - num_senders_device, replace=False
        )
        forward_connections_A_Bdevice = np.random.choice(
            idx_inB,
            size=(num_senders_B - num_senders_device, forwardA_to_Bprobe_max),
            replace=True,
        )
        num_choices_A_Bdevice = np.random.randint(
            forwardA_to_Bprobe_min,
            forwardA_to_Bprobe_max + 1,
            dtype=np.int32,
            size=num_senders_B,
        )

    # A interconnections
    self_connects_Adevice = np.random.choice(
        region_verts,
        size=(
            len(idx_inA),
            int(round(start_probe_to_outside_max)),
        ),
        replace=True,
    )
    num_choices_inter_device = np.random.randint(
        int(round(start_probe_to_outside_min)),
        int(round(start_probe_to_outside_max)) + 1,
        dtype=np.int32,
        size=len(idx_inA),
    )
    self_connects_Arest = np.random.choice(
        region_verts,
        size=(
            len(region_verts) - len(idx_inA),
            int(round(self.max_inter * len(region_verts))),
        ),
        replace=True,
    )
    num_choices_inter = np.random.randint(
        int(round(self.min_inter * len(region_verts))),
        int(round(self.max_inter * len(region_verts))) + 1,
        dtype=np.int32,
        size=len(region_verts) - len(idx_inA),
    )

    # Create the connections
    a_idx = 0
    b_idx = 0
    c_idx = 0
    d_idx = 0
    e_idx = 0
    for i, vert in enumerate(region_verts):
        if vert in idx_inA:
            self_connections = np.array(
                list(
                    set(
                        self_connects_Adevice[
                            d_idx, : num_choices_inter_device[d_idx]
                        ]
                    )
                ),
                dtype=np.int32,
            )
            d_idx = d_idx + 1
        else:
            self_connections = np.array(
                list(set(self_connects_Arest[e_idx, : num_choices_inter[e_idx]])),
                dtype=np.int32,
            )
            e_idx = e_idx + 1

        # Remove autaptic synapses
        self_connections = np.delete(
            self_connections, np.where(self_connections == vert)
        )
        for val in self_connections:
            if isinstance(val, float):
                print(val, self_connections)
                exit(-1)

        if vert in connected_device:
            forward_connection = forward_connections_device[
                a_idx, : num_choices_device[a_idx]
            ]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            a_idx = a_idx + 1

        if vert in connected_Adevice:
            forward_connection = forward_connections_Adevice_B[
                b_idx, : num_choices_Adevice_B[b_idx]
            ]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            b_idx = b_idx + 1

        if vert in connected_Bdevice:
            forward_connection = forward_connections_A_Bdevice[
                c_idx, : num_choices_A_Bdevice[c_idx]
            ]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            c_idx = c_idx + 1

        if isinstance(self_connections, np.int32):
            graph.append(np.array([self_connections], dtype=np.int32))
        else:
            graph.append(self_connections.astype(np.int32))

    return (
        graph,
        list(
            set(connected_device) | set(connected_Adevice) | set(connected_Bdevice)
        ),
    )</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_graph_recursive"><code class="name flex">
<span>def <span class="ident">gen_graph_recursive</span></span>(<span>self, choices, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_graph_recursive(self, choices, **kwargs):
    region_verts = kwargs.get(&#34;region_verts&#34;)
    idx_inB = kwargs.get(&#34;idx_in_deviceB&#34;) + len(choices)
    idx_outB = list(set(choices) - set(idx_inB))
    outside_dist_inter = kwargs.get(&#34;end_outside_to_probe&#34;)
    vals = list(outside_dist_inter.items())
    min_inter = vals[0][0]
    max_inter = vals[-1][0]

    graph = []
    connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
    forward_connections = np.random.choice(
        choices, size=(self.num_senders, self.max_forward), replace=True
    )
    num_choices = np.random.randint(
        self.min_forward,
        self.max_forward + 1,
        dtype=np.int32,
        size=self.num_senders,
    )

    f_idx = 0
    # Create connections between neurons in the same region
    if self.max_inter &gt; 0:

        self_connects_outside = np.random.choice(
            idx_outB,
            size=(
                len(region_verts),
                int(round(self.max_inter * len(region_verts))),
            ),
            replace=True,
        )
        num_choices_inter_outside = np.random.randint(
            int(round(self.min_inter * len(region_verts))),
            int(round(self.max_inter * len(region_verts))) + 1,
            dtype=np.int32,
            size=len(region_verts),
        )

        self_connects_inside = np.random.choice(
            idx_inB,
            size=(
                len(region_verts),
                int(round(max_inter * len(region_verts))),
            ),
            replace=True,
        )
        num_choices_inter_inside = np.random.randint(
            int(round(min_inter * len(region_verts))),
            int(round(max_inter * len(region_verts))) + 1,
            dtype=np.int32,
            size=len(region_verts),
        )

    # Create forward_connections and inter_connections
    for i, vert in enumerate(region_verts):
        if self.max_inter &gt; 0:
            self_connections = np.array(
                list(set(self_connects_outside[i, : num_choices_inter_outside[i]])),
                dtype=np.int32,
            )
            self_connections = np.append(
                self_connections,
                np.array(
                    list(
                        set(self_connects_inside[i, : num_choices_inter_inside[i]])
                    ),
                    dtype=np.int32,
                ),
            )

            # Remove autaptic synapses
            self_connections = np.delete(
                self_connections, np.where(self_connections == vert)
            )
            for val in self_connections:
                if isinstance(val, float):
                    print(val, self_connections)
                    exit(-1)

        else:
            self_connections = np.array([], dtype=np.int32)

        # Create forward_connections
        if vert in connected:
            forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            f_idx = f_idx + 1

        if isinstance(self_connections, np.int32):
            graph.append(np.array([self_connections], dtype=np.int32))
        else:
            graph.append(self_connections.astype(np.int32))

    return graph, connected</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity"><code class="flex name class">
<span>class <span class="ident">UniqueConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Random connections where connections don't overlap.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class UniqueConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connections where connections don&#39;t overlap.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        graph = []

        # Choose the forward connectors
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connections = np.random.choice(
                    choices, size=(self.max_forward), replace=False
                )
                forward_connection = forward_connections[: num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return UniqueConnectivity.static_expected_connections(
            total_samples=num_samples, **kwargs
        )

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 1)

        if max_depth &gt; 1:
            raise ValueError(&#34;max_depth must be 1 for unique connections.&#34;)

        num_end = kwargs.get(&#34;N&#34;)
        out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)

        total_samples = kwargs.get(&#34;total_samples&#34;)
        clt_start = kwargs.get(&#34;clt_start&#34;, 30)
        sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

        # Setup required regardless of the depth of the connection

        # Gives dist of num outgoing connections from A
        # This tends towards normal distribution by CLT in most cases

        def fn_to_apply(k):
            return int(round(expected_unique(num_end, k)))

        ab_dist = random_draw_dist(
            total_samples,
            out_connections_dist,
            num_end,
            apply_fn=False,
            keep_all=True,
            clt_start=clt_start,
            sub=sub,
        )

        final_dist = ab_dist

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end + 1), final_dist, prob_a_senders, sub=None
        )

        return ab_dist, weighted_dist</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Return connection distribution.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
    # Parse out the relevant parameters
    max_depth = kwargs.get(&#34;max_depth&#34;, 1)

    if max_depth &gt; 1:
        raise ValueError(&#34;max_depth must be 1 for unique connections.&#34;)

    num_end = kwargs.get(&#34;N&#34;)
    out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
    num_start = kwargs.get(&#34;num_start&#34;)
    num_senders = kwargs.get(&#34;num_senders&#34;)

    total_samples = kwargs.get(&#34;total_samples&#34;)
    clt_start = kwargs.get(&#34;clt_start&#34;, 30)
    sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

    # Setup required regardless of the depth of the connection

    # Gives dist of num outgoing connections from A
    # This tends towards normal distribution by CLT in most cases

    def fn_to_apply(k):
        return int(round(expected_unique(num_end, k)))

    ab_dist = random_draw_dist(
        total_samples,
        out_connections_dist,
        num_end,
        apply_fn=False,
        keep_all=True,
        clt_start=clt_start,
        sub=sub,
    )

    final_dist = ab_dist

    # PMF of num senders sampled
    prob_a_senders = OrderedDict()

    for i in range(total_samples + 1):
        prob_a_senders[i] = float(
            hypergeometric_pmf(num_start, num_senders, total_samples, i)
        )

    weighted_dist = combine_dists(
        range(num_end + 1), final_dist, prob_a_senders, sub=None
    )

    return ab_dist, weighted_dist</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self, choices, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create connections randomly from model stats.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_connections(self, choices, **kwargs):
    &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
    region_verts = kwargs.get(&#34;region_verts&#34;)
    graph = []

    # Choose the forward connectors
    connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
    forward_connections = np.random.choice(
        choices, size=(self.num_senders, self.max_forward), replace=True
    )
    num_choices = np.random.randint(
        self.min_forward,
        self.max_forward + 1,
        dtype=np.int32,
        size=self.num_senders,
    )

    f_idx = 0
    # Create forward_connections and inter_connections
    for i, vert in enumerate(region_verts):
        self_connections = np.array([], dtype=np.int32)

        # Create forward_connections
        if vert in connected:
            forward_connections = np.random.choice(
                choices, size=(self.max_forward), replace=False
            )
            forward_connection = forward_connections[: num_choices[f_idx]]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            f_idx = f_idx + 1

        if isinstance(self_connections, np.int32):
            graph.append(np.array([self_connections], dtype=np.int32))
        else:
            graph.append(self_connections.astype(np.int32))

    return graph, connected</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, num_samples, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls static_expected_connections</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expected_connections(self, num_samples, **kwargs):
    &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
    return UniqueConnectivity.static_expected_connections(
        total_samples=num_samples, **kwargs
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="neuroconnect" href="index.html">neuroconnect</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.get_by_name" href="#neuroconnect.connectivity_patterns.get_by_name">get_by_name</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy.create_connections" href="#neuroconnect.connectivity_patterns.ConnectionStrategy.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy.expected_connections" href="#neuroconnect.connectivity_patterns.ConnectionStrategy.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy.static_expected_connections" href="#neuroconnect.connectivity_patterns.ConnectionStrategy.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity" href="#neuroconnect.connectivity_patterns.MatrixConnectivity">MatrixConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.compute_probe_stats" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.compute_probe_stats">compute_probe_stats</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.compute_stats" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.compute_stats">compute_stats</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.gen_random_samples" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.gen_random_samples">gen_random_samples</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.load" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.load">load</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.static_expected_connections">static_expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.subsample" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.subsample">subsample</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity" href="#neuroconnect.connectivity_patterns.MeanRecurrentConnectivity">MeanRecurrentConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.MeanRecurrentConnectivity.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_full_graph" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_full_graph">gen_full_graph</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_graph" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_graph">gen_graph</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_graph_recursive" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.gen_graph_recursive">gen_graph_recursive</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.nfmt" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.nfmt">nfmt</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity" href="#neuroconnect.connectivity_patterns.UniqueConnectivity">UniqueConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.UniqueConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.UniqueConnectivity.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.UniqueConnectivity.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>