<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>neuroconnect.connectivity_patterns API documentation</title>
<meta name="description" content="Abstract class setting the functions needed to define connections." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>neuroconnect.connectivity_patterns</code></h1>
</header>
<section id="section-intro">
<p>Abstract class setting the functions needed to define connections.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Abstract class setting the functions needed to define connections.&#34;&#34;&#34;

from abc import ABC, abstractmethod
import math
from collections import OrderedDict

from mpmath import nstr
from scipy import sparse
import numpy as np

from .connect_math import (
    expected_unique,
    expected_non_overlapping,
    expected_overlapping,
    random_draw_dist,
    hypergeometric_pmf,
    get_dist_mean,
    apply_fn_to_dist,
    create_uniform,
    nfold_conv,
    convolution,
    combine_dists,
    create_normal,
    get_uniform_moments,
    get_dist_var,
)
from .simple_graph import from_matrix


def get_by_name(name):
    &#34;&#34;&#34;Retrieve a connection strategy by name.&#34;&#34;&#34;
    classes = {
        &#34;recurrent_connectivity&#34;: RecurrentConnectivity,
        &#34;matrix_connectivity&#34;: MatrixConnectivity,
        &#34;mean_connectivity&#34;: MeanRecurrentConnectivity,
        &#34;unique_connectivity&#34;: UniqueConnectivity,
    }
    return classes[name]


class ConnectionStrategy(ABC):
    &#34;&#34;&#34;
    Abstract class to describe the connection strategy between two regions.

    Must define:
    1. create_connections:
        How to form connections between neurons in the regions.
        Expected to return graph, connections
    2. expected_connections:
        How many connections would be expected between neurons in the regions.
    3. static_expected_connections:
        An interface into expected_connections that can be statically called.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        super().__init__()
        pass

    @abstractmethod
    def create_connections(self, *args, **kwargs):
        &#34;&#34;&#34;How to form connections between neurons in the regions.&#34;&#34;&#34;
        pass

    @abstractmethod
    def expected_connections(self, *args, **kwargs):
        &#34;&#34;&#34;The distribution of connections.&#34;&#34;&#34;
        pass

    @staticmethod
    @abstractmethod
    def static_expected_connections(*args, **kwargs):
        &#34;&#34;&#34;The distribution of connections called statically.&#34;&#34;&#34;
        pass


class UniqueConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connections where connections don&#39;t overlap.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        graph = []

        # Choose the forward connectors
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connections = np.random.choice(
                    choices, size=(self.max_forward), replace=False
                )
                forward_connection = forward_connections[: num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return RecurrentConnectivity.static_expected_connections(num_samples, **kwargs)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 1)

        if max_depth &gt; 1:
            raise ValueError(&#34;max_depth must be 1 for unique connections.&#34;)

        num_end = kwargs.get(&#34;N&#34;)
        out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)

        total_samples = kwargs.get(&#34;total_samples&#34;)
        clt_start = kwargs.get(&#34;clt_start&#34;, 30)
        sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

        # Setup required regardless of the depth of the connection

        # Gives dist of num outgoing connections from A
        # This tends towards normal distribution by CLT in most cases

        def fn_to_apply(k):
            return int(round(expected_unique(num_end, k)))

        ab_dist = random_draw_dist(
            total_samples,
            out_connections_dist,
            num_end,
            apply_fn=False,
            keep_all=True,
            clt_start=clt_start,
            sub=sub,
        )

        final_dist = ab_dist

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end + 1), final_dist, prob_a_senders, sub=None
        )

        return ab_dist, weighted_dist


class RecurrentConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connection with recursive connections and interconnections allowed.

    In this, a certain number of neurons output a random number of connections
    to completely random neurons with repetition possible.
    This handles both forward and backward connections.
    interconnections are handled by randomly sampling a set of
    neurons for each neuron.
    The rate at which interconnected synapses are formed is kept fixed
    but the number of connections varies as multiple synapses can be formed.
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_inter = kwargs.get(&#34;min_inter&#34;)
        self.max_inter = kwargs.get(&#34;max_inter&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        box = kwargs.get(&#34;box&#34;, False)  # for performance reasons

        graph = []

        # Choose the forward connectors
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create connections between neurons in the same region
        if self.max_inter &gt; 0:
            if box:
                num_boxes = 5
                box_like = 4
                box_size = int(math.ceil(len(region_verts) / num_boxes))
                out_box_size = len(region_verts) - box_size

                # Represents in box being box_like times more likely than outside
                # e.g. for 5
                # x = 5y
                # 1 = (1 / num_boxes) * (5 * y) + (1 - 1 / num_boxes) * y
                y_mult = (1 / num_boxes) * (box_like) + (1 - (1 / num_boxes))
                out_box_mult = 1 / y_mult
                in_box_mult = box_like * out_box_mult
                mult = np.array(
                    [
                        (1 / num_boxes) * in_box_mult,
                        (1 - (1 / num_boxes)) * out_box_mult,
                    ]
                )
                rand_amt = self.min_inter + (
                    np.random.rand() * (self.max_inter - self.min_inter)
                )
                sample_sizes = np.ceil(rand_amt * mult * len(region_verts)).astype(int)

                in_box_idx = np.array([i for i in range(box_size)], dtype=np.int32)
                self_connects_box = np.random.choice(
                    in_box_idx, size=(len(region_verts), sample_sizes[0]), replace=True,
                )

                out_box_idx = np.array(
                    [i + box_size for i in range(out_box_size)], dtype=np.int32
                )
                self_connects_outside = np.random.choice(
                    out_box_idx,
                    size=(len(region_verts), sample_sizes[1]),
                    replace=True,
                )

            else:
                self_connects = np.random.choice(
                    region_verts,
                    size=(
                        len(region_verts),
                        int(round(self.max_inter * len(region_verts))),
                    ),
                    replace=True,
                )
                num_choices_inter = np.random.randint(
                    int(round(self.min_inter * len(region_verts))),
                    int(round(self.max_inter * len(region_verts))) + 1,
                    dtype=np.int32,
                    size=len(region_verts),
                )

        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            if self.max_inter &gt; 0:
                if box:
                    which_box = int(math.floor(i / box_size))
                    a = int(which_box * box_size)

                    self_connects_box_i = a + self_connects_box[i]

                    self_connects_out_i = self_connects_outside[i]
                    self_connects_out_i[
                        self_connects_out_i &lt; (a + box_size)
                    ] -= box_size

                    self_connections = np.array(
                        list(
                            set(
                                np.concatenate(
                                    (self_connects_box_i, self_connects_out_i)
                                    + np.min(region_verts)
                                )
                            )
                        ),
                        dtype=np.int32,
                    )

                else:
                    self_connections = np.array(
                        list(set(self_connects[i, : num_choices_inter[i]])),
                        dtype=np.int32,
                    )

                # Remove autaptic synapses
                self_connections = np.delete(
                    self_connections, np.where(self_connections == vert)
                )
                for val in self_connections:
                    if isinstance(val, float):
                        print(val, self_connections)
                        exit(-1)

            else:
                self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return RecurrentConnectivity.static_expected_connections(num_samples, **kwargs)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 3)

        if max_depth &gt; 3:
            raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

        use_mean = kwargs.get(&#34;use_mean&#34;, True)
        if use_mean and (max_depth &gt; 1):
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        else:
            if max_depth &gt;= 1:
                num_end = kwargs.get(&#34;N&#34;)
                out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
                num_start = kwargs.get(&#34;num_start&#34;)
                num_senders = kwargs.get(&#34;num_senders&#34;)

                total_samples = kwargs.get(&#34;total_samples&#34;)
                clt_start = kwargs.get(&#34;clt_start&#34;, 30)
                sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

                # Setup required regardless of the depth of the connection

                # Gives dist of num outgoing connections from A
                # This tends towards normal distribution by CLT in most cases

                def fn_to_apply(k):
                    # Ideally, here would use float if large var dist, and int otherwise.
                    # Not a huge difference though
                    # return expected_unique(num_end, k, do_round=False)
                    return expected_unique(num_end, k, do_round=True)

                ab_dist = random_draw_dist(
                    total_samples,
                    out_connections_dist,
                    num_end,
                    apply_fn=False,
                    keep_all=True,
                    clt_start=clt_start,
                    sub=sub,
                )

                dists = OrderedDict()
                for k, v in ab_dist.items():
                    dists[k] = apply_fn_to_dist(v, fn_to_apply, sub=sub)
                ab_un_dist = dists
                final_dist = ab_un_dist

            if max_depth &gt;= 2:
                final_dist = OrderedDict()
                start_inter_dist = kwargs.get(&#34;start_inter_dist&#34;)
                end_inter_dist = kwargs.get(&#34;end_inter_dist&#34;)
                start_mean = get_dist_mean(out_connections_dist)
                start_var = get_dist_var(out_connections_dist)

                start_inter_mean = get_dist_mean(start_inter_dist)
                start_inter_var = get_dist_var(start_inter_dist)
                end_inter_mean = get_dist_mean(end_inter_dist)
                end_inter_var = get_dist_var(end_inter_dist)

                ab_cache = OrderedDict()
                ab_cache[0] = OrderedDict()
                ab_cache[0][0] = 1.0
                start_max_val = max(list(out_connections_dist.keys()))
                for i in range(1, num_senders + 1):
                    if i &lt; clt_start:
                        ab_cache[i] = convolution(
                            out_connections_dist, ab_cache[i - 1], sub=sub
                        )
                    else:
                        ab_cache[i] = create_normal(
                            range((start_max_val * i) + 1),
                            start_mean * i,
                            start_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                bb_cache = OrderedDict()
                bb_cache[0] = OrderedDict()
                bb_cache[0][0] = 1.0
                end_inter_max_val = max(list(end_inter_dist.keys()))
                for i in range(1, num_end + 1):
                    if i &lt; clt_start:
                        bb_cache[i] = convolution(
                            end_inter_dist, bb_cache[i - 1], sub=sub
                        )
                    else:
                        bb_cache[i] = create_normal(
                            range((end_inter_max_val * i) + 1),
                            end_inter_mean * i,
                            end_inter_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                # AAB calculation
                if total_samples &lt; clt_start:
                    aa_dist = nfold_conv([start_inter_dist] * total_samples, sub=sub)
                else:
                    max_val = max(list(start_inter_dist.keys()))
                    aa_dist = create_normal(
                        range((max_val * total_samples) + 1),
                        start_inter_mean * total_samples,
                        start_inter_var * total_samples,
                        sub=sub,
                        interp_after=True,
                    )
                aa_sender_dist = OrderedDict()

                aab_dist = OrderedDict()
                abb_dist = OrderedDict()

                for i in range(total_samples + 1):

                    def inside_fn(x):
                        aa_sampled = expected_unique(num_start, x)
                        aa_new = expected_non_overlapping(
                            num_start, total_samples, aa_sampled
                        )
                        aa_senders = expected_overlapping(
                            num_start, num_senders - i, aa_new,
                        )
                        return int(round(aa_senders))

                    aa_sender_dist[i] = apply_fn_to_dist(aa_dist, inside_fn, sub=sub)

                    aab_dist[i] = combine_dists(
                        range((start_max_val * num_senders) + 1),
                        ab_cache,
                        aa_sender_dist[i],
                        sub=None,
                    )
                    abb_dist[i] = combine_dists(
                        range((end_inter_max_val * num_end) + 1),
                        bb_cache,
                        ab_un_dist[i],
                        sub=None,
                    )
                    aab_dist[i] = apply_fn_to_dist(aab_dist[i], fn_to_apply, sub=sub)
                    abb_dist[i] = apply_fn_to_dist(abb_dist[i], fn_to_apply, sub=sub)

                    aab_cache = OrderedDict()
                    abb_cache = OrderedDict()

                    for j in range(num_end + 1):

                        def to_app(x):
                            return min(
                                j + round(expected_non_overlapping(num_end, j, x)),
                                num_end,
                            )

                        if j == num_end:
                            to_add = OrderedDict()
                            to_add[num_end] = 1
                            aab_cache[j] = to_add
                            abb_cache[j] = to_add
                        else:
                            aab_cache[j] = apply_fn_to_dist(
                                aab_dist[i], to_app, sub=sub
                            )
                            abb_cache[j] = apply_fn_to_dist(
                                abb_dist[i], to_app, sub=sub
                            )

                    in_prog = OrderedDict()
                    in_prog = combine_dists(
                        range(num_end + 1), aab_cache, ab_un_dist[i], sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), abb_cache, in_prog, sub=None
                    )
                    final_dist[i] = in_prog

            if max_depth &gt;= 3:
                recurrent_connections_dist = kwargs.get(&#34;recurrent_connections_dist&#34;)
                num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
                end_mean = get_dist_mean(recurrent_connections_dist)
                end_var = get_dist_var(recurrent_connections_dist)

                aaab_dist = OrderedDict()
                aabb_dist = OrderedDict()
                abbb_dist = OrderedDict()
                abab_dist = OrderedDict()

                aaab_cache = OrderedDict()
                aabb_cache = OrderedDict()
                abbb_cache = OrderedDict()
                abab_cache = OrderedDict()

                aa_cache = OrderedDict()
                aa_cache[0] = OrderedDict()
                aa_cache[0][0] = 1.0
                start_inter_max_val = max(list(start_inter_dist.keys()))
                for i in range(1, num_start + 1):
                    if i &lt; clt_start:
                        aa_cache[i] = convolution(
                            start_inter_dist, aa_cache[i - 1], sub=sub
                        )
                    else:
                        aa_cache[i] = create_normal(
                            range((start_inter_max_val * i) + 1),
                            start_inter_mean * i,
                            start_inter_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                ba_cache = OrderedDict()
                ba_cache[0] = OrderedDict()
                ba_cache[0][0] = 1.0
                end_max_val = max(list(recurrent_connections_dist.keys()))
                for i in range(1, num_recurrent + 1):
                    if i &lt; clt_start:
                        ba_cache[i] = convolution(
                            recurrent_connections_dist, ba_cache[i - 1], sub=sub
                        )
                    else:
                        ba_cache[i] = create_normal(
                            range((end_max_val * i) + 1),
                            end_mean * i,
                            end_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                ab_sender_dist = OrderedDict()

                def new_fn(x):
                    return int(round(expected_overlapping(num_end, num_recurrent, x)))

                for k, v in ab_un_dist.items():
                    ab_sender_dist[k] = apply_fn_to_dist(v, new_fn, sub=sub)

                aaa_sender_dist = OrderedDict()

                def new_fn(x):
                    return int(round(expected_unique(num_start, x)))

                aa_un_dist = apply_fn_to_dist(aa_dist, new_fn, sub=sub)
                aaa_dist = combine_dists(
                    range((num_start * start_inter_max_val * start_inter_max_val) + 1),
                    aa_cache,
                    aa_un_dist,
                    sub=None,
                )

                aba_dist = OrderedDict()
                aba_sender_dist = OrderedDict()

                for i in range(total_samples + 1):

                    def inside_fn(x):
                        aaa_sampled = expected_unique(num_start, x)
                        aaa_new = expected_non_overlapping(
                            num_start,
                            total_samples + get_dist_mean(aa_un_dist),
                            aaa_sampled,
                        )
                        aaa_senders = expected_overlapping(
                            num_start,
                            num_senders - get_dist_mean(aa_sender_dist[i]) - i,
                            aaa_new,
                        )
                        return int(round(aaa_senders))

                    def new_fn_k(x):
                        aba_sampled = expected_unique(num_start, x)
                        aba_new = expected_non_overlapping(
                            num_start,
                            total_samples
                            + get_dist_mean(aa_un_dist)
                            + get_dist_mean(aaa_dist),
                            aba_sampled,
                        )
                        aba_senders = expected_overlapping(
                            num_start,
                            num_senders
                            - get_dist_mean(aa_sender_dist[i])
                            - get_dist_mean(aaa_sender_dist[i])
                            - i,
                            aba_new,
                        )
                        return int(round(aba_senders))

                    aaa_sender_dist[i] = apply_fn_to_dist(aaa_dist, inside_fn, sub=sub)

                    aba_dist[i] = combine_dists(
                        range((num_recurrent * end_max_val) + 1),
                        ba_cache,
                        ab_sender_dist[i],
                        sub=None,
                    )
                    aba_sender_dist[i] = apply_fn_to_dist(
                        aba_dist[i], new_fn_k, sub=sub
                    )

                    aaab_dist[i] = combine_dists(
                        range((start_max_val * num_senders) + 1),
                        ab_cache,
                        aaa_sender_dist[i],
                        sub=None,
                    )
                    abab_dist[i] = combine_dists(
                        range((start_max_val * num_senders) + 1),
                        ab_cache,
                        aba_sender_dist[i],
                        sub=None,
                    )
                    aabb_dist[i] = combine_dists(
                        range((end_inter_max_val * num_end) + 1),
                        bb_cache,
                        aab_dist[i],
                        sub=None,
                    )
                    abbb_dist[i] = combine_dists(
                        range((end_inter_max_val * num_end) + 1),
                        bb_cache,
                        abb_dist[i],
                        sub=None,
                    )

                    for j in range(num_end + 1):

                        def to_app(x):
                            return min(
                                j + round(expected_non_overlapping(num_end, j, x)),
                                num_end,
                            )

                        if j == num_end:
                            to_add = OrderedDict()
                            to_add[num_end] = 1
                            aaab_cache[j] = to_add
                            aabb_cache[j] = to_add
                            abab_cache[j] = to_add
                            abbb_cache[j] = to_add
                        else:
                            aaab_cache[j] = apply_fn_to_dist(
                                aaab_dist[i], to_app, sub=sub
                            )
                            aabb_cache[j] = apply_fn_to_dist(
                                aabb_dist[i], to_app, sub=sub
                            )
                            abab_cache[j] = apply_fn_to_dist(
                                abab_dist[i], to_app, sub=sub
                            )
                            abbb_cache[j] = apply_fn_to_dist(
                                abbb_dist[i], to_app, sub=sub
                            )

                    in_prog = OrderedDict()
                    in_prog = combine_dists(
                        range(num_end + 1), aaab_cache, final_dist[i], sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), aabb_cache, in_prog, sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), abab_cache, in_prog, sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), abbb_cache, in_prog, sub=None
                    )
                    final_dist[i] = in_prog

            # PMF of num senders sampled
            prob_a_senders = OrderedDict()

            for i in range(total_samples + 1):
                prob_a_senders[i] = float(
                    hypergeometric_pmf(num_start, num_senders, total_samples, i)
                )

            weighted_dist = combine_dists(
                range(num_end + 1), final_dist, prob_a_senders, sub=None
            )

            return dists, weighted_dist

    @staticmethod
    def nfmt(start, *args):
        start = str(start) + &#34;: (&#34;
        for arg in args:
            start = start + nstr(arg, 5) + &#34;, &#34;
        start = start[:-2] + &#34;)&#34;

        return start


class MeanRecurrentConnectivity(RecurrentConnectivity):
    &#34;&#34;&#34;
    Similar to RecurrentConnectivity, but uses the mean instead of full dists.

    In this way, it is less accurate than the RecurrentConnectivity, but it will
    be faster to compute, and can be performed without knowledge of the variance
    of the underlying distribution.

    &#34;&#34;&#34;

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return MeanRecurrentConnectivity.static_expected_connections(
            num_samples, **kwargs
        )

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Distribution of connections from the mean.&#34;&#34;&#34;
        num_end = kwargs.get(&#34;N&#34;)
        num_connections = get_dist_mean(kwargs.get(&#34;out_connections_dist&#34;))
        num_recurrent_synapses = get_dist_mean(kwargs.get(&#34;recurrent_connections_dist&#34;))
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)
        num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
        inter_connections_start = get_dist_mean(kwargs.get(&#34;start_inter_dist&#34;))
        inter_connections_end = get_dist_mean(kwargs.get(&#34;end_inter_dist&#34;))
        total_samples = kwargs.get(&#34;total_samples&#34;)
        max_depth = kwargs.get(&#34;max_depth&#34;, 3)

        plist = []
        if max_depth &gt; 3:
            raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

        dists = OrderedDict()
        for num_sender_samples in range(total_samples + 1):
            final = 0
            if max_depth &gt;= 1:
                # AB
                ab = expected_unique(num_end, num_sender_samples * num_connections)
                plist.append(ab)
                final = final + ab

            if max_depth &gt;= 2:
                # AAB
                aa_sampled = expected_unique(
                    num_start, total_samples * inter_connections_start
                )
                aa_new = expected_non_overlapping(num_start, total_samples, aa_sampled)
                aa_senders = expected_overlapping(
                    num_start, max(num_senders - num_sender_samples, 0), aa_new,
                )
                aab_total = expected_unique(num_end, aa_senders * num_connections)
                aab_less_ab = expected_non_overlapping(num_end, final, aab_total)
                plist.append(aab_total)
                final = final + aab_less_ab

                # ABB
                abb_total = expected_unique(num_end, ab * inter_connections_end)
                abb_less_prev = expected_non_overlapping(num_end, final, abb_total)
                plist.append(abb_total)
                final = final + abb_less_prev

            if max_depth &gt;= 3:
                # AAAB
                aaa_sampled = expected_unique(
                    num_start, aa_sampled * inter_connections_start
                )
                aaa_new = expected_non_overlapping(
                    num_start, aa_new + total_samples, aaa_sampled
                )
                aaa_senders = expected_overlapping(
                    num_start,
                    max(num_senders - (aa_senders + num_sender_samples), 0),
                    aaa_new,
                )
                aaab_total = expected_unique(num_end, aaa_senders * num_connections)
                aaab_less_prev = expected_non_overlapping(num_end, final, aaab_total)
                plist.append(aaab_total)
                final = final + aaab_less_prev

                # AABB
                aabb_total = expected_unique(
                    num_end, aab_less_ab * inter_connections_end
                )
                aabb_less_prev = expected_non_overlapping(num_end, final, aabb_total)
                plist.append(aabb_total)
                final = final + aabb_less_prev

                # ABAB
                ab_recurrent = expected_overlapping(num_end, num_recurrent, ab)
                aba = expected_unique(num_start, ab_recurrent * num_recurrent_synapses)
                aba_new = expected_non_overlapping(
                    num_start, aaa_new + aa_new + total_samples, aba
                )
                aba_send_connections = expected_overlapping(
                    num_start,
                    num_senders - (aaa_senders + aa_senders + num_sender_samples),
                    aba_new,
                )
                abab_total = expected_unique(
                    num_end, aba_send_connections * num_connections
                )
                abab_less_prev = expected_non_overlapping(num_end, final, abab_total)
                plist.append(abab_total)
                final = final + abab_less_prev

                # ABBB
                abb_new = expected_non_overlapping(num_end, aab_less_ab, abb_less_prev)
                abbb_total = expected_unique(num_end, abb_new * inter_connections_end)
                abbb_less_prev = expected_non_overlapping(num_end, final, abbb_total)
                plist.append(abbb_total)
                final = final + abbb_less_prev
            dists[num_sender_samples] = OrderedDict()
            dists[num_sender_samples][int(final)] = 1.0

        # Sums the above distributions to get the marginal
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(range(num_end + 1), dists, prob_a_senders)

        return dists, weighted_dist


class MatrixConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Connections from sparse matrices describing the connectivity.

    Attributes
    ----------
    self.ab : scipy.sparse.csr_matrix
        sparse matrix describing forward connections
    self.ba : scipy.sparse.csr_matrix
        sparse matrix describing backward connections
    self.aa : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.bb : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.to_use : list of bool
        Which matrices to use in the order [ab, ba, aa, bb]
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.ab = kwargs.get(&#34;ab&#34;)
        self.ba = kwargs.get(&#34;ba&#34;)
        self.aa = kwargs.get(&#34;aa&#34;)
        self.bb = kwargs.get(&#34;bb&#34;)
        self.to_use = kwargs.get(&#34;to_use&#34;, [True, True, True, True])

        self.load()

        self.num_a, self.num_b = self.ab.shape
        self.a_indices = np.array([i for i in range(self.num_a)])
        self.b_indices = np.array([i for i in range(self.num_b)])

    def load(self):
        &#34;&#34;&#34;Load the sparse matrices if they are paths to npz files.&#34;&#34;&#34;
        if self.to_use[0]:
            if isinstance(self.ab, str):
                self.ab = sparse.load_npz(self.ab)
        if self.to_use[1]:
            if isinstance(self.ba, str):
                self.ba = sparse.load_npz(self.ba)
        if self.to_use[2]:
            if isinstance(self.aa, str):
                self.aa = sparse.load_npz(self.aa)
        if self.to_use[3]:
            if isinstance(self.bb, str):
                self.bb = sparse.load_npz(self.bb)

    def create_connections(self):
        &#34;&#34;&#34;Create a simple graph representation from the matrices.&#34;&#34;&#34;
        self.graph = from_matrix(self.ab, self.ba, self.aa, self.bb, self.to_use)

    def compute_stats(self):
        &#34;&#34;&#34;Compute descriptive stats on the matrix connectivity.&#34;&#34;&#34;
        args_dict = {}
        args_dict[&#34;N&#34;] = self.num_b
        args_dict[&#34;num_start&#34;] = self.num_a
        if self.to_use[0]:
            ab_sum = np.squeeze(np.array(self.ab.sum(axis=1).astype(np.int64)))
            self.num_senders = np.count_nonzero(ab_sum)
            args_dict[&#34;num_senders&#34;] = self.num_senders
            self.num_connections = OrderedDict()
            dist = np.bincount(ab_sum)
            for i in range(int(np.amin(ab_sum[ab_sum != 0])), int(np.amax(ab_sum) + 1)):
                self.num_connections[i] = dist[i] / float(self.num_senders)
            args_dict[&#34;out_connections_dist&#34;] = self.num_connections
        if self.to_use[1]:
            ba_sum = np.squeeze(np.array(self.ba.sum(axis=1).astype(np.int64)))
            self.num_recurrent = np.count_nonzero(ba_sum)
            args_dict[&#34;num_recurrent&#34;] = self.num_recurrent
            dist = np.bincount(ba_sum)
            self.num_recurrent_connections = OrderedDict()
            for i in range(int(np.amin(ba_sum[ba_sum != 0])), int(np.amax(ba_sum) + 1)):
                self.num_recurrent_connections[i] = dist[i] / float(self.num_recurrent)
            args_dict[&#34;recurrent_connections_dist&#34;] = self.num_recurrent_connections
        if self.to_use[2]:
            aa_sum = np.squeeze(np.array(self.aa.sum(axis=1).astype(np.int64)))
            dist = np.bincount(aa_sum)
            total = aa_sum.shape[0]
            self.inter_connections_start = OrderedDict()
            for i in range(int(np.amin(aa_sum)), int(np.amax(aa_sum) + 1)):
                self.inter_connections_start[i] = dist[i] / float(total)
            args_dict[&#34;start_inter_dist&#34;] = self.inter_connections_start
        if self.to_use[3]:
            bb_sum = np.squeeze(np.array(self.bb.sum(axis=1).astype(np.int64)))
            dist = np.bincount(bb_sum)
            total = bb_sum.shape[0]
            self.inter_connections_end = OrderedDict()
            for i in range(int(np.amin(bb_sum)), int(np.amax(bb_sum) + 1)):
                self.inter_connections_end[i] = dist[i] / float(total)
            args_dict[&#34;end_inter_dist&#34;] = self.inter_connections_end

        return args_dict

    def expected_connections(self, total_samples, max_depth):
        &#34;&#34;&#34;Call to static_expected_connections.&#34;&#34;&#34;
        args_dict = self.compute_stats()
        args_dict[&#34;total_samples&#34;] = total_samples
        args_dict[&#34;max_depth&#34;] = max_depth
        return MatrixConnectivity.static_expected_connections(**args_dict)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Calls RecurrentConnectivity with the matrix stats.&#34;&#34;&#34;
        if kwargs.get(&#34;mean_estimate&#34;, False) is True:
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        else:
            return RecurrentConnectivity.static_expected_connections(**kwargs)

    def subsample(self, num_a, num_b):
        &#34;&#34;&#34;Subsample the connectivity matrices.&#34;&#34;&#34;
        a_samples, b_samples = self.gen_random_samples((num_a, num_b))

        if self.to_use[0]:
            ab_grid = np.ix_(a_samples, b_samples)
            ab = self.ab[ab_grid]
        if self.to_use[1]:
            ba_grid = np.ix_(b_samples, a_samples)
            ba = self.ba[ba_grid]
        if self.to_use[2]:
            aa_grid = np.ix_(a_samples, a_samples)
            aa = self.aa[aa_grid]
        if self.to_use[3]:
            bb_grid = np.ix_(b_samples, b_samples)
            bb = self.bb[bb_grid]

        new_mc = MatrixConnectivity(aa=aa, bb=bb, ab=ab, ba=ba, to_use=self.to_use,)

        return new_mc

    def gen_random_samples(self, num_sampled, zeroed=True):
        &#34;&#34;&#34;Generate random sample indices from both regions.&#34;&#34;&#34;
        start = np.random.choice(self.a_indices, size=num_sampled[0], replace=False)
        end = np.random.choice(self.b_indices, size=num_sampled[1], replace=False)
        if not zeroed:
            end = end + self.num_a

        return start, end

    def __str__(self):
        return f&#34;AA: {self.aa.shape}, BB: {self.bb.shape}, AB: {self.ab.shape}, BA: {self.ba.shape}&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="neuroconnect.connectivity_patterns.get_by_name"><code class="name flex">
<span>def <span class="ident">get_by_name</span></span>(<span>name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve a connection strategy by name.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_by_name(name):
    &#34;&#34;&#34;Retrieve a connection strategy by name.&#34;&#34;&#34;
    classes = {
        &#34;recurrent_connectivity&#34;: RecurrentConnectivity,
        &#34;matrix_connectivity&#34;: MatrixConnectivity,
        &#34;mean_connectivity&#34;: MeanRecurrentConnectivity,
        &#34;unique_connectivity&#34;: UniqueConnectivity,
    }
    return classes[name]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy"><code class="flex name class">
<span>class <span class="ident">ConnectionStrategy</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Abstract class to describe the connection strategy between two regions.</p>
<p>Must define:
1. create_connections:
How to form connections between neurons in the regions.
Expected to return graph, connections
2. expected_connections:
How many connections would be expected between neurons in the regions.
3. static_expected_connections:
An interface into expected_connections that can be statically called.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConnectionStrategy(ABC):
    &#34;&#34;&#34;
    Abstract class to describe the connection strategy between two regions.

    Must define:
    1. create_connections:
        How to form connections between neurons in the regions.
        Expected to return graph, connections
    2. expected_connections:
        How many connections would be expected between neurons in the regions.
    3. static_expected_connections:
        An interface into expected_connections that can be statically called.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        super().__init__()
        pass

    @abstractmethod
    def create_connections(self, *args, **kwargs):
        &#34;&#34;&#34;How to form connections between neurons in the regions.&#34;&#34;&#34;
        pass

    @abstractmethod
    def expected_connections(self, *args, **kwargs):
        &#34;&#34;&#34;The distribution of connections.&#34;&#34;&#34;
        pass

    @staticmethod
    @abstractmethod
    def static_expected_connections(*args, **kwargs):
        &#34;&#34;&#34;The distribution of connections called statically.&#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.MatrixConnectivity" href="#neuroconnect.connectivity_patterns.MatrixConnectivity">MatrixConnectivity</a></li>
<li><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></li>
<li><a title="neuroconnect.connectivity_patterns.UniqueConnectivity" href="#neuroconnect.connectivity_patterns.UniqueConnectivity">UniqueConnectivity</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>The distribution of connections called statically.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@abstractmethod
def static_expected_connections(*args, **kwargs):
    &#34;&#34;&#34;The distribution of connections called statically.&#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>How to form connections between neurons in the regions.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def create_connections(self, *args, **kwargs):
    &#34;&#34;&#34;How to form connections between neurons in the regions.&#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.ConnectionStrategy.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>The distribution of connections.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def expected_connections(self, *args, **kwargs):
    &#34;&#34;&#34;The distribution of connections.&#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity"><code class="flex name class">
<span>class <span class="ident">MatrixConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Connections from sparse matrices describing the connectivity.</p>
<h2 id="attributes">Attributes</h2>
<p>self.ab : scipy.sparse.csr_matrix
sparse matrix describing forward connections
self.ba : scipy.sparse.csr_matrix
sparse matrix describing backward connections
self.aa : scipy.sparse.csr_matrix
sparse matrix describing self connections
self.bb : scipy.sparse.csr_matrix
sparse matrix describing self connections
self.to_use : list of bool
Which matrices to use in the order [ab, ba, aa, bb]</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MatrixConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Connections from sparse matrices describing the connectivity.

    Attributes
    ----------
    self.ab : scipy.sparse.csr_matrix
        sparse matrix describing forward connections
    self.ba : scipy.sparse.csr_matrix
        sparse matrix describing backward connections
    self.aa : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.bb : scipy.sparse.csr_matrix
        sparse matrix describing self connections
    self.to_use : list of bool
        Which matrices to use in the order [ab, ba, aa, bb]
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.ab = kwargs.get(&#34;ab&#34;)
        self.ba = kwargs.get(&#34;ba&#34;)
        self.aa = kwargs.get(&#34;aa&#34;)
        self.bb = kwargs.get(&#34;bb&#34;)
        self.to_use = kwargs.get(&#34;to_use&#34;, [True, True, True, True])

        self.load()

        self.num_a, self.num_b = self.ab.shape
        self.a_indices = np.array([i for i in range(self.num_a)])
        self.b_indices = np.array([i for i in range(self.num_b)])

    def load(self):
        &#34;&#34;&#34;Load the sparse matrices if they are paths to npz files.&#34;&#34;&#34;
        if self.to_use[0]:
            if isinstance(self.ab, str):
                self.ab = sparse.load_npz(self.ab)
        if self.to_use[1]:
            if isinstance(self.ba, str):
                self.ba = sparse.load_npz(self.ba)
        if self.to_use[2]:
            if isinstance(self.aa, str):
                self.aa = sparse.load_npz(self.aa)
        if self.to_use[3]:
            if isinstance(self.bb, str):
                self.bb = sparse.load_npz(self.bb)

    def create_connections(self):
        &#34;&#34;&#34;Create a simple graph representation from the matrices.&#34;&#34;&#34;
        self.graph = from_matrix(self.ab, self.ba, self.aa, self.bb, self.to_use)

    def compute_stats(self):
        &#34;&#34;&#34;Compute descriptive stats on the matrix connectivity.&#34;&#34;&#34;
        args_dict = {}
        args_dict[&#34;N&#34;] = self.num_b
        args_dict[&#34;num_start&#34;] = self.num_a
        if self.to_use[0]:
            ab_sum = np.squeeze(np.array(self.ab.sum(axis=1).astype(np.int64)))
            self.num_senders = np.count_nonzero(ab_sum)
            args_dict[&#34;num_senders&#34;] = self.num_senders
            self.num_connections = OrderedDict()
            dist = np.bincount(ab_sum)
            for i in range(int(np.amin(ab_sum[ab_sum != 0])), int(np.amax(ab_sum) + 1)):
                self.num_connections[i] = dist[i] / float(self.num_senders)
            args_dict[&#34;out_connections_dist&#34;] = self.num_connections
        if self.to_use[1]:
            ba_sum = np.squeeze(np.array(self.ba.sum(axis=1).astype(np.int64)))
            self.num_recurrent = np.count_nonzero(ba_sum)
            args_dict[&#34;num_recurrent&#34;] = self.num_recurrent
            dist = np.bincount(ba_sum)
            self.num_recurrent_connections = OrderedDict()
            for i in range(int(np.amin(ba_sum[ba_sum != 0])), int(np.amax(ba_sum) + 1)):
                self.num_recurrent_connections[i] = dist[i] / float(self.num_recurrent)
            args_dict[&#34;recurrent_connections_dist&#34;] = self.num_recurrent_connections
        if self.to_use[2]:
            aa_sum = np.squeeze(np.array(self.aa.sum(axis=1).astype(np.int64)))
            dist = np.bincount(aa_sum)
            total = aa_sum.shape[0]
            self.inter_connections_start = OrderedDict()
            for i in range(int(np.amin(aa_sum)), int(np.amax(aa_sum) + 1)):
                self.inter_connections_start[i] = dist[i] / float(total)
            args_dict[&#34;start_inter_dist&#34;] = self.inter_connections_start
        if self.to_use[3]:
            bb_sum = np.squeeze(np.array(self.bb.sum(axis=1).astype(np.int64)))
            dist = np.bincount(bb_sum)
            total = bb_sum.shape[0]
            self.inter_connections_end = OrderedDict()
            for i in range(int(np.amin(bb_sum)), int(np.amax(bb_sum) + 1)):
                self.inter_connections_end[i] = dist[i] / float(total)
            args_dict[&#34;end_inter_dist&#34;] = self.inter_connections_end

        return args_dict

    def expected_connections(self, total_samples, max_depth):
        &#34;&#34;&#34;Call to static_expected_connections.&#34;&#34;&#34;
        args_dict = self.compute_stats()
        args_dict[&#34;total_samples&#34;] = total_samples
        args_dict[&#34;max_depth&#34;] = max_depth
        return MatrixConnectivity.static_expected_connections(**args_dict)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Calls RecurrentConnectivity with the matrix stats.&#34;&#34;&#34;
        if kwargs.get(&#34;mean_estimate&#34;, False) is True:
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        else:
            return RecurrentConnectivity.static_expected_connections(**kwargs)

    def subsample(self, num_a, num_b):
        &#34;&#34;&#34;Subsample the connectivity matrices.&#34;&#34;&#34;
        a_samples, b_samples = self.gen_random_samples((num_a, num_b))

        if self.to_use[0]:
            ab_grid = np.ix_(a_samples, b_samples)
            ab = self.ab[ab_grid]
        if self.to_use[1]:
            ba_grid = np.ix_(b_samples, a_samples)
            ba = self.ba[ba_grid]
        if self.to_use[2]:
            aa_grid = np.ix_(a_samples, a_samples)
            aa = self.aa[aa_grid]
        if self.to_use[3]:
            bb_grid = np.ix_(b_samples, b_samples)
            bb = self.bb[bb_grid]

        new_mc = MatrixConnectivity(aa=aa, bb=bb, ab=ab, ba=ba, to_use=self.to_use,)

        return new_mc

    def gen_random_samples(self, num_sampled, zeroed=True):
        &#34;&#34;&#34;Generate random sample indices from both regions.&#34;&#34;&#34;
        start = np.random.choice(self.a_indices, size=num_sampled[0], replace=False)
        end = np.random.choice(self.b_indices, size=num_sampled[1], replace=False)
        if not zeroed:
            end = end + self.num_a

        return start, end

    def __str__(self):
        return f&#34;AA: {self.aa.shape}, BB: {self.bb.shape}, AB: {self.ab.shape}, BA: {self.ba.shape}&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calls RecurrentConnectivity with the matrix stats.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Calls RecurrentConnectivity with the matrix stats.&#34;&#34;&#34;
    if kwargs.get(&#34;mean_estimate&#34;, False) is True:
        return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
    else:
        return RecurrentConnectivity.static_expected_connections(**kwargs)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.compute_stats"><code class="name flex">
<span>def <span class="ident">compute_stats</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Compute descriptive stats on the matrix connectivity.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_stats(self):
    &#34;&#34;&#34;Compute descriptive stats on the matrix connectivity.&#34;&#34;&#34;
    args_dict = {}
    args_dict[&#34;N&#34;] = self.num_b
    args_dict[&#34;num_start&#34;] = self.num_a
    if self.to_use[0]:
        ab_sum = np.squeeze(np.array(self.ab.sum(axis=1).astype(np.int64)))
        self.num_senders = np.count_nonzero(ab_sum)
        args_dict[&#34;num_senders&#34;] = self.num_senders
        self.num_connections = OrderedDict()
        dist = np.bincount(ab_sum)
        for i in range(int(np.amin(ab_sum[ab_sum != 0])), int(np.amax(ab_sum) + 1)):
            self.num_connections[i] = dist[i] / float(self.num_senders)
        args_dict[&#34;out_connections_dist&#34;] = self.num_connections
    if self.to_use[1]:
        ba_sum = np.squeeze(np.array(self.ba.sum(axis=1).astype(np.int64)))
        self.num_recurrent = np.count_nonzero(ba_sum)
        args_dict[&#34;num_recurrent&#34;] = self.num_recurrent
        dist = np.bincount(ba_sum)
        self.num_recurrent_connections = OrderedDict()
        for i in range(int(np.amin(ba_sum[ba_sum != 0])), int(np.amax(ba_sum) + 1)):
            self.num_recurrent_connections[i] = dist[i] / float(self.num_recurrent)
        args_dict[&#34;recurrent_connections_dist&#34;] = self.num_recurrent_connections
    if self.to_use[2]:
        aa_sum = np.squeeze(np.array(self.aa.sum(axis=1).astype(np.int64)))
        dist = np.bincount(aa_sum)
        total = aa_sum.shape[0]
        self.inter_connections_start = OrderedDict()
        for i in range(int(np.amin(aa_sum)), int(np.amax(aa_sum) + 1)):
            self.inter_connections_start[i] = dist[i] / float(total)
        args_dict[&#34;start_inter_dist&#34;] = self.inter_connections_start
    if self.to_use[3]:
        bb_sum = np.squeeze(np.array(self.bb.sum(axis=1).astype(np.int64)))
        dist = np.bincount(bb_sum)
        total = bb_sum.shape[0]
        self.inter_connections_end = OrderedDict()
        for i in range(int(np.amin(bb_sum)), int(np.amax(bb_sum) + 1)):
            self.inter_connections_end[i] = dist[i] / float(total)
        args_dict[&#34;end_inter_dist&#34;] = self.inter_connections_end

    return args_dict</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Create a simple graph representation from the matrices.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_connections(self):
    &#34;&#34;&#34;Create a simple graph representation from the matrices.&#34;&#34;&#34;
    self.graph = from_matrix(self.ab, self.ba, self.aa, self.bb, self.to_use)</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, total_samples, max_depth)</span>
</code></dt>
<dd>
<section class="desc"><p>Call to static_expected_connections.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expected_connections(self, total_samples, max_depth):
    &#34;&#34;&#34;Call to static_expected_connections.&#34;&#34;&#34;
    args_dict = self.compute_stats()
    args_dict[&#34;total_samples&#34;] = total_samples
    args_dict[&#34;max_depth&#34;] = max_depth
    return MatrixConnectivity.static_expected_connections(**args_dict)</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.gen_random_samples"><code class="name flex">
<span>def <span class="ident">gen_random_samples</span></span>(<span>self, num_sampled, zeroed=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Generate random sample indices from both regions.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_random_samples(self, num_sampled, zeroed=True):
    &#34;&#34;&#34;Generate random sample indices from both regions.&#34;&#34;&#34;
    start = np.random.choice(self.a_indices, size=num_sampled[0], replace=False)
    end = np.random.choice(self.b_indices, size=num_sampled[1], replace=False)
    if not zeroed:
        end = end + self.num_a

    return start, end</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Load the sparse matrices if they are paths to npz files.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(self):
    &#34;&#34;&#34;Load the sparse matrices if they are paths to npz files.&#34;&#34;&#34;
    if self.to_use[0]:
        if isinstance(self.ab, str):
            self.ab = sparse.load_npz(self.ab)
    if self.to_use[1]:
        if isinstance(self.ba, str):
            self.ba = sparse.load_npz(self.ba)
    if self.to_use[2]:
        if isinstance(self.aa, str):
            self.aa = sparse.load_npz(self.aa)
    if self.to_use[3]:
        if isinstance(self.bb, str):
            self.bb = sparse.load_npz(self.bb)</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.MatrixConnectivity.subsample"><code class="name flex">
<span>def <span class="ident">subsample</span></span>(<span>self, num_a, num_b)</span>
</code></dt>
<dd>
<section class="desc"><p>Subsample the connectivity matrices.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subsample(self, num_a, num_b):
    &#34;&#34;&#34;Subsample the connectivity matrices.&#34;&#34;&#34;
    a_samples, b_samples = self.gen_random_samples((num_a, num_b))

    if self.to_use[0]:
        ab_grid = np.ix_(a_samples, b_samples)
        ab = self.ab[ab_grid]
    if self.to_use[1]:
        ba_grid = np.ix_(b_samples, a_samples)
        ba = self.ba[ba_grid]
    if self.to_use[2]:
        aa_grid = np.ix_(a_samples, a_samples)
        aa = self.aa[aa_grid]
    if self.to_use[3]:
        bb_grid = np.ix_(b_samples, b_samples)
        bb = self.bb[bb_grid]

    new_mc = MatrixConnectivity(aa=aa, bb=bb, ab=ab, ba=ba, to_use=self.to_use,)

    return new_mc</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity"><code class="flex name class">
<span>class <span class="ident">MeanRecurrentConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Similar to RecurrentConnectivity, but uses the mean instead of full dists.</p>
<p>In this way, it is less accurate than the RecurrentConnectivity, but it will
be faster to compute, and can be performed without knowledge of the variance
of the underlying distribution.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MeanRecurrentConnectivity(RecurrentConnectivity):
    &#34;&#34;&#34;
    Similar to RecurrentConnectivity, but uses the mean instead of full dists.

    In this way, it is less accurate than the RecurrentConnectivity, but it will
    be faster to compute, and can be performed without knowledge of the variance
    of the underlying distribution.

    &#34;&#34;&#34;

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return MeanRecurrentConnectivity.static_expected_connections(
            num_samples, **kwargs
        )

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Distribution of connections from the mean.&#34;&#34;&#34;
        num_end = kwargs.get(&#34;N&#34;)
        num_connections = get_dist_mean(kwargs.get(&#34;out_connections_dist&#34;))
        num_recurrent_synapses = get_dist_mean(kwargs.get(&#34;recurrent_connections_dist&#34;))
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)
        num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
        inter_connections_start = get_dist_mean(kwargs.get(&#34;start_inter_dist&#34;))
        inter_connections_end = get_dist_mean(kwargs.get(&#34;end_inter_dist&#34;))
        total_samples = kwargs.get(&#34;total_samples&#34;)
        max_depth = kwargs.get(&#34;max_depth&#34;, 3)

        plist = []
        if max_depth &gt; 3:
            raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

        dists = OrderedDict()
        for num_sender_samples in range(total_samples + 1):
            final = 0
            if max_depth &gt;= 1:
                # AB
                ab = expected_unique(num_end, num_sender_samples * num_connections)
                plist.append(ab)
                final = final + ab

            if max_depth &gt;= 2:
                # AAB
                aa_sampled = expected_unique(
                    num_start, total_samples * inter_connections_start
                )
                aa_new = expected_non_overlapping(num_start, total_samples, aa_sampled)
                aa_senders = expected_overlapping(
                    num_start, max(num_senders - num_sender_samples, 0), aa_new,
                )
                aab_total = expected_unique(num_end, aa_senders * num_connections)
                aab_less_ab = expected_non_overlapping(num_end, final, aab_total)
                plist.append(aab_total)
                final = final + aab_less_ab

                # ABB
                abb_total = expected_unique(num_end, ab * inter_connections_end)
                abb_less_prev = expected_non_overlapping(num_end, final, abb_total)
                plist.append(abb_total)
                final = final + abb_less_prev

            if max_depth &gt;= 3:
                # AAAB
                aaa_sampled = expected_unique(
                    num_start, aa_sampled * inter_connections_start
                )
                aaa_new = expected_non_overlapping(
                    num_start, aa_new + total_samples, aaa_sampled
                )
                aaa_senders = expected_overlapping(
                    num_start,
                    max(num_senders - (aa_senders + num_sender_samples), 0),
                    aaa_new,
                )
                aaab_total = expected_unique(num_end, aaa_senders * num_connections)
                aaab_less_prev = expected_non_overlapping(num_end, final, aaab_total)
                plist.append(aaab_total)
                final = final + aaab_less_prev

                # AABB
                aabb_total = expected_unique(
                    num_end, aab_less_ab * inter_connections_end
                )
                aabb_less_prev = expected_non_overlapping(num_end, final, aabb_total)
                plist.append(aabb_total)
                final = final + aabb_less_prev

                # ABAB
                ab_recurrent = expected_overlapping(num_end, num_recurrent, ab)
                aba = expected_unique(num_start, ab_recurrent * num_recurrent_synapses)
                aba_new = expected_non_overlapping(
                    num_start, aaa_new + aa_new + total_samples, aba
                )
                aba_send_connections = expected_overlapping(
                    num_start,
                    num_senders - (aaa_senders + aa_senders + num_sender_samples),
                    aba_new,
                )
                abab_total = expected_unique(
                    num_end, aba_send_connections * num_connections
                )
                abab_less_prev = expected_non_overlapping(num_end, final, abab_total)
                plist.append(abab_total)
                final = final + abab_less_prev

                # ABBB
                abb_new = expected_non_overlapping(num_end, aab_less_ab, abb_less_prev)
                abbb_total = expected_unique(num_end, abb_new * inter_connections_end)
                abbb_less_prev = expected_non_overlapping(num_end, final, abbb_total)
                plist.append(abbb_total)
                final = final + abbb_less_prev
            dists[num_sender_samples] = OrderedDict()
            dists[num_sender_samples][int(final)] = 1.0

        # Sums the above distributions to get the marginal
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(range(num_end + 1), dists, prob_a_senders)

        return dists, weighted_dist</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></li>
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Distribution of connections from the mean.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Distribution of connections from the mean.&#34;&#34;&#34;
    num_end = kwargs.get(&#34;N&#34;)
    num_connections = get_dist_mean(kwargs.get(&#34;out_connections_dist&#34;))
    num_recurrent_synapses = get_dist_mean(kwargs.get(&#34;recurrent_connections_dist&#34;))
    num_start = kwargs.get(&#34;num_start&#34;)
    num_senders = kwargs.get(&#34;num_senders&#34;)
    num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
    inter_connections_start = get_dist_mean(kwargs.get(&#34;start_inter_dist&#34;))
    inter_connections_end = get_dist_mean(kwargs.get(&#34;end_inter_dist&#34;))
    total_samples = kwargs.get(&#34;total_samples&#34;)
    max_depth = kwargs.get(&#34;max_depth&#34;, 3)

    plist = []
    if max_depth &gt; 3:
        raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

    dists = OrderedDict()
    for num_sender_samples in range(total_samples + 1):
        final = 0
        if max_depth &gt;= 1:
            # AB
            ab = expected_unique(num_end, num_sender_samples * num_connections)
            plist.append(ab)
            final = final + ab

        if max_depth &gt;= 2:
            # AAB
            aa_sampled = expected_unique(
                num_start, total_samples * inter_connections_start
            )
            aa_new = expected_non_overlapping(num_start, total_samples, aa_sampled)
            aa_senders = expected_overlapping(
                num_start, max(num_senders - num_sender_samples, 0), aa_new,
            )
            aab_total = expected_unique(num_end, aa_senders * num_connections)
            aab_less_ab = expected_non_overlapping(num_end, final, aab_total)
            plist.append(aab_total)
            final = final + aab_less_ab

            # ABB
            abb_total = expected_unique(num_end, ab * inter_connections_end)
            abb_less_prev = expected_non_overlapping(num_end, final, abb_total)
            plist.append(abb_total)
            final = final + abb_less_prev

        if max_depth &gt;= 3:
            # AAAB
            aaa_sampled = expected_unique(
                num_start, aa_sampled * inter_connections_start
            )
            aaa_new = expected_non_overlapping(
                num_start, aa_new + total_samples, aaa_sampled
            )
            aaa_senders = expected_overlapping(
                num_start,
                max(num_senders - (aa_senders + num_sender_samples), 0),
                aaa_new,
            )
            aaab_total = expected_unique(num_end, aaa_senders * num_connections)
            aaab_less_prev = expected_non_overlapping(num_end, final, aaab_total)
            plist.append(aaab_total)
            final = final + aaab_less_prev

            # AABB
            aabb_total = expected_unique(
                num_end, aab_less_ab * inter_connections_end
            )
            aabb_less_prev = expected_non_overlapping(num_end, final, aabb_total)
            plist.append(aabb_total)
            final = final + aabb_less_prev

            # ABAB
            ab_recurrent = expected_overlapping(num_end, num_recurrent, ab)
            aba = expected_unique(num_start, ab_recurrent * num_recurrent_synapses)
            aba_new = expected_non_overlapping(
                num_start, aaa_new + aa_new + total_samples, aba
            )
            aba_send_connections = expected_overlapping(
                num_start,
                num_senders - (aaa_senders + aa_senders + num_sender_samples),
                aba_new,
            )
            abab_total = expected_unique(
                num_end, aba_send_connections * num_connections
            )
            abab_less_prev = expected_non_overlapping(num_end, final, abab_total)
            plist.append(abab_total)
            final = final + abab_less_prev

            # ABBB
            abb_new = expected_non_overlapping(num_end, aab_less_ab, abb_less_prev)
            abbb_total = expected_unique(num_end, abb_new * inter_connections_end)
            abbb_less_prev = expected_non_overlapping(num_end, final, abbb_total)
            plist.append(abbb_total)
            final = final + abbb_less_prev
        dists[num_sender_samples] = OrderedDict()
        dists[num_sender_samples][int(final)] = 1.0

    # Sums the above distributions to get the marginal
    prob_a_senders = OrderedDict()

    for i in range(total_samples + 1):
        prob_a_senders[i] = float(
            hypergeometric_pmf(num_start, num_senders, total_samples, i)
        )

    weighted_dist = combine_dists(range(num_end + 1), dists, prob_a_senders)

    return dists, weighted_dist</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></b></code>:
<ul class="hlist">
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections">expected_connections</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity"><code class="flex name class">
<span>class <span class="ident">RecurrentConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Random connection with recursive connections and interconnections allowed.</p>
<p>In this, a certain number of neurons output a random number of connections
to completely random neurons with repetition possible.
This handles both forward and backward connections.
interconnections are handled by randomly sampling a set of
neurons for each neuron.
The rate at which interconnected synapses are formed is kept fixed
but the number of connections varies as multiple synapses can be formed.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RecurrentConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connection with recursive connections and interconnections allowed.

    In this, a certain number of neurons output a random number of connections
    to completely random neurons with repetition possible.
    This handles both forward and backward connections.
    interconnections are handled by randomly sampling a set of
    neurons for each neuron.
    The rate at which interconnected synapses are formed is kept fixed
    but the number of connections varies as multiple synapses can be formed.
    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_inter = kwargs.get(&#34;min_inter&#34;)
        self.max_inter = kwargs.get(&#34;max_inter&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        box = kwargs.get(&#34;box&#34;, False)  # for performance reasons

        graph = []

        # Choose the forward connectors
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create connections between neurons in the same region
        if self.max_inter &gt; 0:
            if box:
                num_boxes = 5
                box_like = 4
                box_size = int(math.ceil(len(region_verts) / num_boxes))
                out_box_size = len(region_verts) - box_size

                # Represents in box being box_like times more likely than outside
                # e.g. for 5
                # x = 5y
                # 1 = (1 / num_boxes) * (5 * y) + (1 - 1 / num_boxes) * y
                y_mult = (1 / num_boxes) * (box_like) + (1 - (1 / num_boxes))
                out_box_mult = 1 / y_mult
                in_box_mult = box_like * out_box_mult
                mult = np.array(
                    [
                        (1 / num_boxes) * in_box_mult,
                        (1 - (1 / num_boxes)) * out_box_mult,
                    ]
                )
                rand_amt = self.min_inter + (
                    np.random.rand() * (self.max_inter - self.min_inter)
                )
                sample_sizes = np.ceil(rand_amt * mult * len(region_verts)).astype(int)

                in_box_idx = np.array([i for i in range(box_size)], dtype=np.int32)
                self_connects_box = np.random.choice(
                    in_box_idx, size=(len(region_verts), sample_sizes[0]), replace=True,
                )

                out_box_idx = np.array(
                    [i + box_size for i in range(out_box_size)], dtype=np.int32
                )
                self_connects_outside = np.random.choice(
                    out_box_idx,
                    size=(len(region_verts), sample_sizes[1]),
                    replace=True,
                )

            else:
                self_connects = np.random.choice(
                    region_verts,
                    size=(
                        len(region_verts),
                        int(round(self.max_inter * len(region_verts))),
                    ),
                    replace=True,
                )
                num_choices_inter = np.random.randint(
                    int(round(self.min_inter * len(region_verts))),
                    int(round(self.max_inter * len(region_verts))) + 1,
                    dtype=np.int32,
                    size=len(region_verts),
                )

        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            if self.max_inter &gt; 0:
                if box:
                    which_box = int(math.floor(i / box_size))
                    a = int(which_box * box_size)

                    self_connects_box_i = a + self_connects_box[i]

                    self_connects_out_i = self_connects_outside[i]
                    self_connects_out_i[
                        self_connects_out_i &lt; (a + box_size)
                    ] -= box_size

                    self_connections = np.array(
                        list(
                            set(
                                np.concatenate(
                                    (self_connects_box_i, self_connects_out_i)
                                    + np.min(region_verts)
                                )
                            )
                        ),
                        dtype=np.int32,
                    )

                else:
                    self_connections = np.array(
                        list(set(self_connects[i, : num_choices_inter[i]])),
                        dtype=np.int32,
                    )

                # Remove autaptic synapses
                self_connections = np.delete(
                    self_connections, np.where(self_connections == vert)
                )
                for val in self_connections:
                    if isinstance(val, float):
                        print(val, self_connections)
                        exit(-1)

            else:
                self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return RecurrentConnectivity.static_expected_connections(num_samples, **kwargs)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 3)

        if max_depth &gt; 3:
            raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

        use_mean = kwargs.get(&#34;use_mean&#34;, True)
        if use_mean and (max_depth &gt; 1):
            return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
        else:
            if max_depth &gt;= 1:
                num_end = kwargs.get(&#34;N&#34;)
                out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
                num_start = kwargs.get(&#34;num_start&#34;)
                num_senders = kwargs.get(&#34;num_senders&#34;)

                total_samples = kwargs.get(&#34;total_samples&#34;)
                clt_start = kwargs.get(&#34;clt_start&#34;, 30)
                sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

                # Setup required regardless of the depth of the connection

                # Gives dist of num outgoing connections from A
                # This tends towards normal distribution by CLT in most cases

                def fn_to_apply(k):
                    # Ideally, here would use float if large var dist, and int otherwise.
                    # Not a huge difference though
                    # return expected_unique(num_end, k, do_round=False)
                    return expected_unique(num_end, k, do_round=True)

                ab_dist = random_draw_dist(
                    total_samples,
                    out_connections_dist,
                    num_end,
                    apply_fn=False,
                    keep_all=True,
                    clt_start=clt_start,
                    sub=sub,
                )

                dists = OrderedDict()
                for k, v in ab_dist.items():
                    dists[k] = apply_fn_to_dist(v, fn_to_apply, sub=sub)
                ab_un_dist = dists
                final_dist = ab_un_dist

            if max_depth &gt;= 2:
                final_dist = OrderedDict()
                start_inter_dist = kwargs.get(&#34;start_inter_dist&#34;)
                end_inter_dist = kwargs.get(&#34;end_inter_dist&#34;)
                start_mean = get_dist_mean(out_connections_dist)
                start_var = get_dist_var(out_connections_dist)

                start_inter_mean = get_dist_mean(start_inter_dist)
                start_inter_var = get_dist_var(start_inter_dist)
                end_inter_mean = get_dist_mean(end_inter_dist)
                end_inter_var = get_dist_var(end_inter_dist)

                ab_cache = OrderedDict()
                ab_cache[0] = OrderedDict()
                ab_cache[0][0] = 1.0
                start_max_val = max(list(out_connections_dist.keys()))
                for i in range(1, num_senders + 1):
                    if i &lt; clt_start:
                        ab_cache[i] = convolution(
                            out_connections_dist, ab_cache[i - 1], sub=sub
                        )
                    else:
                        ab_cache[i] = create_normal(
                            range((start_max_val * i) + 1),
                            start_mean * i,
                            start_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                bb_cache = OrderedDict()
                bb_cache[0] = OrderedDict()
                bb_cache[0][0] = 1.0
                end_inter_max_val = max(list(end_inter_dist.keys()))
                for i in range(1, num_end + 1):
                    if i &lt; clt_start:
                        bb_cache[i] = convolution(
                            end_inter_dist, bb_cache[i - 1], sub=sub
                        )
                    else:
                        bb_cache[i] = create_normal(
                            range((end_inter_max_val * i) + 1),
                            end_inter_mean * i,
                            end_inter_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                # AAB calculation
                if total_samples &lt; clt_start:
                    aa_dist = nfold_conv([start_inter_dist] * total_samples, sub=sub)
                else:
                    max_val = max(list(start_inter_dist.keys()))
                    aa_dist = create_normal(
                        range((max_val * total_samples) + 1),
                        start_inter_mean * total_samples,
                        start_inter_var * total_samples,
                        sub=sub,
                        interp_after=True,
                    )
                aa_sender_dist = OrderedDict()

                aab_dist = OrderedDict()
                abb_dist = OrderedDict()

                for i in range(total_samples + 1):

                    def inside_fn(x):
                        aa_sampled = expected_unique(num_start, x)
                        aa_new = expected_non_overlapping(
                            num_start, total_samples, aa_sampled
                        )
                        aa_senders = expected_overlapping(
                            num_start, num_senders - i, aa_new,
                        )
                        return int(round(aa_senders))

                    aa_sender_dist[i] = apply_fn_to_dist(aa_dist, inside_fn, sub=sub)

                    aab_dist[i] = combine_dists(
                        range((start_max_val * num_senders) + 1),
                        ab_cache,
                        aa_sender_dist[i],
                        sub=None,
                    )
                    abb_dist[i] = combine_dists(
                        range((end_inter_max_val * num_end) + 1),
                        bb_cache,
                        ab_un_dist[i],
                        sub=None,
                    )
                    aab_dist[i] = apply_fn_to_dist(aab_dist[i], fn_to_apply, sub=sub)
                    abb_dist[i] = apply_fn_to_dist(abb_dist[i], fn_to_apply, sub=sub)

                    aab_cache = OrderedDict()
                    abb_cache = OrderedDict()

                    for j in range(num_end + 1):

                        def to_app(x):
                            return min(
                                j + round(expected_non_overlapping(num_end, j, x)),
                                num_end,
                            )

                        if j == num_end:
                            to_add = OrderedDict()
                            to_add[num_end] = 1
                            aab_cache[j] = to_add
                            abb_cache[j] = to_add
                        else:
                            aab_cache[j] = apply_fn_to_dist(
                                aab_dist[i], to_app, sub=sub
                            )
                            abb_cache[j] = apply_fn_to_dist(
                                abb_dist[i], to_app, sub=sub
                            )

                    in_prog = OrderedDict()
                    in_prog = combine_dists(
                        range(num_end + 1), aab_cache, ab_un_dist[i], sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), abb_cache, in_prog, sub=None
                    )
                    final_dist[i] = in_prog

            if max_depth &gt;= 3:
                recurrent_connections_dist = kwargs.get(&#34;recurrent_connections_dist&#34;)
                num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
                end_mean = get_dist_mean(recurrent_connections_dist)
                end_var = get_dist_var(recurrent_connections_dist)

                aaab_dist = OrderedDict()
                aabb_dist = OrderedDict()
                abbb_dist = OrderedDict()
                abab_dist = OrderedDict()

                aaab_cache = OrderedDict()
                aabb_cache = OrderedDict()
                abbb_cache = OrderedDict()
                abab_cache = OrderedDict()

                aa_cache = OrderedDict()
                aa_cache[0] = OrderedDict()
                aa_cache[0][0] = 1.0
                start_inter_max_val = max(list(start_inter_dist.keys()))
                for i in range(1, num_start + 1):
                    if i &lt; clt_start:
                        aa_cache[i] = convolution(
                            start_inter_dist, aa_cache[i - 1], sub=sub
                        )
                    else:
                        aa_cache[i] = create_normal(
                            range((start_inter_max_val * i) + 1),
                            start_inter_mean * i,
                            start_inter_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                ba_cache = OrderedDict()
                ba_cache[0] = OrderedDict()
                ba_cache[0][0] = 1.0
                end_max_val = max(list(recurrent_connections_dist.keys()))
                for i in range(1, num_recurrent + 1):
                    if i &lt; clt_start:
                        ba_cache[i] = convolution(
                            recurrent_connections_dist, ba_cache[i - 1], sub=sub
                        )
                    else:
                        ba_cache[i] = create_normal(
                            range((end_max_val * i) + 1),
                            end_mean * i,
                            end_var * i,
                            sub=sub,
                            interp_after=True,
                        )

                ab_sender_dist = OrderedDict()

                def new_fn(x):
                    return int(round(expected_overlapping(num_end, num_recurrent, x)))

                for k, v in ab_un_dist.items():
                    ab_sender_dist[k] = apply_fn_to_dist(v, new_fn, sub=sub)

                aaa_sender_dist = OrderedDict()

                def new_fn(x):
                    return int(round(expected_unique(num_start, x)))

                aa_un_dist = apply_fn_to_dist(aa_dist, new_fn, sub=sub)
                aaa_dist = combine_dists(
                    range((num_start * start_inter_max_val * start_inter_max_val) + 1),
                    aa_cache,
                    aa_un_dist,
                    sub=None,
                )

                aba_dist = OrderedDict()
                aba_sender_dist = OrderedDict()

                for i in range(total_samples + 1):

                    def inside_fn(x):
                        aaa_sampled = expected_unique(num_start, x)
                        aaa_new = expected_non_overlapping(
                            num_start,
                            total_samples + get_dist_mean(aa_un_dist),
                            aaa_sampled,
                        )
                        aaa_senders = expected_overlapping(
                            num_start,
                            num_senders - get_dist_mean(aa_sender_dist[i]) - i,
                            aaa_new,
                        )
                        return int(round(aaa_senders))

                    def new_fn_k(x):
                        aba_sampled = expected_unique(num_start, x)
                        aba_new = expected_non_overlapping(
                            num_start,
                            total_samples
                            + get_dist_mean(aa_un_dist)
                            + get_dist_mean(aaa_dist),
                            aba_sampled,
                        )
                        aba_senders = expected_overlapping(
                            num_start,
                            num_senders
                            - get_dist_mean(aa_sender_dist[i])
                            - get_dist_mean(aaa_sender_dist[i])
                            - i,
                            aba_new,
                        )
                        return int(round(aba_senders))

                    aaa_sender_dist[i] = apply_fn_to_dist(aaa_dist, inside_fn, sub=sub)

                    aba_dist[i] = combine_dists(
                        range((num_recurrent * end_max_val) + 1),
                        ba_cache,
                        ab_sender_dist[i],
                        sub=None,
                    )
                    aba_sender_dist[i] = apply_fn_to_dist(
                        aba_dist[i], new_fn_k, sub=sub
                    )

                    aaab_dist[i] = combine_dists(
                        range((start_max_val * num_senders) + 1),
                        ab_cache,
                        aaa_sender_dist[i],
                        sub=None,
                    )
                    abab_dist[i] = combine_dists(
                        range((start_max_val * num_senders) + 1),
                        ab_cache,
                        aba_sender_dist[i],
                        sub=None,
                    )
                    aabb_dist[i] = combine_dists(
                        range((end_inter_max_val * num_end) + 1),
                        bb_cache,
                        aab_dist[i],
                        sub=None,
                    )
                    abbb_dist[i] = combine_dists(
                        range((end_inter_max_val * num_end) + 1),
                        bb_cache,
                        abb_dist[i],
                        sub=None,
                    )

                    for j in range(num_end + 1):

                        def to_app(x):
                            return min(
                                j + round(expected_non_overlapping(num_end, j, x)),
                                num_end,
                            )

                        if j == num_end:
                            to_add = OrderedDict()
                            to_add[num_end] = 1
                            aaab_cache[j] = to_add
                            aabb_cache[j] = to_add
                            abab_cache[j] = to_add
                            abbb_cache[j] = to_add
                        else:
                            aaab_cache[j] = apply_fn_to_dist(
                                aaab_dist[i], to_app, sub=sub
                            )
                            aabb_cache[j] = apply_fn_to_dist(
                                aabb_dist[i], to_app, sub=sub
                            )
                            abab_cache[j] = apply_fn_to_dist(
                                abab_dist[i], to_app, sub=sub
                            )
                            abbb_cache[j] = apply_fn_to_dist(
                                abbb_dist[i], to_app, sub=sub
                            )

                    in_prog = OrderedDict()
                    in_prog = combine_dists(
                        range(num_end + 1), aaab_cache, final_dist[i], sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), aabb_cache, in_prog, sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), abab_cache, in_prog, sub=None
                    )
                    in_prog = combine_dists(
                        range(num_end + 1), abbb_cache, in_prog, sub=None
                    )
                    final_dist[i] = in_prog

            # PMF of num senders sampled
            prob_a_senders = OrderedDict()

            for i in range(total_samples + 1):
                prob_a_senders[i] = float(
                    hypergeometric_pmf(num_start, num_senders, total_samples, i)
                )

            weighted_dist = combine_dists(
                range(num_end + 1), final_dist, prob_a_senders, sub=None
            )

            return dists, weighted_dist

    @staticmethod
    def nfmt(start, *args):
        start = str(start) + &#34;: (&#34;
        for arg in args:
            start = start + nstr(arg, 5) + &#34;, &#34;
        start = start[:-2] + &#34;)&#34;

        return start</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity" href="#neuroconnect.connectivity_patterns.MeanRecurrentConnectivity">MeanRecurrentConnectivity</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.nfmt"><code class="name flex">
<span>def <span class="ident">nfmt</span></span>(<span>start, *args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def nfmt(start, *args):
    start = str(start) + &#34;: (&#34;
    for arg in args:
        start = start + nstr(arg, 5) + &#34;, &#34;
    start = start[:-2] + &#34;)&#34;

    return start</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Return connection distribution.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
    # Parse out the relevant parameters
    max_depth = kwargs.get(&#34;max_depth&#34;, 3)

    if max_depth &gt; 3:
        raise ValueError(&#34;max_depth must be less than 4 currently.&#34;)

    use_mean = kwargs.get(&#34;use_mean&#34;, True)
    if use_mean and (max_depth &gt; 1):
        return MeanRecurrentConnectivity.static_expected_connections(**kwargs)
    else:
        if max_depth &gt;= 1:
            num_end = kwargs.get(&#34;N&#34;)
            out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
            num_start = kwargs.get(&#34;num_start&#34;)
            num_senders = kwargs.get(&#34;num_senders&#34;)

            total_samples = kwargs.get(&#34;total_samples&#34;)
            clt_start = kwargs.get(&#34;clt_start&#34;, 30)
            sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

            # Setup required regardless of the depth of the connection

            # Gives dist of num outgoing connections from A
            # This tends towards normal distribution by CLT in most cases

            def fn_to_apply(k):
                # Ideally, here would use float if large var dist, and int otherwise.
                # Not a huge difference though
                # return expected_unique(num_end, k, do_round=False)
                return expected_unique(num_end, k, do_round=True)

            ab_dist = random_draw_dist(
                total_samples,
                out_connections_dist,
                num_end,
                apply_fn=False,
                keep_all=True,
                clt_start=clt_start,
                sub=sub,
            )

            dists = OrderedDict()
            for k, v in ab_dist.items():
                dists[k] = apply_fn_to_dist(v, fn_to_apply, sub=sub)
            ab_un_dist = dists
            final_dist = ab_un_dist

        if max_depth &gt;= 2:
            final_dist = OrderedDict()
            start_inter_dist = kwargs.get(&#34;start_inter_dist&#34;)
            end_inter_dist = kwargs.get(&#34;end_inter_dist&#34;)
            start_mean = get_dist_mean(out_connections_dist)
            start_var = get_dist_var(out_connections_dist)

            start_inter_mean = get_dist_mean(start_inter_dist)
            start_inter_var = get_dist_var(start_inter_dist)
            end_inter_mean = get_dist_mean(end_inter_dist)
            end_inter_var = get_dist_var(end_inter_dist)

            ab_cache = OrderedDict()
            ab_cache[0] = OrderedDict()
            ab_cache[0][0] = 1.0
            start_max_val = max(list(out_connections_dist.keys()))
            for i in range(1, num_senders + 1):
                if i &lt; clt_start:
                    ab_cache[i] = convolution(
                        out_connections_dist, ab_cache[i - 1], sub=sub
                    )
                else:
                    ab_cache[i] = create_normal(
                        range((start_max_val * i) + 1),
                        start_mean * i,
                        start_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            bb_cache = OrderedDict()
            bb_cache[0] = OrderedDict()
            bb_cache[0][0] = 1.0
            end_inter_max_val = max(list(end_inter_dist.keys()))
            for i in range(1, num_end + 1):
                if i &lt; clt_start:
                    bb_cache[i] = convolution(
                        end_inter_dist, bb_cache[i - 1], sub=sub
                    )
                else:
                    bb_cache[i] = create_normal(
                        range((end_inter_max_val * i) + 1),
                        end_inter_mean * i,
                        end_inter_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            # AAB calculation
            if total_samples &lt; clt_start:
                aa_dist = nfold_conv([start_inter_dist] * total_samples, sub=sub)
            else:
                max_val = max(list(start_inter_dist.keys()))
                aa_dist = create_normal(
                    range((max_val * total_samples) + 1),
                    start_inter_mean * total_samples,
                    start_inter_var * total_samples,
                    sub=sub,
                    interp_after=True,
                )
            aa_sender_dist = OrderedDict()

            aab_dist = OrderedDict()
            abb_dist = OrderedDict()

            for i in range(total_samples + 1):

                def inside_fn(x):
                    aa_sampled = expected_unique(num_start, x)
                    aa_new = expected_non_overlapping(
                        num_start, total_samples, aa_sampled
                    )
                    aa_senders = expected_overlapping(
                        num_start, num_senders - i, aa_new,
                    )
                    return int(round(aa_senders))

                aa_sender_dist[i] = apply_fn_to_dist(aa_dist, inside_fn, sub=sub)

                aab_dist[i] = combine_dists(
                    range((start_max_val * num_senders) + 1),
                    ab_cache,
                    aa_sender_dist[i],
                    sub=None,
                )
                abb_dist[i] = combine_dists(
                    range((end_inter_max_val * num_end) + 1),
                    bb_cache,
                    ab_un_dist[i],
                    sub=None,
                )
                aab_dist[i] = apply_fn_to_dist(aab_dist[i], fn_to_apply, sub=sub)
                abb_dist[i] = apply_fn_to_dist(abb_dist[i], fn_to_apply, sub=sub)

                aab_cache = OrderedDict()
                abb_cache = OrderedDict()

                for j in range(num_end + 1):

                    def to_app(x):
                        return min(
                            j + round(expected_non_overlapping(num_end, j, x)),
                            num_end,
                        )

                    if j == num_end:
                        to_add = OrderedDict()
                        to_add[num_end] = 1
                        aab_cache[j] = to_add
                        abb_cache[j] = to_add
                    else:
                        aab_cache[j] = apply_fn_to_dist(
                            aab_dist[i], to_app, sub=sub
                        )
                        abb_cache[j] = apply_fn_to_dist(
                            abb_dist[i], to_app, sub=sub
                        )

                in_prog = OrderedDict()
                in_prog = combine_dists(
                    range(num_end + 1), aab_cache, ab_un_dist[i], sub=None
                )
                in_prog = combine_dists(
                    range(num_end + 1), abb_cache, in_prog, sub=None
                )
                final_dist[i] = in_prog

        if max_depth &gt;= 3:
            recurrent_connections_dist = kwargs.get(&#34;recurrent_connections_dist&#34;)
            num_recurrent = kwargs.get(&#34;num_recurrent&#34;)
            end_mean = get_dist_mean(recurrent_connections_dist)
            end_var = get_dist_var(recurrent_connections_dist)

            aaab_dist = OrderedDict()
            aabb_dist = OrderedDict()
            abbb_dist = OrderedDict()
            abab_dist = OrderedDict()

            aaab_cache = OrderedDict()
            aabb_cache = OrderedDict()
            abbb_cache = OrderedDict()
            abab_cache = OrderedDict()

            aa_cache = OrderedDict()
            aa_cache[0] = OrderedDict()
            aa_cache[0][0] = 1.0
            start_inter_max_val = max(list(start_inter_dist.keys()))
            for i in range(1, num_start + 1):
                if i &lt; clt_start:
                    aa_cache[i] = convolution(
                        start_inter_dist, aa_cache[i - 1], sub=sub
                    )
                else:
                    aa_cache[i] = create_normal(
                        range((start_inter_max_val * i) + 1),
                        start_inter_mean * i,
                        start_inter_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            ba_cache = OrderedDict()
            ba_cache[0] = OrderedDict()
            ba_cache[0][0] = 1.0
            end_max_val = max(list(recurrent_connections_dist.keys()))
            for i in range(1, num_recurrent + 1):
                if i &lt; clt_start:
                    ba_cache[i] = convolution(
                        recurrent_connections_dist, ba_cache[i - 1], sub=sub
                    )
                else:
                    ba_cache[i] = create_normal(
                        range((end_max_val * i) + 1),
                        end_mean * i,
                        end_var * i,
                        sub=sub,
                        interp_after=True,
                    )

            ab_sender_dist = OrderedDict()

            def new_fn(x):
                return int(round(expected_overlapping(num_end, num_recurrent, x)))

            for k, v in ab_un_dist.items():
                ab_sender_dist[k] = apply_fn_to_dist(v, new_fn, sub=sub)

            aaa_sender_dist = OrderedDict()

            def new_fn(x):
                return int(round(expected_unique(num_start, x)))

            aa_un_dist = apply_fn_to_dist(aa_dist, new_fn, sub=sub)
            aaa_dist = combine_dists(
                range((num_start * start_inter_max_val * start_inter_max_val) + 1),
                aa_cache,
                aa_un_dist,
                sub=None,
            )

            aba_dist = OrderedDict()
            aba_sender_dist = OrderedDict()

            for i in range(total_samples + 1):

                def inside_fn(x):
                    aaa_sampled = expected_unique(num_start, x)
                    aaa_new = expected_non_overlapping(
                        num_start,
                        total_samples + get_dist_mean(aa_un_dist),
                        aaa_sampled,
                    )
                    aaa_senders = expected_overlapping(
                        num_start,
                        num_senders - get_dist_mean(aa_sender_dist[i]) - i,
                        aaa_new,
                    )
                    return int(round(aaa_senders))

                def new_fn_k(x):
                    aba_sampled = expected_unique(num_start, x)
                    aba_new = expected_non_overlapping(
                        num_start,
                        total_samples
                        + get_dist_mean(aa_un_dist)
                        + get_dist_mean(aaa_dist),
                        aba_sampled,
                    )
                    aba_senders = expected_overlapping(
                        num_start,
                        num_senders
                        - get_dist_mean(aa_sender_dist[i])
                        - get_dist_mean(aaa_sender_dist[i])
                        - i,
                        aba_new,
                    )
                    return int(round(aba_senders))

                aaa_sender_dist[i] = apply_fn_to_dist(aaa_dist, inside_fn, sub=sub)

                aba_dist[i] = combine_dists(
                    range((num_recurrent * end_max_val) + 1),
                    ba_cache,
                    ab_sender_dist[i],
                    sub=None,
                )
                aba_sender_dist[i] = apply_fn_to_dist(
                    aba_dist[i], new_fn_k, sub=sub
                )

                aaab_dist[i] = combine_dists(
                    range((start_max_val * num_senders) + 1),
                    ab_cache,
                    aaa_sender_dist[i],
                    sub=None,
                )
                abab_dist[i] = combine_dists(
                    range((start_max_val * num_senders) + 1),
                    ab_cache,
                    aba_sender_dist[i],
                    sub=None,
                )
                aabb_dist[i] = combine_dists(
                    range((end_inter_max_val * num_end) + 1),
                    bb_cache,
                    aab_dist[i],
                    sub=None,
                )
                abbb_dist[i] = combine_dists(
                    range((end_inter_max_val * num_end) + 1),
                    bb_cache,
                    abb_dist[i],
                    sub=None,
                )

                for j in range(num_end + 1):

                    def to_app(x):
                        return min(
                            j + round(expected_non_overlapping(num_end, j, x)),
                            num_end,
                        )

                    if j == num_end:
                        to_add = OrderedDict()
                        to_add[num_end] = 1
                        aaab_cache[j] = to_add
                        aabb_cache[j] = to_add
                        abab_cache[j] = to_add
                        abbb_cache[j] = to_add
                    else:
                        aaab_cache[j] = apply_fn_to_dist(
                            aaab_dist[i], to_app, sub=sub
                        )
                        aabb_cache[j] = apply_fn_to_dist(
                            aabb_dist[i], to_app, sub=sub
                        )
                        abab_cache[j] = apply_fn_to_dist(
                            abab_dist[i], to_app, sub=sub
                        )
                        abbb_cache[j] = apply_fn_to_dist(
                            abbb_dist[i], to_app, sub=sub
                        )

                in_prog = OrderedDict()
                in_prog = combine_dists(
                    range(num_end + 1), aaab_cache, final_dist[i], sub=None
                )
                in_prog = combine_dists(
                    range(num_end + 1), aabb_cache, in_prog, sub=None
                )
                in_prog = combine_dists(
                    range(num_end + 1), abab_cache, in_prog, sub=None
                )
                in_prog = combine_dists(
                    range(num_end + 1), abbb_cache, in_prog, sub=None
                )
                final_dist[i] = in_prog

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end + 1), final_dist, prob_a_senders, sub=None
        )

        return dists, weighted_dist</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self, choices, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Create connections randomly from model stats.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_connections(self, choices, **kwargs):
    &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
    region_verts = kwargs.get(&#34;region_verts&#34;)
    box = kwargs.get(&#34;box&#34;, False)  # for performance reasons

    graph = []

    # Choose the forward connectors
    connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
    forward_connections = np.random.choice(
        choices, size=(self.num_senders, self.max_forward), replace=True
    )
    num_choices = np.random.randint(
        self.min_forward,
        self.max_forward + 1,
        dtype=np.int32,
        size=self.num_senders,
    )

    f_idx = 0
    # Create connections between neurons in the same region
    if self.max_inter &gt; 0:
        if box:
            num_boxes = 5
            box_like = 4
            box_size = int(math.ceil(len(region_verts) / num_boxes))
            out_box_size = len(region_verts) - box_size

            # Represents in box being box_like times more likely than outside
            # e.g. for 5
            # x = 5y
            # 1 = (1 / num_boxes) * (5 * y) + (1 - 1 / num_boxes) * y
            y_mult = (1 / num_boxes) * (box_like) + (1 - (1 / num_boxes))
            out_box_mult = 1 / y_mult
            in_box_mult = box_like * out_box_mult
            mult = np.array(
                [
                    (1 / num_boxes) * in_box_mult,
                    (1 - (1 / num_boxes)) * out_box_mult,
                ]
            )
            rand_amt = self.min_inter + (
                np.random.rand() * (self.max_inter - self.min_inter)
            )
            sample_sizes = np.ceil(rand_amt * mult * len(region_verts)).astype(int)

            in_box_idx = np.array([i for i in range(box_size)], dtype=np.int32)
            self_connects_box = np.random.choice(
                in_box_idx, size=(len(region_verts), sample_sizes[0]), replace=True,
            )

            out_box_idx = np.array(
                [i + box_size for i in range(out_box_size)], dtype=np.int32
            )
            self_connects_outside = np.random.choice(
                out_box_idx,
                size=(len(region_verts), sample_sizes[1]),
                replace=True,
            )

        else:
            self_connects = np.random.choice(
                region_verts,
                size=(
                    len(region_verts),
                    int(round(self.max_inter * len(region_verts))),
                ),
                replace=True,
            )
            num_choices_inter = np.random.randint(
                int(round(self.min_inter * len(region_verts))),
                int(round(self.max_inter * len(region_verts))) + 1,
                dtype=np.int32,
                size=len(region_verts),
            )

    # Create forward_connections and inter_connections
    for i, vert in enumerate(region_verts):
        if self.max_inter &gt; 0:
            if box:
                which_box = int(math.floor(i / box_size))
                a = int(which_box * box_size)

                self_connects_box_i = a + self_connects_box[i]

                self_connects_out_i = self_connects_outside[i]
                self_connects_out_i[
                    self_connects_out_i &lt; (a + box_size)
                ] -= box_size

                self_connections = np.array(
                    list(
                        set(
                            np.concatenate(
                                (self_connects_box_i, self_connects_out_i)
                                + np.min(region_verts)
                            )
                        )
                    ),
                    dtype=np.int32,
                )

            else:
                self_connections = np.array(
                    list(set(self_connects[i, : num_choices_inter[i]])),
                    dtype=np.int32,
                )

            # Remove autaptic synapses
            self_connections = np.delete(
                self_connections, np.where(self_connections == vert)
            )
            for val in self_connections:
                if isinstance(val, float):
                    print(val, self_connections)
                    exit(-1)

        else:
            self_connections = np.array([], dtype=np.int32)

        # Create forward_connections
        if vert in connected:
            forward_connection = forward_connections[f_idx, : num_choices[f_idx]]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            f_idx = f_idx + 1

        if isinstance(self_connections, np.int32):
            graph.append(np.array([self_connections], dtype=np.int32))
        else:
            graph.append(self_connections.astype(np.int32))

    return graph, connected</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, num_samples, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calls static_expected_connections</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expected_connections(self, num_samples, **kwargs):
    &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
    return RecurrentConnectivity.static_expected_connections(num_samples, **kwargs)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity"><code class="flex name class">
<span>class <span class="ident">UniqueConnectivity</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Random connections where connections don't overlap.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class UniqueConnectivity(ConnectionStrategy):
    &#34;&#34;&#34;
    Random connections where connections don&#39;t overlap.

    &#34;&#34;&#34;

    def __init__(self, **kwargs):
        self.num_senders = kwargs.get(&#34;num_senders&#34;)
        self.min_forward = kwargs.get(&#34;min_forward&#34;)
        self.max_forward = kwargs.get(&#34;max_forward&#34;)

    def create_connections(self, choices, **kwargs):
        &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
        region_verts = kwargs.get(&#34;region_verts&#34;)
        graph = []

        # Choose the forward connectors
        connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
        forward_connections = np.random.choice(
            choices, size=(self.num_senders, self.max_forward), replace=True
        )
        num_choices = np.random.randint(
            self.min_forward,
            self.max_forward + 1,
            dtype=np.int32,
            size=self.num_senders,
        )

        f_idx = 0
        # Create forward_connections and inter_connections
        for i, vert in enumerate(region_verts):
            self_connections = np.array([], dtype=np.int32)

            # Create forward_connections
            if vert in connected:
                forward_connections = np.random.choice(
                    choices, size=(self.max_forward), replace=False
                )
                forward_connection = forward_connections[: num_choices[f_idx]]
                self_connections = np.append(
                    self_connections, list(set(forward_connection))
                )
                f_idx = f_idx + 1

            if isinstance(self_connections, np.int32):
                graph.append(np.array([self_connections], dtype=np.int32))
            else:
                graph.append(self_connections.astype(np.int32))

        return graph, connected

    def expected_connections(self, num_samples, **kwargs):
        &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
        return RecurrentConnectivity.static_expected_connections(num_samples, **kwargs)

    @staticmethod
    def static_expected_connections(**kwargs):
        &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
        # Parse out the relevant parameters
        max_depth = kwargs.get(&#34;max_depth&#34;, 1)

        if max_depth &gt; 1:
            raise ValueError(&#34;max_depth must be 1 for unique connections.&#34;)

        num_end = kwargs.get(&#34;N&#34;)
        out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
        num_start = kwargs.get(&#34;num_start&#34;)
        num_senders = kwargs.get(&#34;num_senders&#34;)

        total_samples = kwargs.get(&#34;total_samples&#34;)
        clt_start = kwargs.get(&#34;clt_start&#34;, 30)
        sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

        # Setup required regardless of the depth of the connection

        # Gives dist of num outgoing connections from A
        # This tends towards normal distribution by CLT in most cases

        def fn_to_apply(k):
            return int(round(expected_unique(num_end, k)))

        ab_dist = random_draw_dist(
            total_samples,
            out_connections_dist,
            num_end,
            apply_fn=False,
            keep_all=True,
            clt_start=clt_start,
            sub=sub,
        )

        final_dist = ab_dist

        # PMF of num senders sampled
        prob_a_senders = OrderedDict()

        for i in range(total_samples + 1):
            prob_a_senders[i] = float(
                hypergeometric_pmf(num_start, num_senders, total_samples, i)
            )

        weighted_dist = combine_dists(
            range(num_end + 1), final_dist, prob_a_senders, sub=None
        )

        return ab_dist, weighted_dist</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity.static_expected_connections"><code class="name flex">
<span>def <span class="ident">static_expected_connections</span></span>(<span>**kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Return connection distribution.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def static_expected_connections(**kwargs):
    &#34;&#34;&#34;Return connection distribution.&#34;&#34;&#34;
    # Parse out the relevant parameters
    max_depth = kwargs.get(&#34;max_depth&#34;, 1)

    if max_depth &gt; 1:
        raise ValueError(&#34;max_depth must be 1 for unique connections.&#34;)

    num_end = kwargs.get(&#34;N&#34;)
    out_connections_dist = kwargs.get(&#34;out_connections_dist&#34;)
    num_start = kwargs.get(&#34;num_start&#34;)
    num_senders = kwargs.get(&#34;num_senders&#34;)

    total_samples = kwargs.get(&#34;total_samples&#34;)
    clt_start = kwargs.get(&#34;clt_start&#34;, 30)
    sub = kwargs.get(&#34;subsample_rate&#34;, 0.01)

    # Setup required regardless of the depth of the connection

    # Gives dist of num outgoing connections from A
    # This tends towards normal distribution by CLT in most cases

    def fn_to_apply(k):
        return int(round(expected_unique(num_end, k)))

    ab_dist = random_draw_dist(
        total_samples,
        out_connections_dist,
        num_end,
        apply_fn=False,
        keep_all=True,
        clt_start=clt_start,
        sub=sub,
    )

    final_dist = ab_dist

    # PMF of num senders sampled
    prob_a_senders = OrderedDict()

    for i in range(total_samples + 1):
        prob_a_senders[i] = float(
            hypergeometric_pmf(num_start, num_senders, total_samples, i)
        )

    weighted_dist = combine_dists(
        range(num_end + 1), final_dist, prob_a_senders, sub=None
    )

    return ab_dist, weighted_dist</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity.create_connections"><code class="name flex">
<span>def <span class="ident">create_connections</span></span>(<span>self, choices, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Create connections randomly from model stats.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_connections(self, choices, **kwargs):
    &#34;&#34;&#34;Create connections randomly from model stats.&#34;&#34;&#34;
    region_verts = kwargs.get(&#34;region_verts&#34;)
    graph = []

    # Choose the forward connectors
    connected = np.random.choice(region_verts, size=self.num_senders, replace=False)
    forward_connections = np.random.choice(
        choices, size=(self.num_senders, self.max_forward), replace=True
    )
    num_choices = np.random.randint(
        self.min_forward,
        self.max_forward + 1,
        dtype=np.int32,
        size=self.num_senders,
    )

    f_idx = 0
    # Create forward_connections and inter_connections
    for i, vert in enumerate(region_verts):
        self_connections = np.array([], dtype=np.int32)

        # Create forward_connections
        if vert in connected:
            forward_connections = np.random.choice(
                choices, size=(self.max_forward), replace=False
            )
            forward_connection = forward_connections[: num_choices[f_idx]]
            self_connections = np.append(
                self_connections, list(set(forward_connection))
            )
            f_idx = f_idx + 1

        if isinstance(self_connections, np.int32):
            graph.append(np.array([self_connections], dtype=np.int32))
        else:
            graph.append(self_connections.astype(np.int32))

    return graph, connected</code></pre>
</details>
</dd>
<dt id="neuroconnect.connectivity_patterns.UniqueConnectivity.expected_connections"><code class="name flex">
<span>def <span class="ident">expected_connections</span></span>(<span>self, num_samples, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Calls static_expected_connections</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expected_connections(self, num_samples, **kwargs):
    &#34;&#34;&#34;Calls static_expected_connections&#34;&#34;&#34;
    return RecurrentConnectivity.static_expected_connections(num_samples, **kwargs)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="neuroconnect" href="index.html">neuroconnect</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.get_by_name" href="#neuroconnect.connectivity_patterns.get_by_name">get_by_name</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy" href="#neuroconnect.connectivity_patterns.ConnectionStrategy">ConnectionStrategy</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy.create_connections" href="#neuroconnect.connectivity_patterns.ConnectionStrategy.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy.expected_connections" href="#neuroconnect.connectivity_patterns.ConnectionStrategy.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.ConnectionStrategy.static_expected_connections" href="#neuroconnect.connectivity_patterns.ConnectionStrategy.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity" href="#neuroconnect.connectivity_patterns.MatrixConnectivity">MatrixConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.compute_stats" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.compute_stats">compute_stats</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.gen_random_samples" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.gen_random_samples">gen_random_samples</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.load" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.load">load</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.static_expected_connections">static_expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.MatrixConnectivity.subsample" href="#neuroconnect.connectivity_patterns.MatrixConnectivity.subsample">subsample</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity" href="#neuroconnect.connectivity_patterns.MeanRecurrentConnectivity">MeanRecurrentConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.MeanRecurrentConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.MeanRecurrentConnectivity.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity">RecurrentConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.nfmt" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.nfmt">nfmt</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.RecurrentConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.RecurrentConnectivity.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity" href="#neuroconnect.connectivity_patterns.UniqueConnectivity">UniqueConnectivity</a></code></h4>
<ul class="">
<li><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity.create_connections" href="#neuroconnect.connectivity_patterns.UniqueConnectivity.create_connections">create_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity.expected_connections" href="#neuroconnect.connectivity_patterns.UniqueConnectivity.expected_connections">expected_connections</a></code></li>
<li><code><a title="neuroconnect.connectivity_patterns.UniqueConnectivity.static_expected_connections" href="#neuroconnect.connectivity_patterns.UniqueConnectivity.static_expected_connections">static_expected_connections</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>