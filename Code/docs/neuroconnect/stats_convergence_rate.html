<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>neuroconnect.stats_convergence_rate API documentation</title>
<meta name="description" content="Analysing convergence rate of stats distributions." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>neuroconnect.stats_convergence_rate</code></h1>
</header>
<section id="section-intro">
<p>Analysing convergence rate of stats distributions.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Analysing convergence rate of stats distributions.&#34;&#34;&#34;

import os
import json
from configparser import ConfigParser
from types import SimpleNamespace
from collections import OrderedDict

import numpy as np
import pandas as pd
import tqdm

from .connect_math import hypergeometric_pmf, create_uniform
from .monte_carlo import (
    monte_carlo,
    list_to_df,
    summarise_monte_carlo,
    get_distribution,
    dist_difference,
)
from .main import main as control_main
from .mpf_connection import CombProb
from .connect_math import expected_unique
from .connectivity_patterns import get_by_name
from .experiment import do_full_experiment

here = os.path.dirname(os.path.realpath(__file__))


def test_hyper_convergence_rate(N, K, n, num_iters=1000, num_cpus=1):
    &#34;&#34;&#34;Compare simulated hypergeometric_pmf to actual over num_iters.&#34;&#34;&#34;
    actual_distribution = {}
    expected = 0
    for k in range(n + 1):
        actual_distribution[k] = hypergeometric_pmf(N, K, n, k)
        expected += actual_distribution[k] * k

    total = np.array([i for i in range(N)])
    good = np.random.choice(total, size=K, replace=False)

    def random_var_gen(iter_val):
        drawn = np.random.choice(total, size=n, replace=False)
        return (drawn,)

    def fn_to_eval(drawn):
        count = 0
        for val in drawn:
            if val in good:
                count += 1
        return (count,)

    result = monte_carlo(fn_to_eval, random_var_gen, num_iters, num_cpus=num_cpus)
    df = list_to_df(result, [&#34;Connections&#34;,],)
    dist = get_distribution(df, &#34;Connections&#34;, num_iters)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;figures&#34;), exist_ok=True)
    result = summarise_monte_carlo(
        df,
        to_plot=[&#34;Connections&#34;,],
        plt_outfile=os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;dist.png&#34;),
    )

    diff = dist_difference(actual_distribution, dist)
    return {
        &#34;actual&#34;: actual_distribution,
        &#34;simulated&#34;: dist,
        &#34;difference&#34;: diff,
        &#34;sim_summary&#34;: result,
        &#34;stats_exp&#34;: expected,
    }


def test_network_convergence(num_cpus=1):
    &#34;&#34;&#34;Test how fast the simulated networks converge to stability.&#34;&#34;&#34;

    def delta_fn(k, **delta_params):
        N = delta_params.get(&#34;N&#34;)
        connections = delta_params.get(&#34;connections&#34;)
        return expected_unique(N, k * connections)

    cp = CombProb(1000, 50, 100, 1000, 50, delta_fn, connections=20, N=1000)

    vals = []
    result = {
        &#34;expected&#34;: cp.expected_connections(),
        &#34;total&#34;: cp.get_all_prob(),
    }
    for k, v in result[&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Statistical estimation&#34;])

    total = np.array([i for i in range(1000)])
    good = np.random.choice(total, size=100, replace=False)

    def random_var_gen(iter_val):
        drawn_a = np.random.choice(total, size=50, replace=False)
        count = 0
        for val in drawn_a:
            if val in good:
                count += 1

        good_b = np.random.choice(total, size=count * 20, replace=True)
        drawn_b = np.random.choice(total, size=50, replace=False)

        return (drawn_b, good_b)

    def fn_to_eval(drawn_b, good_b):
        count = 0
        for val in drawn_b:
            if val in good_b:
                count += 1
        return (count,)

    num_iters = 100000
    result = monte_carlo(fn_to_eval, random_var_gen, num_iters, num_cpus=num_cpus)
    df = list_to_df(result, [&#34;Connections&#34;,],)

    for n in [1000, 10000, 50000, num_iters]:
        dist = get_distribution(df.head(n), &#34;Connections&#34;, n)
        for k, v in dist.items():
            vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(n)])

    columns = [&#34;Number of sampled connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
    df = pd.DataFrame(vals, columns=columns)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;stats_convergence_fixed.csv&#34;), index=False,
    )
    return df


def make_test_net(has_var=True):
    &#34;&#34;&#34;Make a test network.&#34;&#34;&#34;
    total = np.array([i for i in range(1000)])
    good = np.random.choice(total, size=200, replace=False)
    bad = []
    for val in total:
        if val not in good:
            bad.append(val)
    connections = {}

    if has_var:
        senders = np.random.choice(total, size=(200, 250), replace=True)
    else:
        senders = np.random.choice(total, size=(200, 150), replace=True)
    for i, val in enumerate(good):
        if has_var:
            num_choices = np.random.randint(50, 250 + 1, dtype=np.int32)
        else:
            num_choices = 150
        forward_connection = senders[i, :num_choices]
        connections[val] = forward_connection

    def random_var_gen(iter_val):
        f_arrays = []
        drawn_a = np.random.choice(total, size=20, replace=False)
        for val in drawn_a:
            if val in good:
                f_arrays.append(connections[val])
        if len(f_arrays) &gt; 0:
            good_b = np.concatenate(f_arrays)
        else:
            good_b = []
        drawn_b = np.random.choice(total, size=20, replace=False)

        return (drawn_b, good_b)

    def fn_to_eval(drawn_b, good_b):
        count = 0
        for val in drawn_b:
            if val in good_b:
                count += 1
        return (count,)

    return random_var_gen, fn_to_eval


def test_rand_network_convergence(num_cpus=1, sr=None):
    &#34;&#34;&#34;Test convergence of random networks.&#34;&#34;&#34;
    rv = get_by_name(&#34;recurrent_connectivity&#34;)
    ndelta_fn = rv.static_expected_connections
    unif_out = create_uniform(50, 250)
    unif_re = create_uniform(50, 250)

    inter_dist = OrderedDict()
    inter_dist[0] = 1
    vals = []
    delta_params = {
        &#34;out_connections_dist&#34;: unif_out,
        &#34;recurrent_connections_dist&#34;: unif_re,
        &#34;num_senders&#34;: 200,
        &#34;num_recurrent&#34;: 0,
        &#34;num_start&#34;: 1000,
        &#34;total_samples&#34;: 20,
        &#34;start_inter_dist&#34;: inter_dist,
        &#34;end_inter_dist&#34;: inter_dist,
        &#34;static_verbose&#34;: False,
        &#34;max_depth&#34;: 1,
        &#34;N&#34;: 1000,
    }

    cp = CombProb(1000, 20, 200, 1000, 20, ndelta_fn, subsample_rate=sr, **delta_params)

    mpf_result = {
        &#34;expected&#34;: cp.expected_connections(),
        &#34;total&#34;: cp.get_all_prob(),
    }
    for k, v in mpf_result[&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Statistical estimation&#34;])

    rv = get_by_name(&#34;mean_connectivity&#34;)
    ndelta_fn = rv.static_expected_connections
    cp = CombProb(1000, 20, 200, 1000, 20, ndelta_fn, **delta_params)

    mpf_result = {
        &#34;expected&#34;: cp.expected_connections(),
        &#34;total&#34;: cp.get_all_prob(),
    }
    for k, v in mpf_result[&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Mean estimation&#34;])

    # Let&#39;s do 1000 iterations on 1000 graphs?
    # result = []
    # for j in tqdm.tqdm(range(50)):
    #     random_var_gen, fn_to_eval = make_test_net()
    #     r = monte_carlo(
    #         fn_to_eval, random_var_gen, 10000, num_cpus=num_cpus, progress=False
    #     )
    #     for val in r:
    #         result.append(val)
    # df = list_to_df(result, [&#34;Connections&#34;,],)
    # dist = get_distribution(df, &#34;Connections&#34;, 1000 * 100)
    # for k, v in dist.items():
    #     vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(&#34;50000&#34;)])

    random_var_gen, fn_to_eval = make_test_net()
    result = monte_carlo(fn_to_eval, random_var_gen, 50000, num_cpus=num_cpus)
    df = list_to_df(result, [&#34;Connections&#34;,],)

    for n in [10000, 20000, 50000]:
        dist = get_distribution(df.head(n), &#34;Connections&#34;, n)
        for k, v in dist.items():
            vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(n)])

    columns = [&#34;Number of sampled connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
    df = pd.DataFrame(vals, columns=columns)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;stats_convergence_rand.csv&#34;), index=False,
    )

    return df


def test_config_convergence(config, out_name, num_cpus=1, max_depth=1):
    &#34;&#34;&#34;Test convergence of network from a config file.&#34;&#34;&#34;
    columns = [&#34;Number of sampled connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
    vals = []
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_nx = False
    do_graph = True
    do_vis_graph = False

    result = do_full_experiment(
        region_sizes,
        connectivity_pattern,
        connectivity_params,
        num_samples,
        do_mpf,
        do_graph,
        do_nx,
        do_vis_graph,
        num_iters=100000,
        max_depth=max_depth,
        gen_graph_each_iter=False,
        do_fixed=-1,
    )

    for k, v in result[&#34;mpf&#34;][&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Statistical estimation&#34;])

    df = result[&#34;graph&#34;][&#34;full_results&#34;]
    for n in [1000, 10000, 50000, 100000]:
        dist = get_distribution(df.head(n), &#34;Connections&#34;, n)
        for k, v in dist.items():
            vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(n)])

    result = do_full_experiment(
        region_sizes,
        get_by_name(&#34;mean_connectivity&#34;),
        connectivity_params,
        num_samples,
        do_mpf,
        False,
        do_nx,
        do_vis_graph,
        num_iters=100000,
        max_depth=max_depth,
        gen_graph_each_iter=False,
        do_fixed=-1,
    )
    for k, v in result[&#34;mpf&#34;][&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Mean estimation&#34;])

    df = pd.DataFrame(vals, columns=columns)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;convergence_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df


def main(N, K, n, num_iters):
    &#34;&#34;&#34;Check convergence rate of hypergeometric_pmf and network dist.&#34;&#34;&#34;
    np.random.seed(42)
    res1 = test_hyper_convergence_rate(N, K, n, num_iters)
    cfg_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, &#34;stats_check.cfg&#34;)
    cfg = ConfigParser()
    cfg.read(cfg_path)
    args = SimpleNamespace(max_depth=1, num_cpus=1, cfg=&#34;stats_check&#34;)
    print(&#34;Writing graph convergence to file in results directory&#34;)
    control_main(cfg, args)
    return res1


if __name__ == &#34;__main__&#34;:
    np.random.seed(42)
    main(100, 10, 10, 1000)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="neuroconnect.stats_convergence_rate.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>N, K, n, num_iters)</span>
</code></dt>
<dd>
<section class="desc"><p>Check convergence rate of hypergeometric_pmf and network dist.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(N, K, n, num_iters):
    &#34;&#34;&#34;Check convergence rate of hypergeometric_pmf and network dist.&#34;&#34;&#34;
    np.random.seed(42)
    res1 = test_hyper_convergence_rate(N, K, n, num_iters)
    cfg_path = os.path.join(here, &#34;..&#34;, &#34;configs&#34;, &#34;stats_check.cfg&#34;)
    cfg = ConfigParser()
    cfg.read(cfg_path)
    args = SimpleNamespace(max_depth=1, num_cpus=1, cfg=&#34;stats_check&#34;)
    print(&#34;Writing graph convergence to file in results directory&#34;)
    control_main(cfg, args)
    return res1</code></pre>
</details>
</dd>
<dt id="neuroconnect.stats_convergence_rate.make_test_net"><code class="name flex">
<span>def <span class="ident">make_test_net</span></span>(<span>has_var=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Make a test network.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_test_net(has_var=True):
    &#34;&#34;&#34;Make a test network.&#34;&#34;&#34;
    total = np.array([i for i in range(1000)])
    good = np.random.choice(total, size=200, replace=False)
    bad = []
    for val in total:
        if val not in good:
            bad.append(val)
    connections = {}

    if has_var:
        senders = np.random.choice(total, size=(200, 250), replace=True)
    else:
        senders = np.random.choice(total, size=(200, 150), replace=True)
    for i, val in enumerate(good):
        if has_var:
            num_choices = np.random.randint(50, 250 + 1, dtype=np.int32)
        else:
            num_choices = 150
        forward_connection = senders[i, :num_choices]
        connections[val] = forward_connection

    def random_var_gen(iter_val):
        f_arrays = []
        drawn_a = np.random.choice(total, size=20, replace=False)
        for val in drawn_a:
            if val in good:
                f_arrays.append(connections[val])
        if len(f_arrays) &gt; 0:
            good_b = np.concatenate(f_arrays)
        else:
            good_b = []
        drawn_b = np.random.choice(total, size=20, replace=False)

        return (drawn_b, good_b)

    def fn_to_eval(drawn_b, good_b):
        count = 0
        for val in drawn_b:
            if val in good_b:
                count += 1
        return (count,)

    return random_var_gen, fn_to_eval</code></pre>
</details>
</dd>
<dt id="neuroconnect.stats_convergence_rate.test_config_convergence"><code class="name flex">
<span>def <span class="ident">test_config_convergence</span></span>(<span>config, out_name, num_cpus=1, max_depth=1)</span>
</code></dt>
<dd>
<section class="desc"><p>Test convergence of network from a config file.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_config_convergence(config, out_name, num_cpus=1, max_depth=1):
    &#34;&#34;&#34;Test convergence of network from a config file.&#34;&#34;&#34;
    columns = [&#34;Number of sampled connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
    vals = []
    region_sizes = json.loads(config.get(&#34;default&#34;, &#34;region_sizes&#34;))
    num_samples = json.loads(config.get(&#34;default&#34;, &#34;num_samples&#34;))
    connectivity_pattern = config.get(&#34;default&#34;, &#34;connectivity_pattern&#34;)
    connectivity_pattern = get_by_name(connectivity_pattern)
    connectivity_param_names = json.loads(
        config.get(&#34;default&#34;, &#34;connectivity_param_names&#34;)
    )

    connectivity_param_vals = []
    for name in connectivity_param_names:
        cfg_val = config.get(&#34;default&#34;, name, fallback=None)
        if cfg_val is not None:
            val = json.loads(cfg_val)
        else:
            val = [0 for _ in range(len(region_sizes))]
        connectivity_param_vals.append(val)

    connectivity_params = []
    for i in range(len(region_sizes)):
        d = {}
        for k, v in zip(connectivity_param_names, connectivity_param_vals):
            d[k] = v[i]
        connectivity_params.append(d)

    do_mpf = True
    do_nx = False
    do_graph = True
    do_vis_graph = False

    result = do_full_experiment(
        region_sizes,
        connectivity_pattern,
        connectivity_params,
        num_samples,
        do_mpf,
        do_graph,
        do_nx,
        do_vis_graph,
        num_iters=100000,
        max_depth=max_depth,
        gen_graph_each_iter=False,
        do_fixed=-1,
    )

    for k, v in result[&#34;mpf&#34;][&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Statistical estimation&#34;])

    df = result[&#34;graph&#34;][&#34;full_results&#34;]
    for n in [1000, 10000, 50000, 100000]:
        dist = get_distribution(df.head(n), &#34;Connections&#34;, n)
        for k, v in dist.items():
            vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(n)])

    result = do_full_experiment(
        region_sizes,
        get_by_name(&#34;mean_connectivity&#34;),
        connectivity_params,
        num_samples,
        do_mpf,
        False,
        do_nx,
        do_vis_graph,
        num_iters=100000,
        max_depth=max_depth,
        gen_graph_each_iter=False,
        do_fixed=-1,
    )
    for k, v in result[&#34;mpf&#34;][&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Mean estimation&#34;])

    df = pd.DataFrame(vals, columns=columns)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;convergence_{}.csv&#34;.format(out_name)),
        index=False,
    )

    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.stats_convergence_rate.test_hyper_convergence_rate"><code class="name flex">
<span>def <span class="ident">test_hyper_convergence_rate</span></span>(<span>N, K, n, num_iters=1000, num_cpus=1)</span>
</code></dt>
<dd>
<section class="desc"><p>Compare simulated hypergeometric_pmf to actual over num_iters.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_hyper_convergence_rate(N, K, n, num_iters=1000, num_cpus=1):
    &#34;&#34;&#34;Compare simulated hypergeometric_pmf to actual over num_iters.&#34;&#34;&#34;
    actual_distribution = {}
    expected = 0
    for k in range(n + 1):
        actual_distribution[k] = hypergeometric_pmf(N, K, n, k)
        expected += actual_distribution[k] * k

    total = np.array([i for i in range(N)])
    good = np.random.choice(total, size=K, replace=False)

    def random_var_gen(iter_val):
        drawn = np.random.choice(total, size=n, replace=False)
        return (drawn,)

    def fn_to_eval(drawn):
        count = 0
        for val in drawn:
            if val in good:
                count += 1
        return (count,)

    result = monte_carlo(fn_to_eval, random_var_gen, num_iters, num_cpus=num_cpus)
    df = list_to_df(result, [&#34;Connections&#34;,],)
    dist = get_distribution(df, &#34;Connections&#34;, num_iters)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;figures&#34;), exist_ok=True)
    result = summarise_monte_carlo(
        df,
        to_plot=[&#34;Connections&#34;,],
        plt_outfile=os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;dist.png&#34;),
    )

    diff = dist_difference(actual_distribution, dist)
    return {
        &#34;actual&#34;: actual_distribution,
        &#34;simulated&#34;: dist,
        &#34;difference&#34;: diff,
        &#34;sim_summary&#34;: result,
        &#34;stats_exp&#34;: expected,
    }</code></pre>
</details>
</dd>
<dt id="neuroconnect.stats_convergence_rate.test_network_convergence"><code class="name flex">
<span>def <span class="ident">test_network_convergence</span></span>(<span>num_cpus=1)</span>
</code></dt>
<dd>
<section class="desc"><p>Test how fast the simulated networks converge to stability.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_network_convergence(num_cpus=1):
    &#34;&#34;&#34;Test how fast the simulated networks converge to stability.&#34;&#34;&#34;

    def delta_fn(k, **delta_params):
        N = delta_params.get(&#34;N&#34;)
        connections = delta_params.get(&#34;connections&#34;)
        return expected_unique(N, k * connections)

    cp = CombProb(1000, 50, 100, 1000, 50, delta_fn, connections=20, N=1000)

    vals = []
    result = {
        &#34;expected&#34;: cp.expected_connections(),
        &#34;total&#34;: cp.get_all_prob(),
    }
    for k, v in result[&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Statistical estimation&#34;])

    total = np.array([i for i in range(1000)])
    good = np.random.choice(total, size=100, replace=False)

    def random_var_gen(iter_val):
        drawn_a = np.random.choice(total, size=50, replace=False)
        count = 0
        for val in drawn_a:
            if val in good:
                count += 1

        good_b = np.random.choice(total, size=count * 20, replace=True)
        drawn_b = np.random.choice(total, size=50, replace=False)

        return (drawn_b, good_b)

    def fn_to_eval(drawn_b, good_b):
        count = 0
        for val in drawn_b:
            if val in good_b:
                count += 1
        return (count,)

    num_iters = 100000
    result = monte_carlo(fn_to_eval, random_var_gen, num_iters, num_cpus=num_cpus)
    df = list_to_df(result, [&#34;Connections&#34;,],)

    for n in [1000, 10000, 50000, num_iters]:
        dist = get_distribution(df.head(n), &#34;Connections&#34;, n)
        for k, v in dist.items():
            vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(n)])

    columns = [&#34;Number of sampled connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
    df = pd.DataFrame(vals, columns=columns)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;stats_convergence_fixed.csv&#34;), index=False,
    )
    return df</code></pre>
</details>
</dd>
<dt id="neuroconnect.stats_convergence_rate.test_rand_network_convergence"><code class="name flex">
<span>def <span class="ident">test_rand_network_convergence</span></span>(<span>num_cpus=1, sr=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Test convergence of random networks.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_rand_network_convergence(num_cpus=1, sr=None):
    &#34;&#34;&#34;Test convergence of random networks.&#34;&#34;&#34;
    rv = get_by_name(&#34;recurrent_connectivity&#34;)
    ndelta_fn = rv.static_expected_connections
    unif_out = create_uniform(50, 250)
    unif_re = create_uniform(50, 250)

    inter_dist = OrderedDict()
    inter_dist[0] = 1
    vals = []
    delta_params = {
        &#34;out_connections_dist&#34;: unif_out,
        &#34;recurrent_connections_dist&#34;: unif_re,
        &#34;num_senders&#34;: 200,
        &#34;num_recurrent&#34;: 0,
        &#34;num_start&#34;: 1000,
        &#34;total_samples&#34;: 20,
        &#34;start_inter_dist&#34;: inter_dist,
        &#34;end_inter_dist&#34;: inter_dist,
        &#34;static_verbose&#34;: False,
        &#34;max_depth&#34;: 1,
        &#34;N&#34;: 1000,
    }

    cp = CombProb(1000, 20, 200, 1000, 20, ndelta_fn, subsample_rate=sr, **delta_params)

    mpf_result = {
        &#34;expected&#34;: cp.expected_connections(),
        &#34;total&#34;: cp.get_all_prob(),
    }
    for k, v in mpf_result[&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Statistical estimation&#34;])

    rv = get_by_name(&#34;mean_connectivity&#34;)
    ndelta_fn = rv.static_expected_connections
    cp = CombProb(1000, 20, 200, 1000, 20, ndelta_fn, **delta_params)

    mpf_result = {
        &#34;expected&#34;: cp.expected_connections(),
        &#34;total&#34;: cp.get_all_prob(),
    }
    for k, v in mpf_result[&#34;total&#34;].items():
        vals.append([k, float(v), &#34;Mean estimation&#34;])

    # Let&#39;s do 1000 iterations on 1000 graphs?
    # result = []
    # for j in tqdm.tqdm(range(50)):
    #     random_var_gen, fn_to_eval = make_test_net()
    #     r = monte_carlo(
    #         fn_to_eval, random_var_gen, 10000, num_cpus=num_cpus, progress=False
    #     )
    #     for val in r:
    #         result.append(val)
    # df = list_to_df(result, [&#34;Connections&#34;,],)
    # dist = get_distribution(df, &#34;Connections&#34;, 1000 * 100)
    # for k, v in dist.items():
    #     vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(&#34;50000&#34;)])

    random_var_gen, fn_to_eval = make_test_net()
    result = monte_carlo(fn_to_eval, random_var_gen, 50000, num_cpus=num_cpus)
    df = list_to_df(result, [&#34;Connections&#34;,],)

    for n in [10000, 20000, 50000]:
        dist = get_distribution(df.head(n), &#34;Connections&#34;, n)
        for k, v in dist.items():
            vals.append([k, float(v), &#34;Monte Carlo simulation {}&#34;.format(n)])

    columns = [&#34;Number of sampled connected neurons&#34;, &#34;Probability&#34;, &#34;Calculation&#34;]
    df = pd.DataFrame(vals, columns=columns)
    os.makedirs(os.path.join(here, &#34;..&#34;, &#34;results&#34;), exist_ok=True)
    df.to_csv(
        os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;stats_convergence_rand.csv&#34;), index=False,
    )

    return df</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="neuroconnect" href="index.html">neuroconnect</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="neuroconnect.stats_convergence_rate.main" href="#neuroconnect.stats_convergence_rate.main">main</a></code></li>
<li><code><a title="neuroconnect.stats_convergence_rate.make_test_net" href="#neuroconnect.stats_convergence_rate.make_test_net">make_test_net</a></code></li>
<li><code><a title="neuroconnect.stats_convergence_rate.test_config_convergence" href="#neuroconnect.stats_convergence_rate.test_config_convergence">test_config_convergence</a></code></li>
<li><code><a title="neuroconnect.stats_convergence_rate.test_hyper_convergence_rate" href="#neuroconnect.stats_convergence_rate.test_hyper_convergence_rate">test_hyper_convergence_rate</a></code></li>
<li><code><a title="neuroconnect.stats_convergence_rate.test_network_convergence" href="#neuroconnect.stats_convergence_rate.test_network_convergence">test_network_convergence</a></code></li>
<li><code><a title="neuroconnect.stats_convergence_rate.test_rand_network_convergence" href="#neuroconnect.stats_convergence_rate.test_rand_network_convergence">test_rand_network_convergence</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>