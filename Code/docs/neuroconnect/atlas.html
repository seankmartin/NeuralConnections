<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>neuroconnect.atlas API documentation</title>
<meta name="description" content="Functions related to atlas processing" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>neuroconnect.atlas</code></h1>
</header>
<section id="section-intro">
<p>Functions related to atlas processing</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Functions related to atlas processing&#34;&#34;&#34;

from pprint import pprint
import os

import vedo
import brainrender
import numpy as np
import myterial
from bg_atlasapi import BrainGlobeAtlas, show_atlases
from skm_pyutils.py_plot import ColorManager
from one.api import One
from hilbertcurve.hilbertcurve import HilbertCurve
from scipy.spatial.transform import Rotation as R

here = os.path.abspath(os.path.dirname(__file__))


def vedo_vis(regions, colors=None, atlas_name=&#34;allen_mouse_25um&#34;):
    &#34;&#34;&#34;Visualise regions of atlas using vedo.&#34;&#34;&#34;
    bg_atlas = BrainGlobeAtlas(atlas_name, check_latest=False)
    pprint(bg_atlas.metadata)

    if colors is None:
        cm = ColorManager(num_colors=len(regions), method=&#34;rgb&#34;)
        colors = cm.colors

    # Show the full heirarchy
    # pprint(bg_atlas.structures.tree.show())

    # The order of x, y, z in the dataset
    ## This assumes asr layout.
    mapping = [2, 0, 1]
    max_x = bg_atlas.resolution[mapping[0]] * bg_atlas.shape[mapping[0]]
    max_y = bg_atlas.resolution[mapping[1]] * bg_atlas.shape[mapping[1]]
    max_z = bg_atlas.resolution[mapping[2]] * bg_atlas.shape[mapping[2]]
    full_size = bg_atlas.shape[0] * bg_atlas.shape[1] * bg_atlas.shape[2]

    points_list = []
    for region in regions:
        mask = bg_atlas.get_structure_mask(region)
        structure_id = bg_atlas.structures[region][&#34;id&#34;]
        y, z, x = np.nonzero(mask == structure_id)
        vol_pc = round((100 * x.shape[0]) / full_size, 2)
        n_sample_points = x.shape[0] // 500
        choice = np.random.randint(low=0, high=x.shape[0], size=n_sample_points)
        x = x[choice] * bg_atlas.resolution[mapping[0]] - (max_x // 2)
        y = y[choice] * bg_atlas.resolution[mapping[1]] - (max_y // 2)
        z = z[choice] * bg_atlas.resolution[mapping[2]] - (max_z // 2)

        print(f&#34;{region} occupies {vol_pc}% of the full brain&#34;)
        points_list.append((x, y, z))

    vedo_points = []
    for val, color in zip(points_list, colors):
        vedo_points.append(vedo.Points(np.array(val)).c(color))
    # axs = vedo.Axes(
    #     vedo_points,
    #     xtitle=&#34;X-axis in \mum&#34;,
    #     ytitle=&#34;Variable Y in \mum&#34;,
    #     ztitle=&#34;Inverted Z in \mum&#34;,
    #     htitle=&#34;My \Gamma^2_ijk  plot&#34;,
    #     hTitleFont=&#34;Kanopus&#34;,
    #     hTitleJustify=&#34;bottom-right&#34;,
    #     hTitleColor=&#34;red2&#34;,
    #     hTitleSize=0.035,
    #     hTitleOffset=(0, 0.075, 0),
    #     hTitleRotation=45,
    #     zHighlightZero=True,
    #     xyFrameLine=2,
    #     yzFrameLine=1,
    #     zxFrameLine=1,
    #     xyFrameColor=&#34;red3&#34;,
    #     xyShift=1.05,  # move xy 5% above the top of z-range
    #     yzGrid=True,
    #     zxGrid=True,
    #     zxShift=1.0,
    #     xTitleJustify=&#34;bottom-right&#34;,
    #     xTitleOffset=-1.175,
    #     xLabelOffset=-1.75,
    #     yLabelRotation=90,
    #     zInverted=True,
    #     tipSize=0.25,
    # )
    axs = vedo.Axes(vedo_points, zInverted=True, zHighlightZero=False)
    to = [0, 0, 0]
    from_ = [7000, 6000, 2000]
    camera = dict(pos=from_, focalPoint=to, viewup=[0, 0, -1])
    vedo.show(*vedo_points, axes=axs, camera=camera).close()


def get_points_in_hemisphere(atlas, region_actor, side=&#34;left&#34;):
    &#34;&#34;&#34;Return all points for a given region on one side&#34;&#34;&#34;
    all_points = region_actor.mesh.points()
    points_in_hemisphere = np.array(
        [
            point
            for point in all_points
            if atlas.hemisphere_from_coords(point, as_string=True, microns=True) == side
        ]
    )

    return points_in_hemisphere


def brainrender_vis(regions, colors=None, atlas_name=&#34;allen_mouse_25um&#34;):
    &#34;&#34;&#34;Visualise regions in atlas using brainrender&#34;&#34;&#34;

    if colors is None:
        cm = ColorManager(num_colors=len(regions), method=&#34;rgb&#34;)
        colors = cm.colors

    def get_n_random_points_in_region(region, N):
        &#34;&#34;&#34;
        Gets N random points inside (or on the surface) of a mes
        &#34;&#34;&#34;

        region_bounds = region.mesh.bounds()
        X = np.random.randint(region_bounds[0], region_bounds[1], size=10000)
        Y = np.random.randint(region_bounds[2], region_bounds[3], size=10000)
        Z = np.random.randint(region_bounds[4], region_bounds[5], size=10000)
        pts = [[x, y, z] for x, y, z in zip(X, Y, Z)]

        ipts = region.mesh.insidePoints(pts).points()

        if N &lt; ipts.shape[0]:
            return ipts[np.random.choice(ipts.shape[0], N, replace=False), :]
        else:
            return ipts

    scene = brainrender.Scene(root=True, title=&#34;Labelled cells&#34;, atlas_name=atlas_name)

    # Get a numpy array with (fake) coordinates of some labelled cells
    brain_region_actors = []
    for region, color in zip(regions, colors):
        brain_region = scene.add_brain_region(region, alpha=0.15, color=color)
        coordinates = get_n_random_points_in_region(brain_region.mesh, 2000)
        color = [color] * coordinates.shape[0]

        # Add to scene
        scene.add(
            brainrender.actors.Points(coordinates, name=f&#34;{region} CELLS&#34;, colors=color)
        )
        brain_region_actors.append(brain_region)

    hemisphere_points = [
        get_points_in_hemisphere(scene.atlas, brain_region_actor)
        for brain_region_actor in brain_region_actors
    ]

    p1 = hemisphere_points[0].mean(axis=0)
    p2 = hemisphere_points[1].mean(axis=0)

    mesh = vedo.shapes.Cylinder(pos=[p1, p2], c=&#34;blue&#34;, r=100, alpha=0.5)
    cylinder = brainrender.actor.Actor(mesh, name=&#34;Cylinder&#34;, br_class=&#34;Cylinder&#34;)

    scene.add(cylinder)

    # render
    scene.content
    scene.render()


def make_probes():
    &#34;&#34;&#34;Visualise some actual probes that were recorded with.&#34;&#34;&#34;
    # render a bunch of probes as sets of spheres (one per channel)
    scene = brainrender.Scene()
    scene.root._silhouette_kwargs[&#34;lw&#34;] = 1
    scene.root.alpha(0.2)
    probes_locs = load_steinmetz_locations()

    for locs in probes_locs:
        k = int(len(locs) / 374.0)

        for i in range(k):
            points = locs[i * 374 : (i + 1) * 374]
            regs = points.allen_ontology.values

            if &#34;LGd&#34; in regs and (&#34;VISa&#34; in regs or &#34;VISp&#34; in regs):
                color = myterial.salmon_darker
                alpha = 1
                sil = 1
            elif &#34;VISa&#34; in regs:
                color = myterial.salmon_light
                alpha = 1
                sil = 0.5
            else:
                continue

            spheres = brainrender.actors.Points(
                points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values,
                colors=color,
                alpha=alpha,
                radius=30,
            )
            spheres = scene.add(spheres)

            p1 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[0]
            p2 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[-1]
            mesh = vedo.shapes.Cylinder(pos=[p1, p2], c=color, r=100, alpha=0.3)
            cylinder = brainrender.actor.Actor(
                mesh, name=&#34;Cylinder&#34;, br_class=&#34;Cylinder&#34;
            )
            scene.add(cylinder)

            if sil:
                scene.add_silhouette(spheres, lw=sil)

    # Add brain regions
    visp, lgd = scene.add_brain_region(
        &#34;VISp&#34;,
        &#34;LGd&#34;,
        hemisphere=&#34;right&#34;,
        alpha=0.3,
        silhouette=False,
        color=myterial.blue_grey_dark,
    )
    visa = scene.add_brain_region(
        &#34;VISa&#34;,
        hemisphere=&#34;right&#34;,
        alpha=0.2,
        silhouette=False,
        color=myterial.blue_grey,
    )
    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()
    scene.add_silhouette(lgd, visp, lw=2)

    camera = {
        &#34;pos&#34;: (-16170, -7127, 31776),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (27548, 67414),
        &#34;focalPoint&#34;: (7319, 2861, -3942),
        &#34;distance&#34;: 43901,
    }

    scene.render(zoom=3.5, camera=camera)
    scene.close()


def steinmetz_brain_regions(cache_dir=None):
    &#34;&#34;&#34;
    Write to file the set of regions in each recording.

    Parameters
    ----------
    cache_dir : str
        The path to the directory containing the steinmetz dataset.
        By default None, which uses the path on my PC.


    &#34;&#34;&#34;
    if cache_dir is None:
        cache_dir = (
            r&#34;E:\OpenNeuroData\Steinmetz2019\Steinmetz_et_al_2019_9974357\9974357&#34;
        )
    one = One(cache_dir=cache_dir)  # The location of the unarchived data
    sessions = one.search(dataset=&#34;trials&#34;)

    # Get the location of implanted probes
    brain_regions = []
    here = os.path.abspath(os.path.dirname(__file__))
    with open(os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;allen_regions.txt&#34;), &#34;w&#34;) as f:
        for session in sessions:
            locations = one.load_object(session, &#34;channels&#34;, attribute=&#34;brainLocation&#34;)[
                &#34;brainLocation&#34;
            ]
            brain_regions.append(sorted(list(set(locations[&#34;allen_ontology&#34;].values))))
            f.write(str(brain_regions[-1]) + &#34;\n&#34;)


def load_steinmetz_locations(cache_dir=None):
    &#34;&#34;&#34;
    Load the steinmetz dataset of brain locations from figshare.

    https://figshare.com/articles/dataset/Distributed_coding_of_choice_action_and_engagement_across_the_mouse_brain/9974357

    Parameters
    ----------
    cache_dir : str
        The path to the directory containing the steinmetz dataset.
        By default None, which uses the path on my PC.

    Returns
    -------
    probes_locs : dataframe like
        A dataframe like object containing information on the brain location of probes.

    &#34;&#34;&#34;
    if cache_dir is None:
        cache_dir = (
            r&#34;E:\OpenNeuroData\Steinmetz2019\Steinmetz_et_al_2019_9974357\9974357&#34;
        )
        if not os.path.isdir(cache_dir):
            cache_dir = os.path.join(
                here, &#34;..&#34;, &#34;resources&#34;, &#34;Steinmetz_et_al_2019_9974357&#34;
            )

    one = One(cache_dir=cache_dir)  # The location of the unarchived data
    sessions = one.search(dataset=&#34;trials&#34;)
    # session = sessions[0]  # take the first session
    # trials = one.load_object(session, &#34;trials&#34;)  # load the trials object
    # print(
    #     trials.intervals
    # )  # trials is a Bunch, values are NumPy arrays or pandas DataFrames
    # print(trials.goCue_times)

    # Get the location of implanted probes
    probes_locs = []
    for session in sessions:
        locations = one.load_object(session, &#34;channels&#34;, attribute=&#34;brainLocation&#34;)[
            &#34;brainLocation&#34;
        ]
        probes_locs.append(locations)

    return probes_locs


def vis_steinmetz_with_regions(region_names, colors=None):
    &#34;&#34;&#34;
    Visualise recordings containing regions

    Parameters
    ----------
    region_names : list of str
        The names of the regions
    colors : list of RGB or str, optional
        The colors to use for visualization, by default None

    Returns
    -------
    None

    &#34;&#34;&#34;
    probes_locs = load_steinmetz_locations()

    scene = brainrender.Scene()
    scene.root._silhouette_kwargs[&#34;lw&#34;] = 1
    scene.root.alpha(0.2)

    if colors is None:
        cm = ColorManager(num_colors=len(region_names) + 2, method=&#34;rgb&#34;)
        colors = cm.colors

    for locs in probes_locs:
        brain_regions = locs[&#34;allen_ontology&#34;].values
        cont = False
        for region_name in region_names:
            if region_name not in brain_regions:
                print(sorted(list(set(brain_regions))))
                cont = True

        if cont:
            continue

        k = int(len(locs) / 374.0)

        for i in range(k):
            points = locs[i * 374 : (i + 1) * 374]
            brain_regions = points[&#34;allen_ontology&#34;].values
            cont = True
            for region_name in region_names:
                if region_name in brain_regions:
                    print(sorted(list(set(brain_regions))))
                    cont = False

            if cont:
                continue

            sil = 0.5
            alpha = 0.8
            color_list = [colors[-1]] * len(points)
            spheres = brainrender.actors.Points(
                points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values,
                colors=color_list,
                alpha=alpha,
                radius=20,
            )
            spheres = scene.add(spheres)

            p1 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[0]
            p2 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[-1]

            distance_vec = p2 - p1
            distance = np.sqrt(np.sum(np.square(distance_vec)))
            print(f&#34;Npixels probe is {distance:.2f} units long&#34;)

            mesh = vedo.shapes.Cylinder(pos=[p1, p2], c=colors[-2], r=100, alpha=0.3)
            cylinder = brainrender.actor.Actor(
                mesh, name=&#34;Cylinder&#34;, br_class=&#34;Cylinder&#34;
            )
            scene.add(cylinder)

            if sil:
                scene.add_silhouette(spheres, lw=sil)

    # Add brain regions
    for region_name, color in zip(region_names, colors[:-2]):
        reg = scene.add_brain_region(
            region_name, hemisphere=&#34;right&#34;, alpha=0.3, silhouette=False, color=color
        )
        scene.add_silhouette(reg, lw=2)

    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()

    camera = {
        &#34;pos&#34;: (-16170, -7127, 31776),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (27548, 67414),
        &#34;focalPoint&#34;: (7319, 2861, -3942),
        &#34;distance&#34;: 43901,
    }

    scene.render(zoom=3.5, camera=camera)
    scene.close()


def get_idx_of_points_in_meshes(points, meshes, N=None):
    &#34;&#34;&#34;
    Find the indices of the points inside the given meshes.

    Parameters
    ----------
    points : list of vedo points
        The points to check.
    meshes : list of vedo meshes
        The meshes to check.
    N : int, optional
        A required number of points to find inside the given meshes, by default None

    Returns
    -------
    list of int
        The indices of the points that are inside the given meshes.

    &#34;&#34;&#34;
    ipts = [mesh.insidePoints(points, returnIds=True) for mesh in meshes]

    set_of_points = set()
    for pt in ipts:
        set_of_points.update(pt)
    ipts = list(set_of_points)

    if N is not None:
        return ipts[np.random.choice(ipts.shape[0], N, replace=False), :]
    else:
        return ipts


def get_bounding_probes(region_names, session_id=None, shift=False):
    &#34;&#34;&#34;
    Find the probes which intersect given regions and their bounds.

    Parameters
    ----------
    region_names : list of str
        The names of the regions
    session_id : int, optional
        The session to consider, by default None,
        which uses all sessions.
    shift : bool, optional, by default False
        Whether to shift the probes in the lateral anterior direction.

    Returns
    -------
    list of tuples
        each tuple contains
        found_regions, points, mesh
        where found_regions is a list of regions found
        points is a list of probe site locations in AP, DV, LR
        mesh is a vedo mesh bounding the probe

    &#34;&#34;&#34;
    if session_id is None:
        probes_locs = load_steinmetz_locations()
    else:
        probes_locs = [load_steinmetz_locations()[session_id]]

    info = {}
    for i, locs in enumerate(probes_locs):
        brain_regions = locs[&#34;allen_ontology&#34;].values
        cont = False
        for region_name in region_names:
            if region_name not in brain_regions:
                cont = True

        if cont:
            continue

        # Split into single probes per session
        k = int(len(locs) / 374.0)

        info[i] = []
        for j in range(k):
            points = locs[j * 374 : (j + 1) * 374]

            if shift:
                points[&#34;ccf_lr&#34;] = points[&#34;ccf_lr&#34;] - (points[&#34;ccf_lr&#34;] / 10)
                points[&#34;ccf_ap&#34;] = points[&#34;ccf_ap&#34;] + (points[&#34;ccf_ap&#34;] / 15)
                points[&#34;ccf_dv&#34;] = points[&#34;ccf_dv&#34;] + (points[&#34;ccf_dv&#34;] / 4)

            brain_regions = points[&#34;allen_ontology&#34;].values
            cont = True
            for region_name in region_names:
                if region_name in brain_regions:
                    found_regions = sorted(list(set(brain_regions)))
                    print(f&#34;Found probe in regions: {found_regions}&#34;)
                    cont = False

            if cont:
                continue

            p1 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[0]
            p2 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[-1]

            # 100micron radius cylinder from top to bottom of probe
            n_pixel_micron_radius = 100
            mesh = vedo.shapes.Cylinder(
                pos=[p1, p2], r=n_pixel_micron_radius, alpha=0.3
            )

            info[i].append([found_regions, points, mesh])

    return info


def get_n_random_points_in_region(region_mesh, N, s=None, sort_=False):
    &#34;&#34;&#34;
    Gets N random points inside (or on the surface) of a mesh

    If sort_ is True, performs a Hilbert curve sorting process
    &#34;&#34;&#34;

    region_bounds = region_mesh.bounds()
    if s is None:
        s = int(N * 2)
    X = np.random.randint(region_bounds[0], region_bounds[1], size=s)
    Y = np.random.randint(region_bounds[2], region_bounds[3], size=s)
    Z = np.random.randint(region_bounds[4], region_bounds[5], size=s)
    pts = [[x, y, z] for x, y, z in zip(X, Y, Z)]

    ipts = region_mesh.insidePoints(pts).points()

    if N &lt;= ipts.shape[0]:
        ipts = ipts[:N]
    else:
        ipts = get_n_random_points_in_region(region_mesh, N, s=int(s * 2))

    if sort_:
        hilbert_dim = int(np.floor(np.log10(np.max(ipts)) / np.log10(2)) + 1)
        hilbert_curve = HilbertCurve(hilbert_dim, 3)
        distances = hilbert_curve.distances_from_points(ipts, match_type=True)
        sorted_idxs = distances.argsort()
        ipts = ipts[sorted_idxs]

    return ipts


def get_brain_region_meshes(region_names, atlas_name, hemisphere=&#34;right&#34;):
    # TODO am coverting from brain render
    atlas = brainrender.Atlas(atlas_name=atlas_name)
    root = vedo.load(str(atlas.root_meshfile()))
    atlas.root = root
    # slice to keep only one hemisphere
    if hemisphere == &#34;right&#34;:
        plane = atlas.get_plane(pos=root.centerOfMass(), norm=(0, 0, 1))
    elif hemisphere == &#34;left&#34;:
        plane = atlas.get_plane(pos=root.centerOfMass(), norm=(0, 0, -1))

    region_meshes = []
    for region_name in region_names:
        region_mesh = vedo.load(str(atlas.meshfile_from_structure(region_name)))
        if hemisphere in (&#34;left&#34;, &#34;right&#34;):
            region_mesh.cutWithPlane(
                origin=plane.center,
                normal=plane.normal,
            )

            region_mesh.cap()
        region_meshes.append(region_mesh)

    return region_meshes


def gen_graph_for_regions(
    region_names,
    region_sizes,
    atlas_name=None,
    session_id=None,
    hemisphere=&#34;left&#34;,
    sort_=False,
    shift=False,
):
    &#34;&#34;&#34;
    Generate a set of points in 3D space for given regions and intersect with probes.

    Parameters
    ----------
    region_names : list of str
        The names of the regions involved.
    region_sizes : list of int
        The number of cells to place in each brain region respectively.
    atlas_name : str, optional, by default None
        The name of the atlas to use.
    session_id : int, optional, by default None
        The ID of the recording session to consider.
    hemisphere : str, optional, by default &#34;left&#34;
        The part of the brain to consider.
        &#34;right&#34; or &#34;left&#34; or None.
    sort_ : bool, optional, by default False
        If True, sort the output cells by a Hilbert curve
    shift : bool, optional, by default False
        Whether to shift the probes in the lateral anterior direction.

    Returns
    -------
    (region_pts, brain_region_meshes, probes_to_use)
    region_pts : list of tuples
        (cell locations in the probes, indices of the cells inside the probes)
    brain_region_meshes : list of vedo meshes
        The brain region meshes for plotting purposes
    probes_to_use : list of tuple
        The probe information of the probes used

    &#34;&#34;&#34;
    probe_info = get_bounding_probes(region_names, session_id, shift=shift)
    if len(probe_info) &gt; 1:
        print(&#34;Found multiple matching probes for the given brain regions.&#34;)
        print(&#34;You can visualise these probes using get_bounding_probes method&#34;)
        print(f&#34;These were {probe_info}&#34;)
        print(&#34;Using the first entry for now&#34;)

    probes_to_use = list(probe_info.values())[0]
    # TODO could improve efficiency by storing which regions the probes are in
    all_cylinders = [entry[-1] for entry in probes_to_use]
    brain_region_meshes = get_brain_region_meshes(
        region_names, atlas_name, hemisphere=hemisphere
    )

    region_pts = []
    for region_mesh, region_size in zip(brain_region_meshes, region_sizes):
        pts = get_n_random_points_in_region(region_mesh, region_size, sort_=sort_)
        pts_idxs = np.sort(get_idx_of_points_in_meshes(pts, all_cylinders))
        pts = pts[pts_idxs]
        region_pts.append((pts, pts_idxs))

    return region_pts, brain_region_meshes, probes_to_use


def visualise_probe_cells(
    region_names,
    region_sizes,
    atlas_name=None,
    session_id=None,
    hemisphere=&#34;left&#34;,
    colors=None,
    style=&#34;metallic&#34;,
    interactive=True,
    screenshot_name=None,
    shift=False,
):
    &#34;&#34;&#34;
    Render probes in a recording and the cells in inside probe bounds.

    By default will look for probes in steinmetz data that match the given regions.

    Parameters
    ----------
    region_names : list of str
        The names of the regions
    region_sizes : list of int
        The number of cells in each region
    atlas_name : str, optional
        The name of the atlas, by default None
    session_id : int, optional
        The ID of the session, by default None
    hemisphere : str, optional
        The side of the brain, by default &#34;left&#34;
    colors : list of str or RGB, optional
        The colors to use, by default None
    style : str, optional, by default &#34;metallic&#34;
        The style of rendering to use
    interactive : bool, optional, by default True
        Whether to plot in interactive mode.
    screenshot_name : str, optional, by default None
        Should be passed if interactive is False.
    shift : bool, optional, by default False
        Whether to shift the probes in the lateral anterior direction.

    &#34;&#34;&#34;
    np.random.seed(42)

    # Here is where all the setup of points is done.
    point_locations, brain_region_meshes, probe_info = gen_graph_for_regions(
        region_names,
        region_sizes,
        atlas_name,
        session_id,
        hemisphere,
        sort_=True,
        shift=shift,
    )

    brainrender.settings.SHADER_STYLE = style
    brainrender.settings.SHOW_AXES = False
    brainrender.settings.SCREENSHOT_SCALE = 2
    screenshots_folder = os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;brainrender&#34;)
    scene = brainrender.Scene(screenshots_folder=screenshots_folder, inset=False)

    if colors is None:
        cm = ColorManager(num_colors=len(region_names) + len(probe_info), method=&#34;sns&#34;)
        colors = cm.colors
    iter_color = iter(colors)

    for name, mesh, points_loc in zip(
        region_names, brain_region_meshes, point_locations
    ):
        points_loc = points_loc[0]
        region_color = next(iter_color)
        brain_mesh = brainrender.actor.Actor(
            mesh, name=name, br_class=&#34;brain region&#34;, color=region_color, alpha=0.3
        )
        scene.add(brain_mesh)
        scene.add_silhouette(brain_mesh, lw=2)

        color_list = [region_color] * len(points_loc)
        spheres = brainrender.actors.Points(
            points_loc,
            colors=color_list,
            alpha=0.5,
            radius=15,
        )
        spheres = scene.add(spheres)

        scene.add_silhouette(spheres, lw=0.5)

    for probes in probe_info:
        sphere_color = next(iter_color)
        points = probes[1][[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values
        color_list = [sphere_color] * len(points)
        spheres = brainrender.actors.Points(
            points,
            colors=color_list,
            alpha=0.6,
            radius=20,
        )
        spheres = scene.add(spheres)

        cylinder = brainrender.actor.Actor(
            probes[-1],
            name=&#34;Cylinder&#34;,
            br_class=&#34;Cylinder&#34;,
            color=sphere_color,
            alpha=0.4,
        )
        scene.add(cylinder)

    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()

    camera = {
        &#34;pos&#34;: (-16170, -7127, 31776),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (27548, 67414),
        &#34;focalPoint&#34;: (7319, 2861, -3942),
        &#34;distance&#34;: 43901,
    }
    scene.render(zoom=3.5, camera=camera, interactive=interactive)

    if not interactive:
        scene.screenshot(name=screenshot_name, scale=2)

    scene.close()

    return point_locations


def place_probes_at_com(
    region_names,
    atlas_name=None,
    hemisphere=&#34;left&#34;,
    colors=None,
    style=&#34;cartoon&#34;,
    interactive=True,
    screenshot_name=None,
    probe_kwargs=None,
):
    &#34;&#34;&#34;
    Place probes in regions_names at the centre of mass

    probe_kwargs allows for manual adjustment of parameters.

    &#34;&#34;&#34;
    brainrender.settings.SHADER_STYLE = style
    brainrender.settings.SHOW_AXES = False
    brainrender.settings.SCREENSHOT_SCALE = 2
    screenshots_folder = os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;brainrender&#34;)
    scene = brainrender.Scene(screenshots_folder=screenshots_folder, inset=False)

    if probe_kwargs is None:
        probe_kwargs = {}

    brain_region_meshes = get_brain_region_meshes(
        region_names, atlas_name, hemisphere=hemisphere
    )

    if colors is None:
        cm = ColorManager(num_colors=len(region_names) * 2, method=&#34;sns&#34;)
        colors = cm.colors
    iter_color = iter(colors)

    # com = centre of mass
    coms = np.zeros((len(region_names), 3))

    for i, (name, mesh) in enumerate(zip(region_names, brain_region_meshes)):
        bounds = mesh.bounds()
        arr1 = np.array([bounds[0], bounds[2], bounds[4]])
        arr2 = np.array([bounds[1], bounds[3], bounds[5]])
        com = (arr2 + arr1) / 2.0
        coms[i] = com

        region_color = next(iter_color)
        brain_mesh = brainrender.actor.Actor(
            mesh, name=name, br_class=&#34;brain region&#34;, color=region_color, alpha=0.3
        )
        scene.add(brain_mesh)
        scene.add_silhouette(brain_mesh, lw=2)

    n_pixel_micron_radius = 100

    if isinstance(probe_kwargs, dict):
        probe_kwargs = [probe_kwargs]

    atlas = brainrender.Atlas(atlas_name)
    root_mesh = vedo.load(str(atlas.meshfile_from_structure(&#34;root&#34;)))
    top_of_brain = root_mesh.bounds()[2]

    for i in range(len(coms) // 2):
        c1 = coms[i]
        c2 = coms[i + 1]

        centre_top = c1
        centre_bottom = c2
        if centre_top[1] &gt; centre_bottom[1]:
            centre_top = c2
            centre_bottom = c1

        # scene.add(
        #     brainrender.actors.Points(
        #         np.array([centre_top, centre_bottom]),
        #         name=&#34;&#34;,
        #         colors=[&#34;b&#34;, &#34;k&#34;],
        #         radius=50,
        #     )
        # )

    for i in range(len(coms) // 2):
        region_color = next(iter_color)
        for probe_dict in probe_kwargs:
            top_scale = probe_dict.get(&#34;top_scale&#34;, 1.0)
            angles_top = probe_dict.get(&#34;angles_top&#34;, [0, 0, 0])
            angles_bottom = probe_dict.get(&#34;angles_bottom&#34;, [0, 0, 0])

            ## Rotate the top
            r = R.from_euler(&#34;zyx&#34;, angles_top, degrees=True)
            rotated_top = r.apply(centre_bottom)
            top = rotated_top + (centre_top - centre_bottom)

            ## Rotate the bottom
            r = R.from_euler(&#34;zyx&#34;, angles_bottom, degrees=True)
            rotated_bottom = r.apply(centre_top)
            bottom = rotated_bottom + (centre_bottom - centre_top)

            ## Move to top
            vec_in_dir = top - bottom
            scale_top = (top_of_brain - top[1]) / vec_in_dir[1]
            top = top + (top_scale * scale_top * vec_in_dir)
            vec_in_dir = bottom - top
            vec_in_dir_norm = vec_in_dir / np.linalg.norm(vec_in_dir)
            bottom = top + (vec_in_dir_norm * 3820)

            cylinder = vedo.shapes.Cylinder(
                pos=[top, bottom], r=n_pixel_micron_radius, alpha=0.35
            )
            cyl_for_br = vedo.shapes.Cylinder(
                pos=[top, bottom], r=n_pixel_micron_radius, alpha=0.35
            )
            cyl_br = brainrender.actor.Actor(
                cyl_for_br,
                name=&#34;Cylinder&#34;,
                br_class=&#34;Cylinder&#34;,
                color=region_color,
                alpha=0.35,
            )
            scene.add(cyl_br)

            cyl_mesh = vedo.shapes.Cylinder(pos=[top, bottom], r=30, alpha=0.8)
            inside_cyl = brainrender.actor.Actor(
                cyl_mesh,
                name=&#34;inside&#34;,
                br_class=&#34;Cylinder&#34;,
                color=region_color,
                alpha=0.8,
            )
            scene.add(inside_cyl)

            # scene.add(
            #     brainrender.actors.Points(
            #         np.array([top, bottom]), name=&#34;&#34;, colors=[&#34;r&#34;, &#34;g&#34;], radius=50
            #     )
            # )

    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()

    camera = {
        &#34;pos&#34;: (-40394, -5346, -54832),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (53156, 88185),
        &#34;focalPoint&#34;: (6446, 4615, -5524),
        &#34;distance&#34;: 68734,
    }

    scene.render(zoom=3.5, camera=camera, interactive=interactive)

    if not interactive:
        scene.screenshot(name=screenshot_name, scale=2)

    scene.close()

    return cylinder


if __name__ == &#34;__main__&#34;:
    ### Testing smaller functions
    # show_atlases()
    # main_regions = [&#34;CA&#34;, &#34;PL&#34;]
    # main_colours = [&#34;k&#34;, &#34;b&#34;]
    # vedo_vis(main_regions, None)
    # make_probes()
    # steinmetz_brain_regions()
    # vis_steinmetz_with_regions([&#34;VISp&#34;, &#34;VISl&#34;])
    # main_regions = [&#34;MOp&#34;, &#34;SSp-ll&#34;]
    # brainrender_vis(main_regions, None)

    #### Visualise probes and cells
    # for style in (&#34;cartoon&#34;, &#34;metallic&#34;, &#34;plastic&#34;, &#34;shiny&#34;, &#34;glossy&#34;):
    # style = &#34;cartoon&#34;
    # colors = ColorManager(4, method=&#34;sns&#34;, sns_style=&#34;deep&#34;).colors
    # visualise_probe_cells(
    #     [&#34;VISp&#34;, &#34;VISl&#34;],
    #     [30000, 10000],
    #     atlas_name=&#34;allen_mouse_25um&#34;,
    #     session_id=None,
    #     hemisphere=&#34;left&#34;,
    #     colors=colors,
    #     style=style,
    # )

    #### Visualise COMs
    # place_probes_at_com([&#34;ILA&#34;, &#34;PL&#34;])
    # place_probes_at_com([&#34;MOp&#34;, &#34;SSp-ll&#34;], join=True)
    interactive = True
    f1 = False
    f2 = True
    f3 = False
    f4 = False

    if f1:
        probe_kwargs = [
            {},
            dict(top_scale=0.8, angles_top=[0, 0, 5], angles_bottom=[0, 0, -5]),
            dict(top_scale=0.9, angles_top=[0, 0, 3], angles_bottom=[0, 0, -2]),
        ]

        place_probes_at_com(
            [&#34;MOp&#34;, &#34;SSp-ll&#34;],
            probe_kwargs=probe_kwargs,
            hemisphere=&#34;right&#34;,
            interactive=interactive,
        )

    if f2:
        probe_kwargs = [
            {},
            dict(top_scale=0.4, angles_top=[0, 0, 10], angles_bottom=[0, 0, -5]),
            dict(top_scale=0.4, angles_top=[1, 0, 5], angles_bottom=[1, 0, -2]),
        ]

        place_probes_at_com(
            (&#34;VISp&#34;, &#34;VISl&#34;),
            probe_kwargs=probe_kwargs,
            hemisphere=&#34;right&#34;,
            interactive=interactive,
        )

    if f3:
        probe_kwargs = [
            {},
            dict(top_scale=0.8, angles_top=[0, 0, 5], angles_bottom=[0, 0, -5]),
            dict(top_scale=0.83, angles_top=[0, 0, 3], angles_bottom=[0, 0, -2]),
        ]

        place_probes_at_com(
            (&#34;AUDp&#34;, &#34;AUDpo&#34;),
            probe_kwargs=probe_kwargs,
            hemisphere=&#34;right&#34;,
            interactive=interactive,
        )

    if f4:
        probe_kwargs = [
            {},
            dict(top_scale=0.5, angles_top=[0, 0, 10], angles_bottom=[0, 0, -5]),
            dict(top_scale=0.83, angles_top=[0, 0, 3], angles_bottom=[0, 0, -2]),
        ]

        place_probes_at_com(
            (&#34;ILA&#34;, &#34;PL&#34;),
            probe_kwargs=probe_kwargs,
            hemisphere=&#34;right&#34;,
            interactive=interactive,
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="neuroconnect.atlas.brainrender_vis"><code class="name flex">
<span>def <span class="ident">brainrender_vis</span></span>(<span>regions, colors=None, atlas_name='allen_mouse_25um')</span>
</code></dt>
<dd>
<div class="desc"><p>Visualise regions in atlas using brainrender</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def brainrender_vis(regions, colors=None, atlas_name=&#34;allen_mouse_25um&#34;):
    &#34;&#34;&#34;Visualise regions in atlas using brainrender&#34;&#34;&#34;

    if colors is None:
        cm = ColorManager(num_colors=len(regions), method=&#34;rgb&#34;)
        colors = cm.colors

    def get_n_random_points_in_region(region, N):
        &#34;&#34;&#34;
        Gets N random points inside (or on the surface) of a mes
        &#34;&#34;&#34;

        region_bounds = region.mesh.bounds()
        X = np.random.randint(region_bounds[0], region_bounds[1], size=10000)
        Y = np.random.randint(region_bounds[2], region_bounds[3], size=10000)
        Z = np.random.randint(region_bounds[4], region_bounds[5], size=10000)
        pts = [[x, y, z] for x, y, z in zip(X, Y, Z)]

        ipts = region.mesh.insidePoints(pts).points()

        if N &lt; ipts.shape[0]:
            return ipts[np.random.choice(ipts.shape[0], N, replace=False), :]
        else:
            return ipts

    scene = brainrender.Scene(root=True, title=&#34;Labelled cells&#34;, atlas_name=atlas_name)

    # Get a numpy array with (fake) coordinates of some labelled cells
    brain_region_actors = []
    for region, color in zip(regions, colors):
        brain_region = scene.add_brain_region(region, alpha=0.15, color=color)
        coordinates = get_n_random_points_in_region(brain_region.mesh, 2000)
        color = [color] * coordinates.shape[0]

        # Add to scene
        scene.add(
            brainrender.actors.Points(coordinates, name=f&#34;{region} CELLS&#34;, colors=color)
        )
        brain_region_actors.append(brain_region)

    hemisphere_points = [
        get_points_in_hemisphere(scene.atlas, brain_region_actor)
        for brain_region_actor in brain_region_actors
    ]

    p1 = hemisphere_points[0].mean(axis=0)
    p2 = hemisphere_points[1].mean(axis=0)

    mesh = vedo.shapes.Cylinder(pos=[p1, p2], c=&#34;blue&#34;, r=100, alpha=0.5)
    cylinder = brainrender.actor.Actor(mesh, name=&#34;Cylinder&#34;, br_class=&#34;Cylinder&#34;)

    scene.add(cylinder)

    # render
    scene.content
    scene.render()</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.gen_graph_for_regions"><code class="name flex">
<span>def <span class="ident">gen_graph_for_regions</span></span>(<span>region_names, region_sizes, atlas_name=None, session_id=None, hemisphere='left', sort_=False, shift=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a set of points in 3D space for given regions and intersect with probes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>region_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>The names of the regions involved.</dd>
<dt><strong><code>region_sizes</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>The number of cells to place in each brain region respectively.</dd>
<dt><strong><code>atlas_name</code></strong> :&ensp;<code>str</code>, optional<code>, by default None</code></dt>
<dd>The name of the atlas to use.</dd>
<dt><strong><code>session_id</code></strong> :&ensp;<code>int</code>, optional<code>, by default None</code></dt>
<dd>The ID of the recording session to consider.</dd>
<dt><strong><code>hemisphere</code></strong> :&ensp;<code>str</code>, optional<code>, by default "left"</code></dt>
<dd>The part of the brain to consider.
"right" or "left" or None.</dd>
<dt><strong><code>sort_</code></strong> :&ensp;<code>bool</code>, optional<code>, by default False</code></dt>
<dd>If True, sort the output cells by a Hilbert curve</dd>
<dt><strong><code>shift</code></strong> :&ensp;<code>bool</code>, optional<code>, by default False</code></dt>
<dd>Whether to shift the probes in the lateral anterior direction.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt>(region_pts, brain_region_meshes, probes_to_use)</dt>
<dt><strong><code>region_pts</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>(cell locations in the probes, indices of the cells inside the probes)</dd>
<dt><strong><code>brain_region_meshes</code></strong> :&ensp;<code>list</code> of <code>vedo meshes</code></dt>
<dd>The brain region meshes for plotting purposes</dd>
<dt><strong><code>probes_to_use</code></strong> :&ensp;<code>list</code> of <code>tuple</code></dt>
<dd>The probe information of the probes used</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_graph_for_regions(
    region_names,
    region_sizes,
    atlas_name=None,
    session_id=None,
    hemisphere=&#34;left&#34;,
    sort_=False,
    shift=False,
):
    &#34;&#34;&#34;
    Generate a set of points in 3D space for given regions and intersect with probes.

    Parameters
    ----------
    region_names : list of str
        The names of the regions involved.
    region_sizes : list of int
        The number of cells to place in each brain region respectively.
    atlas_name : str, optional, by default None
        The name of the atlas to use.
    session_id : int, optional, by default None
        The ID of the recording session to consider.
    hemisphere : str, optional, by default &#34;left&#34;
        The part of the brain to consider.
        &#34;right&#34; or &#34;left&#34; or None.
    sort_ : bool, optional, by default False
        If True, sort the output cells by a Hilbert curve
    shift : bool, optional, by default False
        Whether to shift the probes in the lateral anterior direction.

    Returns
    -------
    (region_pts, brain_region_meshes, probes_to_use)
    region_pts : list of tuples
        (cell locations in the probes, indices of the cells inside the probes)
    brain_region_meshes : list of vedo meshes
        The brain region meshes for plotting purposes
    probes_to_use : list of tuple
        The probe information of the probes used

    &#34;&#34;&#34;
    probe_info = get_bounding_probes(region_names, session_id, shift=shift)
    if len(probe_info) &gt; 1:
        print(&#34;Found multiple matching probes for the given brain regions.&#34;)
        print(&#34;You can visualise these probes using get_bounding_probes method&#34;)
        print(f&#34;These were {probe_info}&#34;)
        print(&#34;Using the first entry for now&#34;)

    probes_to_use = list(probe_info.values())[0]
    # TODO could improve efficiency by storing which regions the probes are in
    all_cylinders = [entry[-1] for entry in probes_to_use]
    brain_region_meshes = get_brain_region_meshes(
        region_names, atlas_name, hemisphere=hemisphere
    )

    region_pts = []
    for region_mesh, region_size in zip(brain_region_meshes, region_sizes):
        pts = get_n_random_points_in_region(region_mesh, region_size, sort_=sort_)
        pts_idxs = np.sort(get_idx_of_points_in_meshes(pts, all_cylinders))
        pts = pts[pts_idxs]
        region_pts.append((pts, pts_idxs))

    return region_pts, brain_region_meshes, probes_to_use</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.get_bounding_probes"><code class="name flex">
<span>def <span class="ident">get_bounding_probes</span></span>(<span>region_names, session_id=None, shift=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the probes which intersect given regions and their bounds.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>region_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>The names of the regions</dd>
<dt><strong><code>session_id</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The session to consider, by default None,
which uses all sessions.</dd>
<dt><strong><code>shift</code></strong> :&ensp;<code>bool</code>, optional<code>, by default False</code></dt>
<dd>Whether to shift the probes in the lateral anterior direction.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tuples</code></dt>
<dd>each tuple contains
found_regions, points, mesh
where found_regions is a list of regions found
points is a list of probe site locations in AP, DV, LR
mesh is a vedo mesh bounding the probe</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_bounding_probes(region_names, session_id=None, shift=False):
    &#34;&#34;&#34;
    Find the probes which intersect given regions and their bounds.

    Parameters
    ----------
    region_names : list of str
        The names of the regions
    session_id : int, optional
        The session to consider, by default None,
        which uses all sessions.
    shift : bool, optional, by default False
        Whether to shift the probes in the lateral anterior direction.

    Returns
    -------
    list of tuples
        each tuple contains
        found_regions, points, mesh
        where found_regions is a list of regions found
        points is a list of probe site locations in AP, DV, LR
        mesh is a vedo mesh bounding the probe

    &#34;&#34;&#34;
    if session_id is None:
        probes_locs = load_steinmetz_locations()
    else:
        probes_locs = [load_steinmetz_locations()[session_id]]

    info = {}
    for i, locs in enumerate(probes_locs):
        brain_regions = locs[&#34;allen_ontology&#34;].values
        cont = False
        for region_name in region_names:
            if region_name not in brain_regions:
                cont = True

        if cont:
            continue

        # Split into single probes per session
        k = int(len(locs) / 374.0)

        info[i] = []
        for j in range(k):
            points = locs[j * 374 : (j + 1) * 374]

            if shift:
                points[&#34;ccf_lr&#34;] = points[&#34;ccf_lr&#34;] - (points[&#34;ccf_lr&#34;] / 10)
                points[&#34;ccf_ap&#34;] = points[&#34;ccf_ap&#34;] + (points[&#34;ccf_ap&#34;] / 15)
                points[&#34;ccf_dv&#34;] = points[&#34;ccf_dv&#34;] + (points[&#34;ccf_dv&#34;] / 4)

            brain_regions = points[&#34;allen_ontology&#34;].values
            cont = True
            for region_name in region_names:
                if region_name in brain_regions:
                    found_regions = sorted(list(set(brain_regions)))
                    print(f&#34;Found probe in regions: {found_regions}&#34;)
                    cont = False

            if cont:
                continue

            p1 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[0]
            p2 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[-1]

            # 100micron radius cylinder from top to bottom of probe
            n_pixel_micron_radius = 100
            mesh = vedo.shapes.Cylinder(
                pos=[p1, p2], r=n_pixel_micron_radius, alpha=0.3
            )

            info[i].append([found_regions, points, mesh])

    return info</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.get_brain_region_meshes"><code class="name flex">
<span>def <span class="ident">get_brain_region_meshes</span></span>(<span>region_names, atlas_name, hemisphere='right')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_brain_region_meshes(region_names, atlas_name, hemisphere=&#34;right&#34;):
    # TODO am coverting from brain render
    atlas = brainrender.Atlas(atlas_name=atlas_name)
    root = vedo.load(str(atlas.root_meshfile()))
    atlas.root = root
    # slice to keep only one hemisphere
    if hemisphere == &#34;right&#34;:
        plane = atlas.get_plane(pos=root.centerOfMass(), norm=(0, 0, 1))
    elif hemisphere == &#34;left&#34;:
        plane = atlas.get_plane(pos=root.centerOfMass(), norm=(0, 0, -1))

    region_meshes = []
    for region_name in region_names:
        region_mesh = vedo.load(str(atlas.meshfile_from_structure(region_name)))
        if hemisphere in (&#34;left&#34;, &#34;right&#34;):
            region_mesh.cutWithPlane(
                origin=plane.center,
                normal=plane.normal,
            )

            region_mesh.cap()
        region_meshes.append(region_mesh)

    return region_meshes</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.get_idx_of_points_in_meshes"><code class="name flex">
<span>def <span class="ident">get_idx_of_points_in_meshes</span></span>(<span>points, meshes, N=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the indices of the points inside the given meshes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>points</code></strong> :&ensp;<code>list</code> of <code>vedo points</code></dt>
<dd>The points to check.</dd>
<dt><strong><code>meshes</code></strong> :&ensp;<code>list</code> of <code>vedo meshes</code></dt>
<dd>The meshes to check.</dd>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>A required number of points to find inside the given meshes, by default None</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>int</code></dt>
<dd>The indices of the points that are inside the given meshes.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_idx_of_points_in_meshes(points, meshes, N=None):
    &#34;&#34;&#34;
    Find the indices of the points inside the given meshes.

    Parameters
    ----------
    points : list of vedo points
        The points to check.
    meshes : list of vedo meshes
        The meshes to check.
    N : int, optional
        A required number of points to find inside the given meshes, by default None

    Returns
    -------
    list of int
        The indices of the points that are inside the given meshes.

    &#34;&#34;&#34;
    ipts = [mesh.insidePoints(points, returnIds=True) for mesh in meshes]

    set_of_points = set()
    for pt in ipts:
        set_of_points.update(pt)
    ipts = list(set_of_points)

    if N is not None:
        return ipts[np.random.choice(ipts.shape[0], N, replace=False), :]
    else:
        return ipts</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.get_n_random_points_in_region"><code class="name flex">
<span>def <span class="ident">get_n_random_points_in_region</span></span>(<span>region_mesh, N, s=None, sort_=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets N random points inside (or on the surface) of a mesh</p>
<p>If sort_ is True, performs a Hilbert curve sorting process</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_n_random_points_in_region(region_mesh, N, s=None, sort_=False):
    &#34;&#34;&#34;
    Gets N random points inside (or on the surface) of a mesh

    If sort_ is True, performs a Hilbert curve sorting process
    &#34;&#34;&#34;

    region_bounds = region_mesh.bounds()
    if s is None:
        s = int(N * 2)
    X = np.random.randint(region_bounds[0], region_bounds[1], size=s)
    Y = np.random.randint(region_bounds[2], region_bounds[3], size=s)
    Z = np.random.randint(region_bounds[4], region_bounds[5], size=s)
    pts = [[x, y, z] for x, y, z in zip(X, Y, Z)]

    ipts = region_mesh.insidePoints(pts).points()

    if N &lt;= ipts.shape[0]:
        ipts = ipts[:N]
    else:
        ipts = get_n_random_points_in_region(region_mesh, N, s=int(s * 2))

    if sort_:
        hilbert_dim = int(np.floor(np.log10(np.max(ipts)) / np.log10(2)) + 1)
        hilbert_curve = HilbertCurve(hilbert_dim, 3)
        distances = hilbert_curve.distances_from_points(ipts, match_type=True)
        sorted_idxs = distances.argsort()
        ipts = ipts[sorted_idxs]

    return ipts</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.get_points_in_hemisphere"><code class="name flex">
<span>def <span class="ident">get_points_in_hemisphere</span></span>(<span>atlas, region_actor, side='left')</span>
</code></dt>
<dd>
<div class="desc"><p>Return all points for a given region on one side</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_points_in_hemisphere(atlas, region_actor, side=&#34;left&#34;):
    &#34;&#34;&#34;Return all points for a given region on one side&#34;&#34;&#34;
    all_points = region_actor.mesh.points()
    points_in_hemisphere = np.array(
        [
            point
            for point in all_points
            if atlas.hemisphere_from_coords(point, as_string=True, microns=True) == side
        ]
    )

    return points_in_hemisphere</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.load_steinmetz_locations"><code class="name flex">
<span>def <span class="ident">load_steinmetz_locations</span></span>(<span>cache_dir=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the steinmetz dataset of brain locations from figshare.</p>
<p><a href="https://figshare.com/articles/dataset/Distributed_coding_of_choice_action_and_engagement_across_the_mouse_brain/9974357">https://figshare.com/articles/dataset/Distributed_coding_of_choice_action_and_engagement_across_the_mouse_brain/9974357</a></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cache_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the directory containing the steinmetz dataset.
By default None, which uses the path on my PC.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>probes_locs</code></strong> :&ensp;<code>dataframe like</code></dt>
<dd>A dataframe like object containing information on the brain location of probes.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_steinmetz_locations(cache_dir=None):
    &#34;&#34;&#34;
    Load the steinmetz dataset of brain locations from figshare.

    https://figshare.com/articles/dataset/Distributed_coding_of_choice_action_and_engagement_across_the_mouse_brain/9974357

    Parameters
    ----------
    cache_dir : str
        The path to the directory containing the steinmetz dataset.
        By default None, which uses the path on my PC.

    Returns
    -------
    probes_locs : dataframe like
        A dataframe like object containing information on the brain location of probes.

    &#34;&#34;&#34;
    if cache_dir is None:
        cache_dir = (
            r&#34;E:\OpenNeuroData\Steinmetz2019\Steinmetz_et_al_2019_9974357\9974357&#34;
        )
        if not os.path.isdir(cache_dir):
            cache_dir = os.path.join(
                here, &#34;..&#34;, &#34;resources&#34;, &#34;Steinmetz_et_al_2019_9974357&#34;
            )

    one = One(cache_dir=cache_dir)  # The location of the unarchived data
    sessions = one.search(dataset=&#34;trials&#34;)
    # session = sessions[0]  # take the first session
    # trials = one.load_object(session, &#34;trials&#34;)  # load the trials object
    # print(
    #     trials.intervals
    # )  # trials is a Bunch, values are NumPy arrays or pandas DataFrames
    # print(trials.goCue_times)

    # Get the location of implanted probes
    probes_locs = []
    for session in sessions:
        locations = one.load_object(session, &#34;channels&#34;, attribute=&#34;brainLocation&#34;)[
            &#34;brainLocation&#34;
        ]
        probes_locs.append(locations)

    return probes_locs</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.make_probes"><code class="name flex">
<span>def <span class="ident">make_probes</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Visualise some actual probes that were recorded with.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_probes():
    &#34;&#34;&#34;Visualise some actual probes that were recorded with.&#34;&#34;&#34;
    # render a bunch of probes as sets of spheres (one per channel)
    scene = brainrender.Scene()
    scene.root._silhouette_kwargs[&#34;lw&#34;] = 1
    scene.root.alpha(0.2)
    probes_locs = load_steinmetz_locations()

    for locs in probes_locs:
        k = int(len(locs) / 374.0)

        for i in range(k):
            points = locs[i * 374 : (i + 1) * 374]
            regs = points.allen_ontology.values

            if &#34;LGd&#34; in regs and (&#34;VISa&#34; in regs or &#34;VISp&#34; in regs):
                color = myterial.salmon_darker
                alpha = 1
                sil = 1
            elif &#34;VISa&#34; in regs:
                color = myterial.salmon_light
                alpha = 1
                sil = 0.5
            else:
                continue

            spheres = brainrender.actors.Points(
                points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values,
                colors=color,
                alpha=alpha,
                radius=30,
            )
            spheres = scene.add(spheres)

            p1 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[0]
            p2 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[-1]
            mesh = vedo.shapes.Cylinder(pos=[p1, p2], c=color, r=100, alpha=0.3)
            cylinder = brainrender.actor.Actor(
                mesh, name=&#34;Cylinder&#34;, br_class=&#34;Cylinder&#34;
            )
            scene.add(cylinder)

            if sil:
                scene.add_silhouette(spheres, lw=sil)

    # Add brain regions
    visp, lgd = scene.add_brain_region(
        &#34;VISp&#34;,
        &#34;LGd&#34;,
        hemisphere=&#34;right&#34;,
        alpha=0.3,
        silhouette=False,
        color=myterial.blue_grey_dark,
    )
    visa = scene.add_brain_region(
        &#34;VISa&#34;,
        hemisphere=&#34;right&#34;,
        alpha=0.2,
        silhouette=False,
        color=myterial.blue_grey,
    )
    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()
    scene.add_silhouette(lgd, visp, lw=2)

    camera = {
        &#34;pos&#34;: (-16170, -7127, 31776),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (27548, 67414),
        &#34;focalPoint&#34;: (7319, 2861, -3942),
        &#34;distance&#34;: 43901,
    }

    scene.render(zoom=3.5, camera=camera)
    scene.close()</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.place_probes_at_com"><code class="name flex">
<span>def <span class="ident">place_probes_at_com</span></span>(<span>region_names, atlas_name=None, hemisphere='left', colors=None, style='cartoon', interactive=True, screenshot_name=None, probe_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Place probes in regions_names at the centre of mass</p>
<p>probe_kwargs allows for manual adjustment of parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def place_probes_at_com(
    region_names,
    atlas_name=None,
    hemisphere=&#34;left&#34;,
    colors=None,
    style=&#34;cartoon&#34;,
    interactive=True,
    screenshot_name=None,
    probe_kwargs=None,
):
    &#34;&#34;&#34;
    Place probes in regions_names at the centre of mass

    probe_kwargs allows for manual adjustment of parameters.

    &#34;&#34;&#34;
    brainrender.settings.SHADER_STYLE = style
    brainrender.settings.SHOW_AXES = False
    brainrender.settings.SCREENSHOT_SCALE = 2
    screenshots_folder = os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;brainrender&#34;)
    scene = brainrender.Scene(screenshots_folder=screenshots_folder, inset=False)

    if probe_kwargs is None:
        probe_kwargs = {}

    brain_region_meshes = get_brain_region_meshes(
        region_names, atlas_name, hemisphere=hemisphere
    )

    if colors is None:
        cm = ColorManager(num_colors=len(region_names) * 2, method=&#34;sns&#34;)
        colors = cm.colors
    iter_color = iter(colors)

    # com = centre of mass
    coms = np.zeros((len(region_names), 3))

    for i, (name, mesh) in enumerate(zip(region_names, brain_region_meshes)):
        bounds = mesh.bounds()
        arr1 = np.array([bounds[0], bounds[2], bounds[4]])
        arr2 = np.array([bounds[1], bounds[3], bounds[5]])
        com = (arr2 + arr1) / 2.0
        coms[i] = com

        region_color = next(iter_color)
        brain_mesh = brainrender.actor.Actor(
            mesh, name=name, br_class=&#34;brain region&#34;, color=region_color, alpha=0.3
        )
        scene.add(brain_mesh)
        scene.add_silhouette(brain_mesh, lw=2)

    n_pixel_micron_radius = 100

    if isinstance(probe_kwargs, dict):
        probe_kwargs = [probe_kwargs]

    atlas = brainrender.Atlas(atlas_name)
    root_mesh = vedo.load(str(atlas.meshfile_from_structure(&#34;root&#34;)))
    top_of_brain = root_mesh.bounds()[2]

    for i in range(len(coms) // 2):
        c1 = coms[i]
        c2 = coms[i + 1]

        centre_top = c1
        centre_bottom = c2
        if centre_top[1] &gt; centre_bottom[1]:
            centre_top = c2
            centre_bottom = c1

        # scene.add(
        #     brainrender.actors.Points(
        #         np.array([centre_top, centre_bottom]),
        #         name=&#34;&#34;,
        #         colors=[&#34;b&#34;, &#34;k&#34;],
        #         radius=50,
        #     )
        # )

    for i in range(len(coms) // 2):
        region_color = next(iter_color)
        for probe_dict in probe_kwargs:
            top_scale = probe_dict.get(&#34;top_scale&#34;, 1.0)
            angles_top = probe_dict.get(&#34;angles_top&#34;, [0, 0, 0])
            angles_bottom = probe_dict.get(&#34;angles_bottom&#34;, [0, 0, 0])

            ## Rotate the top
            r = R.from_euler(&#34;zyx&#34;, angles_top, degrees=True)
            rotated_top = r.apply(centre_bottom)
            top = rotated_top + (centre_top - centre_bottom)

            ## Rotate the bottom
            r = R.from_euler(&#34;zyx&#34;, angles_bottom, degrees=True)
            rotated_bottom = r.apply(centre_top)
            bottom = rotated_bottom + (centre_bottom - centre_top)

            ## Move to top
            vec_in_dir = top - bottom
            scale_top = (top_of_brain - top[1]) / vec_in_dir[1]
            top = top + (top_scale * scale_top * vec_in_dir)
            vec_in_dir = bottom - top
            vec_in_dir_norm = vec_in_dir / np.linalg.norm(vec_in_dir)
            bottom = top + (vec_in_dir_norm * 3820)

            cylinder = vedo.shapes.Cylinder(
                pos=[top, bottom], r=n_pixel_micron_radius, alpha=0.35
            )
            cyl_for_br = vedo.shapes.Cylinder(
                pos=[top, bottom], r=n_pixel_micron_radius, alpha=0.35
            )
            cyl_br = brainrender.actor.Actor(
                cyl_for_br,
                name=&#34;Cylinder&#34;,
                br_class=&#34;Cylinder&#34;,
                color=region_color,
                alpha=0.35,
            )
            scene.add(cyl_br)

            cyl_mesh = vedo.shapes.Cylinder(pos=[top, bottom], r=30, alpha=0.8)
            inside_cyl = brainrender.actor.Actor(
                cyl_mesh,
                name=&#34;inside&#34;,
                br_class=&#34;Cylinder&#34;,
                color=region_color,
                alpha=0.8,
            )
            scene.add(inside_cyl)

            # scene.add(
            #     brainrender.actors.Points(
            #         np.array([top, bottom]), name=&#34;&#34;, colors=[&#34;r&#34;, &#34;g&#34;], radius=50
            #     )
            # )

    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()

    camera = {
        &#34;pos&#34;: (-40394, -5346, -54832),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (53156, 88185),
        &#34;focalPoint&#34;: (6446, 4615, -5524),
        &#34;distance&#34;: 68734,
    }

    scene.render(zoom=3.5, camera=camera, interactive=interactive)

    if not interactive:
        scene.screenshot(name=screenshot_name, scale=2)

    scene.close()

    return cylinder</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.steinmetz_brain_regions"><code class="name flex">
<span>def <span class="ident">steinmetz_brain_regions</span></span>(<span>cache_dir=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Write to file the set of regions in each recording.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cache_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the directory containing the steinmetz dataset.
By default None, which uses the path on my PC.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def steinmetz_brain_regions(cache_dir=None):
    &#34;&#34;&#34;
    Write to file the set of regions in each recording.

    Parameters
    ----------
    cache_dir : str
        The path to the directory containing the steinmetz dataset.
        By default None, which uses the path on my PC.


    &#34;&#34;&#34;
    if cache_dir is None:
        cache_dir = (
            r&#34;E:\OpenNeuroData\Steinmetz2019\Steinmetz_et_al_2019_9974357\9974357&#34;
        )
    one = One(cache_dir=cache_dir)  # The location of the unarchived data
    sessions = one.search(dataset=&#34;trials&#34;)

    # Get the location of implanted probes
    brain_regions = []
    here = os.path.abspath(os.path.dirname(__file__))
    with open(os.path.join(here, &#34;..&#34;, &#34;results&#34;, &#34;allen_regions.txt&#34;), &#34;w&#34;) as f:
        for session in sessions:
            locations = one.load_object(session, &#34;channels&#34;, attribute=&#34;brainLocation&#34;)[
                &#34;brainLocation&#34;
            ]
            brain_regions.append(sorted(list(set(locations[&#34;allen_ontology&#34;].values))))
            f.write(str(brain_regions[-1]) + &#34;\n&#34;)</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.vedo_vis"><code class="name flex">
<span>def <span class="ident">vedo_vis</span></span>(<span>regions, colors=None, atlas_name='allen_mouse_25um')</span>
</code></dt>
<dd>
<div class="desc"><p>Visualise regions of atlas using vedo.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vedo_vis(regions, colors=None, atlas_name=&#34;allen_mouse_25um&#34;):
    &#34;&#34;&#34;Visualise regions of atlas using vedo.&#34;&#34;&#34;
    bg_atlas = BrainGlobeAtlas(atlas_name, check_latest=False)
    pprint(bg_atlas.metadata)

    if colors is None:
        cm = ColorManager(num_colors=len(regions), method=&#34;rgb&#34;)
        colors = cm.colors

    # Show the full heirarchy
    # pprint(bg_atlas.structures.tree.show())

    # The order of x, y, z in the dataset
    ## This assumes asr layout.
    mapping = [2, 0, 1]
    max_x = bg_atlas.resolution[mapping[0]] * bg_atlas.shape[mapping[0]]
    max_y = bg_atlas.resolution[mapping[1]] * bg_atlas.shape[mapping[1]]
    max_z = bg_atlas.resolution[mapping[2]] * bg_atlas.shape[mapping[2]]
    full_size = bg_atlas.shape[0] * bg_atlas.shape[1] * bg_atlas.shape[2]

    points_list = []
    for region in regions:
        mask = bg_atlas.get_structure_mask(region)
        structure_id = bg_atlas.structures[region][&#34;id&#34;]
        y, z, x = np.nonzero(mask == structure_id)
        vol_pc = round((100 * x.shape[0]) / full_size, 2)
        n_sample_points = x.shape[0] // 500
        choice = np.random.randint(low=0, high=x.shape[0], size=n_sample_points)
        x = x[choice] * bg_atlas.resolution[mapping[0]] - (max_x // 2)
        y = y[choice] * bg_atlas.resolution[mapping[1]] - (max_y // 2)
        z = z[choice] * bg_atlas.resolution[mapping[2]] - (max_z // 2)

        print(f&#34;{region} occupies {vol_pc}% of the full brain&#34;)
        points_list.append((x, y, z))

    vedo_points = []
    for val, color in zip(points_list, colors):
        vedo_points.append(vedo.Points(np.array(val)).c(color))
    # axs = vedo.Axes(
    #     vedo_points,
    #     xtitle=&#34;X-axis in \mum&#34;,
    #     ytitle=&#34;Variable Y in \mum&#34;,
    #     ztitle=&#34;Inverted Z in \mum&#34;,
    #     htitle=&#34;My \Gamma^2_ijk  plot&#34;,
    #     hTitleFont=&#34;Kanopus&#34;,
    #     hTitleJustify=&#34;bottom-right&#34;,
    #     hTitleColor=&#34;red2&#34;,
    #     hTitleSize=0.035,
    #     hTitleOffset=(0, 0.075, 0),
    #     hTitleRotation=45,
    #     zHighlightZero=True,
    #     xyFrameLine=2,
    #     yzFrameLine=1,
    #     zxFrameLine=1,
    #     xyFrameColor=&#34;red3&#34;,
    #     xyShift=1.05,  # move xy 5% above the top of z-range
    #     yzGrid=True,
    #     zxGrid=True,
    #     zxShift=1.0,
    #     xTitleJustify=&#34;bottom-right&#34;,
    #     xTitleOffset=-1.175,
    #     xLabelOffset=-1.75,
    #     yLabelRotation=90,
    #     zInverted=True,
    #     tipSize=0.25,
    # )
    axs = vedo.Axes(vedo_points, zInverted=True, zHighlightZero=False)
    to = [0, 0, 0]
    from_ = [7000, 6000, 2000]
    camera = dict(pos=from_, focalPoint=to, viewup=[0, 0, -1])
    vedo.show(*vedo_points, axes=axs, camera=camera).close()</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.vis_steinmetz_with_regions"><code class="name flex">
<span>def <span class="ident">vis_steinmetz_with_regions</span></span>(<span>region_names, colors=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Visualise recordings containing regions</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>region_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>The names of the regions</dd>
<dt><strong><code>colors</code></strong> :&ensp;<code>list</code> of <code>RGB</code> or <code>str</code>, optional</dt>
<dd>The colors to use for visualization, by default None</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vis_steinmetz_with_regions(region_names, colors=None):
    &#34;&#34;&#34;
    Visualise recordings containing regions

    Parameters
    ----------
    region_names : list of str
        The names of the regions
    colors : list of RGB or str, optional
        The colors to use for visualization, by default None

    Returns
    -------
    None

    &#34;&#34;&#34;
    probes_locs = load_steinmetz_locations()

    scene = brainrender.Scene()
    scene.root._silhouette_kwargs[&#34;lw&#34;] = 1
    scene.root.alpha(0.2)

    if colors is None:
        cm = ColorManager(num_colors=len(region_names) + 2, method=&#34;rgb&#34;)
        colors = cm.colors

    for locs in probes_locs:
        brain_regions = locs[&#34;allen_ontology&#34;].values
        cont = False
        for region_name in region_names:
            if region_name not in brain_regions:
                print(sorted(list(set(brain_regions))))
                cont = True

        if cont:
            continue

        k = int(len(locs) / 374.0)

        for i in range(k):
            points = locs[i * 374 : (i + 1) * 374]
            brain_regions = points[&#34;allen_ontology&#34;].values
            cont = True
            for region_name in region_names:
                if region_name in brain_regions:
                    print(sorted(list(set(brain_regions))))
                    cont = False

            if cont:
                continue

            sil = 0.5
            alpha = 0.8
            color_list = [colors[-1]] * len(points)
            spheres = brainrender.actors.Points(
                points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values,
                colors=color_list,
                alpha=alpha,
                radius=20,
            )
            spheres = scene.add(spheres)

            p1 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[0]
            p2 = points[[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values[-1]

            distance_vec = p2 - p1
            distance = np.sqrt(np.sum(np.square(distance_vec)))
            print(f&#34;Npixels probe is {distance:.2f} units long&#34;)

            mesh = vedo.shapes.Cylinder(pos=[p1, p2], c=colors[-2], r=100, alpha=0.3)
            cylinder = brainrender.actor.Actor(
                mesh, name=&#34;Cylinder&#34;, br_class=&#34;Cylinder&#34;
            )
            scene.add(cylinder)

            if sil:
                scene.add_silhouette(spheres, lw=sil)

    # Add brain regions
    for region_name, color in zip(region_names, colors[:-2]):
        reg = scene.add_brain_region(
            region_name, hemisphere=&#34;right&#34;, alpha=0.3, silhouette=False, color=color
        )
        scene.add_silhouette(reg, lw=2)

    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()

    camera = {
        &#34;pos&#34;: (-16170, -7127, 31776),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (27548, 67414),
        &#34;focalPoint&#34;: (7319, 2861, -3942),
        &#34;distance&#34;: 43901,
    }

    scene.render(zoom=3.5, camera=camera)
    scene.close()</code></pre>
</details>
</dd>
<dt id="neuroconnect.atlas.visualise_probe_cells"><code class="name flex">
<span>def <span class="ident">visualise_probe_cells</span></span>(<span>region_names, region_sizes, atlas_name=None, session_id=None, hemisphere='left', colors=None, style='metallic', interactive=True, screenshot_name=None, shift=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Render probes in a recording and the cells in inside probe bounds.</p>
<p>By default will look for probes in steinmetz data that match the given regions.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>region_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>The names of the regions</dd>
<dt><strong><code>region_sizes</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>The number of cells in each region</dd>
<dt><strong><code>atlas_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the atlas, by default None</dd>
<dt><strong><code>session_id</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The ID of the session, by default None</dd>
<dt><strong><code>hemisphere</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The side of the brain, by default "left"</dd>
<dt><strong><code>colors</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>RGB</code>, optional</dt>
<dd>The colors to use, by default None</dd>
<dt><strong><code>style</code></strong> :&ensp;<code>str</code>, optional<code>, by default "metallic"</code></dt>
<dd>The style of rendering to use</dd>
<dt><strong><code>interactive</code></strong> :&ensp;<code>bool</code>, optional<code>, by default True</code></dt>
<dd>Whether to plot in interactive mode.</dd>
<dt><strong><code>screenshot_name</code></strong> :&ensp;<code>str</code>, optional<code>, by default None</code></dt>
<dd>Should be passed if interactive is False.</dd>
<dt><strong><code>shift</code></strong> :&ensp;<code>bool</code>, optional<code>, by default False</code></dt>
<dd>Whether to shift the probes in the lateral anterior direction.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualise_probe_cells(
    region_names,
    region_sizes,
    atlas_name=None,
    session_id=None,
    hemisphere=&#34;left&#34;,
    colors=None,
    style=&#34;metallic&#34;,
    interactive=True,
    screenshot_name=None,
    shift=False,
):
    &#34;&#34;&#34;
    Render probes in a recording and the cells in inside probe bounds.

    By default will look for probes in steinmetz data that match the given regions.

    Parameters
    ----------
    region_names : list of str
        The names of the regions
    region_sizes : list of int
        The number of cells in each region
    atlas_name : str, optional
        The name of the atlas, by default None
    session_id : int, optional
        The ID of the session, by default None
    hemisphere : str, optional
        The side of the brain, by default &#34;left&#34;
    colors : list of str or RGB, optional
        The colors to use, by default None
    style : str, optional, by default &#34;metallic&#34;
        The style of rendering to use
    interactive : bool, optional, by default True
        Whether to plot in interactive mode.
    screenshot_name : str, optional, by default None
        Should be passed if interactive is False.
    shift : bool, optional, by default False
        Whether to shift the probes in the lateral anterior direction.

    &#34;&#34;&#34;
    np.random.seed(42)

    # Here is where all the setup of points is done.
    point_locations, brain_region_meshes, probe_info = gen_graph_for_regions(
        region_names,
        region_sizes,
        atlas_name,
        session_id,
        hemisphere,
        sort_=True,
        shift=shift,
    )

    brainrender.settings.SHADER_STYLE = style
    brainrender.settings.SHOW_AXES = False
    brainrender.settings.SCREENSHOT_SCALE = 2
    screenshots_folder = os.path.join(here, &#34;..&#34;, &#34;figures&#34;, &#34;brainrender&#34;)
    scene = brainrender.Scene(screenshots_folder=screenshots_folder, inset=False)

    if colors is None:
        cm = ColorManager(num_colors=len(region_names) + len(probe_info), method=&#34;sns&#34;)
        colors = cm.colors
    iter_color = iter(colors)

    for name, mesh, points_loc in zip(
        region_names, brain_region_meshes, point_locations
    ):
        points_loc = points_loc[0]
        region_color = next(iter_color)
        brain_mesh = brainrender.actor.Actor(
            mesh, name=name, br_class=&#34;brain region&#34;, color=region_color, alpha=0.3
        )
        scene.add(brain_mesh)
        scene.add_silhouette(brain_mesh, lw=2)

        color_list = [region_color] * len(points_loc)
        spheres = brainrender.actors.Points(
            points_loc,
            colors=color_list,
            alpha=0.5,
            radius=15,
        )
        spheres = scene.add(spheres)

        scene.add_silhouette(spheres, lw=0.5)

    for probes in probe_info:
        sphere_color = next(iter_color)
        points = probes[1][[&#34;ccf_ap&#34;, &#34;ccf_dv&#34;, &#34;ccf_lr&#34;]].values
        color_list = [sphere_color] * len(points)
        spheres = brainrender.actors.Points(
            points,
            colors=color_list,
            alpha=0.6,
            radius=20,
        )
        spheres = scene.add(spheres)

        cylinder = brainrender.actor.Actor(
            probes[-1],
            name=&#34;Cylinder&#34;,
            br_class=&#34;Cylinder&#34;,
            color=sphere_color,
            alpha=0.4,
        )
        scene.add(cylinder)

    th = scene.add_brain_region(
        &#34;TH&#34;, alpha=0.3, silhouette=False, color=myterial.blue_grey_dark
    )
    th.wireframe()

    camera = {
        &#34;pos&#34;: (-16170, -7127, 31776),
        &#34;viewup&#34;: (0, -1, 0),
        &#34;clippingRange&#34;: (27548, 67414),
        &#34;focalPoint&#34;: (7319, 2861, -3942),
        &#34;distance&#34;: 43901,
    }
    scene.render(zoom=3.5, camera=camera, interactive=interactive)

    if not interactive:
        scene.screenshot(name=screenshot_name, scale=2)

    scene.close()

    return point_locations</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="neuroconnect" href="index.html">neuroconnect</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="neuroconnect.atlas.brainrender_vis" href="#neuroconnect.atlas.brainrender_vis">brainrender_vis</a></code></li>
<li><code><a title="neuroconnect.atlas.gen_graph_for_regions" href="#neuroconnect.atlas.gen_graph_for_regions">gen_graph_for_regions</a></code></li>
<li><code><a title="neuroconnect.atlas.get_bounding_probes" href="#neuroconnect.atlas.get_bounding_probes">get_bounding_probes</a></code></li>
<li><code><a title="neuroconnect.atlas.get_brain_region_meshes" href="#neuroconnect.atlas.get_brain_region_meshes">get_brain_region_meshes</a></code></li>
<li><code><a title="neuroconnect.atlas.get_idx_of_points_in_meshes" href="#neuroconnect.atlas.get_idx_of_points_in_meshes">get_idx_of_points_in_meshes</a></code></li>
<li><code><a title="neuroconnect.atlas.get_n_random_points_in_region" href="#neuroconnect.atlas.get_n_random_points_in_region">get_n_random_points_in_region</a></code></li>
<li><code><a title="neuroconnect.atlas.get_points_in_hemisphere" href="#neuroconnect.atlas.get_points_in_hemisphere">get_points_in_hemisphere</a></code></li>
<li><code><a title="neuroconnect.atlas.load_steinmetz_locations" href="#neuroconnect.atlas.load_steinmetz_locations">load_steinmetz_locations</a></code></li>
<li><code><a title="neuroconnect.atlas.make_probes" href="#neuroconnect.atlas.make_probes">make_probes</a></code></li>
<li><code><a title="neuroconnect.atlas.place_probes_at_com" href="#neuroconnect.atlas.place_probes_at_com">place_probes_at_com</a></code></li>
<li><code><a title="neuroconnect.atlas.steinmetz_brain_regions" href="#neuroconnect.atlas.steinmetz_brain_regions">steinmetz_brain_regions</a></code></li>
<li><code><a title="neuroconnect.atlas.vedo_vis" href="#neuroconnect.atlas.vedo_vis">vedo_vis</a></code></li>
<li><code><a title="neuroconnect.atlas.vis_steinmetz_with_regions" href="#neuroconnect.atlas.vis_steinmetz_with_regions">vis_steinmetz_with_regions</a></code></li>
<li><code><a title="neuroconnect.atlas.visualise_probe_cells" href="#neuroconnect.atlas.visualise_probe_cells">visualise_probe_cells</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>